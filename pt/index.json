[{"content":" Mockito is a powerful Java testing framework that enables developers to create mock objects for unit testing purposes. It allows developers to test their code in isolation by replacing dependencies with mock objects that simulate the behavior of real objects. Mockito can also be used to test final and static methods, which can be challenging to test with other testing frameworks.\nTesting final and static methods can be tricky because they are tightly coupled to the implementation of the class. Mockito provides a way to create mocks for final and static methods using a special plugin called \u0026ldquo;PowerMock.\u0026rdquo; In this post, we will explore how to use Mockito with PowerMock to test final and static methods.\nStep 1: Add Mockito and PowerMock Dependencies The first step is to add the necessary dependencies to your project. You can add the following dependencies to your build.gradle or pom.xml file:\ngroovy 1 2 3 testImplementation \u0026#39;org.mockito:mockito-core:3.11.2\u0026#39; testImplementation \u0026#39;org.powermock:powermock-module-junit4:2.0.9\u0026#39; testImplementation \u0026#39;org.powermock:powermock-api-mockito3:2.0.9\u0026#39; Step 2: Enable PowerMockitoRunner\nThe next step is to enable the PowerMockitoRunner in your JUnit test class. The PowerMockitoRunner is responsible for initializing the PowerMock framework.\njava 1 2 3 @RunWith(PowerMockRunner.class) @PrepareForTest({ClassName.class}) public class ClassNameTest { The @RunWith(PowerMockRunner.class) annotation tells JUnit to use the PowerMockitoRunner, while @PrepareForTest tells PowerMock which class needs to be prepared for testing.\nStep 3: Mocking Final and Static Methods\nTo mock final and static methods, you need to use the PowerMockito framework. PowerMockito provides a mockStatic method that you can use to create a mock object for a static method. Similarly, it provides a mockFinal method to mock final methods.\njava 1 2 3 4 5 6 7 8 9 10 11 12 13 @Test public void testFinalMethod() { final ClassName mockObject = mock(ClassName.class); when(mockObject.finalMethod()).thenReturn(\u0026#34;Mock Value\u0026#34;); assertEquals(\u0026#34;Mock Value\u0026#34;, mockObject.finalMethod()); } @Test public void testStaticMethod() { mockStatic(ClassName.class); when(ClassName.staticMethod()).thenReturn(\u0026#34;Mock Value\u0026#34;); assertEquals(\u0026#34;Mock Value\u0026#34;, ClassName.staticMethod()); } The \u0026lsquo;mock\u0026rsquo; method is used to create a mock object for the class, and the \u0026lsquo;when\u0026rsquo; method is used to specify the behavior of the method. The \u0026lsquo;mockStatic\u0026rsquo; method is used to create a mock object for a static method.\nStep 4: Verify the Method Calls\nFinally, you need to verify that the mocked method was called during the test.\njava 1 2 3 verify(mockObject).finalMethod(); verifyStatic(ClassName.class); ClassName.staticMethod(); The \u0026lsquo;verify\u0026rsquo; method is used to verify that a method was called on a mock object. The \u0026lsquo;verifyStatic\u0026rsquo; method is used to verify that a static method was called.\nBy using Mockito with PowerMock, developers can create mock objects for final and static methods, which can be challenging to test with other testing frameworks. This approach enables developers to write more robust and reliable unit tests for their code.\n","description":"How to use Mockito with PowerMock to test final and static methods in Java. It outlines a step-by-step guide, from adding necessary dependencies to verifying method calls.","id":0,"section":"posts","tags":null,"title":"Mockito and PowerMock: How to Test Final and Static Methods with Ease","uri":"/2023/04/25/Mockito-PowerMock-Test-Final-Static-Methods/"},{"content":" Becoming a successful freelance developer is a dream for many, and with the rise of the gig economy, more and more people are choosing to work for themselves. While being your own boss can be liberating, it\u0026rsquo;s also a challenging journey that requires dedication, hard work, and a bit of luck. In this article, we will explore the steps you can take to become a successful freelance developer.\nThe world of freelance development is rapidly growing, and more people than ever are making the jump to become their own boss. While the freedom of freelancing can be appealing, it can also be a challenging journey that requires dedication, hard work, and a bit of luck. However, with the right approach and mindset, anyone can become a successful freelance developer. In this article, we will explore the steps you can take to become a successful freelance developer.\nStep 1: Develop Your Skills Before you start developing your skills, it\u0026rsquo;s essential to identify your niche. While it\u0026rsquo;s possible to be a generalist, specializing in a specific area can help you stand out in a crowded market. For example, you may specialize in web development, mobile app development, or database management. Once you identify your niche, you can focus on developing the specific skills needed for that area.\nThe first step to becoming a successful freelance developer is to develop your skills. You need to have a solid understanding of the programming languages you work with, as well as a deep understanding of the software development life cycle. Additionally, you need to stay up-to-date with the latest trends and technologies in your field.\nOnline courses and coding boot camps are an excellent way to develop your skills. Many online platforms offer courses on programming languages, frameworks, and software development processes. These courses are often taught by industry experts and can be completed at your own pace. Coding boot camps are intensive programs that teach you the skills needed to become a developer. They typically last for several weeks or months and often include hands-on projects to help you apply what you\u0026rsquo;ve learned.\nReading programming books and blogs can help you stay up-to-date with the latest trends and technologies in your field. Books provide in-depth knowledge on specific topics and can help you master a programming language or framework. Blogs provide up-to-date information on emerging trends and best practices in software development.\nPractice makes perfect, and coding regularly can help you hone your skills. Create your projects or contribute to open-source projects to apply what you\u0026rsquo;ve learned. Participate in coding challenges and hackathons to challenge yourself and learn from others.\nFinding a mentor can be an excellent way to accelerate your learning and receive feedback on your work. Mentors can provide guidance on industry best practices, help you identify areas for improvement, and provide insights on how to build your portfolio and brand.\nStep 2: Build a Portfolio Once you have developed your skills, the next step is to build a portfolio. A portfolio is a collection of projects that you have worked on, which showcases your skills and abilities. It’s essential to have a portfolio because potential clients will want to see your work before hiring you.\nWhen building your portfolio, it\u0026rsquo;s important to showcase your best work. Choose projects that demonstrate your skills and abilities in your niche. If you\u0026rsquo;re just starting, you can create personal projects to showcase your abilities.\nYour portfolio should look professional and polished. Use a clean and modern design to showcase your work. Include your name, contact information, and a brief introduction about yourself and your skills.\nInclude a variety of projects in your portfolio to showcase your versatility as a developer. For example, if you specialize in web development, you can include projects that involve building websites, web applications, and e-commerce sites.\nInclude a brief description of each project in your portfolio, highlighting the technologies and tools used, the problem you solved, and the outcome achieved. This helps potential clients understand your thought process and the value you can bring to their project.\nIt\u0026rsquo;s important to keep your portfolio updated with your latest work. As you work on new projects, add them to your portfolio to showcase your continuous growth and development.\nAsk for feedback on your portfolio from your peers or mentors. They can provide valuable insights on how to improve your portfolio and make it more effective in attracting potential clients.\nBy choosing your best work, making it professional, showcasing your versatility, providing context, keeping it updated, and getting feedback, you can create a portfolio that showcases your skills and abilities and attracts potential clients. Remember that your portfolio is a representation of your brand, so make sure it\u0026rsquo;s polished and professional.\nStep 3: Build Your Brand Building your brand is critical to success as a freelance developer. Your brand is what sets you apart from other developers and helps potential clients remember you. Your brand should reflect your personality, values, and skills.\nBefore you start building your brand, you need to define it. Think about your personality, values, and skills, and how they can be translated into your brand. Your brand should be authentic and reflect who you are as a person and a developer.\nA personal website is an essential tool for building your brand as a freelance developer. It\u0026rsquo;s a place where potential clients can learn more about you, your skills, and your services. Your website should showcase your portfolio and include an \u0026ldquo;About\u0026rdquo; page that tells your story.\nWhen creating your website, focus on design and user experience. Make sure your website is visually appealing and easy to navigate. Use a professional domain name, and ensure your website is mobile-friendly.\nSocial media platforms such as LinkedIn, Twitter, and GitHub can be powerful tools for building your brand as a freelance developer. Use these platforms to share your work, engage with other developers, and build your network.\nLinkedIn is an excellent platform for building your professional network. Create a LinkedIn profile that highlights your skills and experience, and connect with other developers, recruiters, and potential clients.\nTwitter is an excellent platform for engaging with other developers and sharing your thoughts and insights. Use Twitter to share your work, participate in relevant conversations, and build your following.\nGitHub is a platform for sharing code and collaborating with other developers. Use GitHub to showcase your open-source projects and contribute to other projects. This can help establish your reputation as a skilled developer.\nConsistency is key when building your brand as a freelance developer. Use the same branding across all platforms, including your personal website, social media profiles, and business cards. This helps create a cohesive and recognizable brand that potential clients can remember.\nAbove all, be authentic when building your brand. Your brand should reflect who you are as a person and a developer. Don\u0026rsquo;t try to be someone you\u0026rsquo;re not, as this can come across as insincere. Authenticity is key to building trust with potential clients and establishing long-term relationships.\nBy defining your brand, creating a personal website, using social media to your advantage, being consistent, and being authentic, you can establish a brand that sets you apart from other developers and attracts potential clients. Remember that your brand is a representation of you and your skills, so make sure it\u0026rsquo;s authentic and reflects who you are as a person and a developer.\nStep 4: Establish Your Rates Establishing your rates is an important part of being a successful freelance developer. You need to price your services in a way that’s fair to both you and your clients. If you charge too little, you may struggle to make ends meet. On the other hand, if you charge too much, you may struggle to find clients.\nYour experience and skills are the primary factors that determine your rates as a freelance developer. If you\u0026rsquo;re a beginner, you may need to charge less until you gain more experience and build your portfolio. However, as you gain more experience and develop your skills, you can charge higher rates.\nIt\u0026rsquo;s important to research the market rates for freelance developers in your field and location. This will help you determine what is reasonable and competitive for your services. You can use online platforms such as Upwork or Freelancer to get an idea of what other developers are charging for similar services. You can also reach out to other freelance developers in your network to get an idea of their rates.\nThe type of work you\u0026rsquo;re doing also affects your rates. For example, web development may be priced differently from software development. If you specialize in a specific type of development, such as mobile app development, you may be able to charge higher rates due to the higher demand for those services.\nThe timeline for completion is another factor that affects your rates. If a client needs a project completed within a short timeframe, you may need to charge a higher rate to accommodate the time constraints. On the other hand, if a project has a longer timeline, you may be able to charge a lower rate.\nThe level of complexity of a project also affects your rates. More complex projects require more time and effort, and therefore, you may need to charge higher rates. For example, developing an e-commerce platform may be more complex than developing a simple website, and therefore, you may need to charge a higher rate.\nIt\u0026rsquo;s important to be transparent with your clients about your rates and the factors that affect them. Provide a breakdown of your rates and explain why you charge what you do. This helps build trust with your clients and establishes clear expectations from the beginning.\nEstablishing your rates as a freelance developer is crucial to your success. Consider your experience and skills, research the market rates, consider the type of work, timeline for completion, and level of complexity, and be transparent with your clients. By doing so, you can establish fair and competitive rates that are beneficial to both you and your clients.\nStep 5: Network and Market Yourself Networking and marketing yourself are crucial to success as a freelance developer. You need to get your name out there and let potential clients know about your services. Attend networking events, conferences, and meetups. Join online communities and participate in discussions. Reach out to potential clients and offer your services.\nBuilding a strong professional network is an essential aspect of being a successful freelance developer. Your network can provide you with job opportunities, referrals, and valuable feedback on your work. To expand your network, attend industry events, conferences, and meetups. You can also join online communities and forums, such as Reddit, StackOverflow, or GitHub.\nWhen attending events, be prepared to introduce yourself and talk about your services. Have business cards and a professional-looking website to share with potential clients or colleagues. It’s also essential to follow up with people you meet after the event to maintain the connection and strengthen the relationship.\nAnother way to market yourself as a freelance developer is to create a personal brand that reflects your personality, values, and skills. Building a personal brand is not just about having a website or a social media presence, but also about establishing a consistent voice and tone across all your marketing channels. Your brand should represent your unique perspective, expertise, and style.\nIn addition to networking and marketing yourself, you can also leverage your existing network to find new opportunities. Reach out to former colleagues or classmates and let them know about your services. Ask for referrals or recommendations from satisfied clients. You can also participate in open-source projects or contribute to online communities to showcase your skills and gain recognition in your field.\nFinally, don’t underestimate the importance of word-of-mouth marketing. Satisfied clients can be your best advocates, so focus on providing excellent customer service and delivering high-quality work. Ask for feedback after completing a project and use it to improve your skills and services.\nOverall, networking and marketing are critical to success as a freelance developer. Building a strong professional network, establishing a personal brand, and leveraging your existing network can help you find new opportunities and grow your business.\nStep 6: Manage Your Finances Managing your finances is essential to success as a freelance developer. You need to keep track of your income, expenses, and taxes. Additionally, you need to ensure that you have enough money saved to cover unexpected expenses or slow periods.\nManaging your finances effectively is critical to success as a freelance developer. Here are some tips to help you stay on top of your finances:\nSet Up a Separate Bank Account: It\u0026rsquo;s essential to keep your personal and business finances separate. Consider setting up a separate bank account for your freelance income and expenses. This will help you track your business expenses more easily and make it easier to file your taxes.\nUse Accounting Software: Consider using accounting software like QuickBooks or Xero to help manage your finances. These tools can help you track your income, expenses, and invoices, and generate reports for tax purposes. They can also save you time and help you stay organized.\nTrack Your Income and Expenses: Keep track of all your income and expenses, including project fees, expenses for equipment and software, travel expenses, and other business-related costs. This will help you identify areas where you can cut costs and maximize your profitability.\nBudget for Taxes: As a freelance developer, you\u0026rsquo;re responsible for paying your taxes. Budgeting for taxes can help you avoid surprises at tax time. Consider setting aside a percentage of your income for taxes or consulting with a tax professional to determine how much you should be setting aside.\nSave for Emergencies: Freelancing can be unpredictable, and it\u0026rsquo;s important to have savings to cover unexpected expenses or slow periods. Consider setting aside some money each month in an emergency fund. A general rule of thumb is to save three to six months of expenses.\nInvoice and Get Paid on Time: It\u0026rsquo;s important to invoice your clients promptly and follow up on unpaid invoices. Consider using invoicing software to make the process easier. Additionally, make sure you have clear payment terms in your contracts and follow up on late payments.\nEvaluate Your Rates: Periodically evaluate your rates and adjust them as necessary. If you\u0026rsquo;re consistently working long hours or taking on low-paying projects, it may be time to reevaluate your rates. Make sure your rates are fair and reflect your experience, skills, and the value you provide to clients.\nManaging your finances is an essential part of being a successful freelance developer. By setting up a separate bank account, using accounting software, tracking your income and expenses, budgeting for taxes, saving for emergencies, invoicing and getting paid on time, and evaluating your rates, you can stay on top of your finances and grow your business.\n","description":"The world of freelance development is rapidly growing, and more people than ever are making the jump to become their own boss. While the freedom of freelancing can be appealing, it can also be a challenging journey that requires dedication, hard work, and a bit of luck. However, with the right approach and mindset, anyone can become a successful freelance developer. In this article, we will explore the steps you can take to become a successful freelance developer.","id":1,"section":"posts","tags":null,"title":"6 Steps to Becoming a Successful Freelance Developer in the Gig Economy","uri":"/2023/03/15/6-steps-to-become-freelance-developer/"},{"content":" While there are a variety of authentication services available, including Firebase Authentication and Auth0, there may be situations in your project where you require greater flexibility and control over your user management and authorization with advanced features.\nIn such cases, Keycloak is an ideal choice as it offers a wide range of features out of the box. Keycloak includes built-in support for OpenID Connect and SAML 2.0, as well as integrations with popular social networks like Google, GitHub, Facebook, and Twitter.\nLet\u0026rsquo;s take a look at how to create a login page using React and keycloak.\nNote We will not go over how to install keycloak. You can view the installation of keycloak here\nStep 1: Install Keycloak JavaScript adapter for React You can install the Keycloak JavaScript adapter for React using npm. In your project directory, run the following command:\njavascript 1 npm install @react-keycloak/web keycloak-js Step 2: Set up Keycloak instance You need to set up a Keycloak instance in your React application. You can do this by creating a Keycloak configuration file with the following code:\njavascript 1 2 3 4 5 6 7 8 9 import Keycloak from \u0026#34;keycloak-js\u0026#34;; const keycloak = new Keycloak({ url: \u0026#34;https://your-keycloak-server/auth\u0026#34;, realm: \u0026#34;your-realm\u0026#34;, clientId: \u0026#34;your-client-id\u0026#34;, }); export default keycloak; Replace the url, realm, and clientId values with your Keycloak server URL, realm name, and client ID.\nStep 3: Wrap the app with KeycloakProvider\nWrap your React application with the KeycloakProvider component to provide the Keycloak context to your app. You can do this by adding the following code to your index.js file:\njavascript 1 2 3 4 5 6 7 8 9 10 11 import React from \u0026#34;react\u0026#34;; import ReactDOM from \u0026#34;react-dom\u0026#34;; import { KeycloakProvider } from \u0026#34;@react-keycloak/web\u0026#34;; import keycloak from \u0026#34;./keycloak\u0026#34;; ReactDOM.render( \u0026lt;KeycloakProvider keycloak={keycloak}\u0026gt; \u0026lt;App /\u0026gt; \u0026lt;/KeycloakProvider\u0026gt;, document.getElementById(\u0026#34;root\u0026#34;) ); Replace App with the name of your main component.\nStep 4: Create a login page component\nCreate a new component for the login page. This component should contain a form with two input fields for the username and password, and a submit button to submit the form. You can use the following code as a starting point:\njavascript 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import React, { useState } from \u0026#34;react\u0026#34;; import { useKeycloak } from \u0026#34;@react-keycloak/web\u0026#34;; function LoginPage() { const { keycloak } = useKeycloak(); const [username, setUsername] = useState(\u0026#34;\u0026#34;); const [password, setPassword] = useState(\u0026#34;\u0026#34;); const handleSubmit = async (event) =\u0026gt; { event.preventDefault(); try { await keycloak.login({ username, password, }); } catch (error) { console.error(\u0026#34;Failed to log in\u0026#34;, error); } }; return ( \u0026lt;form onSubmit={handleSubmit}\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; placeholder=\u0026#34;Username\u0026#34; value={username} onChange={(event) =\u0026gt; setUsername(event.target.value)} /\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; placeholder=\u0026#34;Password\u0026#34; value={password} onChange={(event) =\u0026gt; setPassword(event.target.value)} /\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;Log in\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; ); } export default LoginPage; Step 5: Use the login page component\nYou can use the login page component in your main component or any other component in your app. You can also add a link to the login page in your app navigation. Here\u0026rsquo;s an example of how to use the login page component in your main component:\njavascript 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import React from \u0026#39;react\u0026#39;; import { useKeycloak } from \u0026#39;@react-keycloak/web\u0026#39;; import LoginPage from \u0026#39;./LoginPage\u0026#39;; function App() { const { keycloak, initialized } = useKeycloak(); if (!initialized) { return \u0026lt;div\u0026gt;Loading...\u0026lt;/div\u0026gt;; } if (!keycloak.authenticated) { return \u0026lt;LoginPage /\u0026gt;; } return ( \u0026lt;div\u0026gt;) That\u0026rsquo;s it! With these steps, you should be able to create a login page using React and Keycloak.\nCiao\n","description":"Creating a login page is the one of the first things you need when creating a website. However, you dont have to struggle trying to create the schema from scratch. Keycloak is one such tool that provides functionalities such as user management, social logins and much more.","id":2,"section":"posts","tags":null,"title":"Securing React Apps with Keycloak: A Comprehensive Guide","uri":"/2023/03/14/Securing-react-app-keycloak/"},{"content":"Resilience4j calculates the failure threshold using ringbit buffer.\nThe state of circuitbreaker changes from CLOSED to OPEN when at end of count size the failure rate exceeds the threshold.\nResilience4j provides you two buffers - CLOSED and HALF_OPEN state buffers. Imagine this is our set up\nClosed buffer size = 10\nHalf open buffer size = 5\nFailure rate threshold = 60%\nOpen state count = 10\nWhen the first call comes in the buffer has 0 entries. At the end of 10th call the imagine that all calls were successful. Threshhold rate is calculated to 0% after 10 calls.\nThen the next 6 calls all failed calls and will push out the first 6 Passed calls. After 11th call onwards, the threshold rate will keep getting updated at each new entry.\nAt the end of 16th call, the state would change to OPEN. In the open state this bucket would stay as is for next 10 calls.\nAfter end of 25th call, the state would change to HALF_OPEN and half open bucket will start filling. Say all the 5 calls are success, then then the circuitbreaker is closed.\nAt this moment, the threshold rate is reset for CLOSED state. For threshold to be calculated again, the buffer must fill in again.\nThen the updates on threshold rate is continouly updated with each call\nHere\u0026rsquo;s the link to the code which uses the below config.\n1 2 3 4 .failureRateThreshold(60) .waitDurationInOpenState(Duration.ofSeconds(10)) .permittedNumberOfCallsInHalfOpenState(3) .slidingWindowSize(10) Logs: Pay special attention to Buffered calls and you see that buffer is emptied after state swutches from HALF_OPEN to CLOSED\ncounter = 1 Hi Dinesh I am good. Nice to meet you Successful call count: 1 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:1 counter = 2 Hi Dinesh I am good. Nice to meet you Successful call count: 2 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:2 counter = 3 Hi Dinesh I am good. Nice to meet you Successful call count: 3 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:3 counter = 4 Hi Dinesh I am good. Nice to meet you Successful call count: 4 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:4 counter = 5 Hi Dinesh I am good. Nice to meet you Successful call count: 5 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:5 counter = 6 Hi Dinesh I am good. Nice to meet you Successful call count: 6 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:6 counter = 7 Hi Dinesh I am good. Nice to meet you Successful call count: 7 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:7 counter = 8 Hi Dinesh I am good. Nice to meet you Successful call count: 8 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:8 counter = 9 Hi Dinesh I am good. Nice to meet you Successful call count: 9 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:9 counter = 10 Hi Dinesh I am good. Nice to meet you Successful call count: 10 | Failed call count: 0 | Failure rate %:0.0 | State: CLOSED | Buffered cals:10 counter = 11 Successful call count: 9 | Failed call count: 1 | Failure rate %:10.0 | State: CLOSED | Buffered cals:10 FAILED counter = 12 Successful call count: 8 | Failed call count: 2 | Failure rate %:20.0 | State: CLOSED | Buffered cals:10 FAILED counter = 13 Successful call count: 7 | Failed call count: 3 | Failure rate %:30.0 | State: CLOSED | Buffered cals:10 FAILED counter = 14 Successful call count: 6 | Failed call count: 4 | Failure rate %:40.0 | State: CLOSED | Buffered cals:10 FAILED counter = 15 Successful call count: 5 | Failed call count: 5 | Failure rate %:50.0 | State: CLOSED | Buffered cals:10 FAILED counter = 16 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 17 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 18 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 19 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 20 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 21 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 22 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 23 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 24 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 25 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 26 Successful call count: 0 | Failed call count: 1 | Failure rate %:-1.0 | State: HALF_OPEN | Buffered cals:1 FAILED counter = 27 Hi Dinesh I am good. Nice to meet you Successful call count: 1 | Failed call count: 1 | Failure rate %:-1.0 | State: HALF_OPEN | Buffered cals:2 counter = 28 Hi Dinesh I am good. Nice to meet you Successful call count: 0 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:0 counter = 29 Hi Dinesh I am good. Nice to meet you Successful call count: 1 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:1 counter = 30 Hi Dinesh I am good. Nice to meet you Successful call count: 2 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:2 counter = 31 Hi Dinesh I am good. Nice to meet you Successful call count: 3 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:3 counter = 32 Hi Dinesh I am good. Nice to meet you Successful call count: 4 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:4 counter = 33 Hi Dinesh I am good. Nice to meet you Successful call count: 5 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:5 counter = 34 Hi Dinesh I am good. Nice to meet you Successful call count: 6 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:6 counter = 35 Hi Dinesh I am good. Nice to meet you Successful call count: 7 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:7 counter = 36 Hi Dinesh I am good. Nice to meet you Successful call count: 8 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:8 counter = 37 Successful call count: 8 | Failed call count: 1 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:9 FAILED counter = 38 Successful call count: 8 | Failed call count: 2 | Failure rate %:20.0 | State: CLOSED | Buffered cals:10 FAILED counter = 39 Successful call count: 7 | Failed call count: 3 | Failure rate %:30.0 | State: CLOSED | Buffered cals:10 FAILED counter = 40 Successful call count: 6 | Failed call count: 4 | Failure rate %:40.0 | State: CLOSED | Buffered cals:10 FAILED counter = 41 Successful call count: 5 | Failed call count: 5 | Failure rate %:50.0 | State: CLOSED | Buffered cals:10 FAILED counter = 42 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 43 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 44 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 45 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 46 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 47 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 48 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 49 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 50 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 51 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 52 Successful call count: 0 | Failed call count: 1 | Failure rate %:-1.0 | State: HALF_OPEN | Buffered cals:1 FAILED counter = 53 Hi Dinesh I am good. Nice to meet you Successful call count: 1 | Failed call count: 1 | Failure rate %:-1.0 | State: HALF_OPEN | Buffered cals:2 counter = 54 Hi Dinesh I am good. Nice to meet you Successful call count: 0 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:0 counter = 55 Hi Dinesh I am good. Nice to meet you Successful call count: 1 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:1 counter = 56 Hi Dinesh I am good. Nice to meet you Successful call count: 2 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:2 counter = 57 Hi Dinesh I am good. Nice to meet you Successful call count: 3 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:3 counter = 58 Hi Dinesh I am good. Nice to meet you Successful call count: 4 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:4 counter = 59 Hi Dinesh I am good. Nice to meet you Successful call count: 5 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:5 counter = 60 Hi Dinesh I am good. Nice to meet you Successful call count: 6 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:6 counter = 61 Hi Dinesh I am good. Nice to meet you Successful call count: 7 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:7 counter = 62 Hi Dinesh I am good. Nice to meet you Successful call count: 8 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:8 counter = 63 Successful call count: 8 | Failed call count: 1 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:9 FAILED counter = 64 Successful call count: 8 | Failed call count: 2 | Failure rate %:20.0 | State: CLOSED | Buffered cals:10 FAILED counter = 65 Successful call count: 7 | Failed call count: 3 | Failure rate %:30.0 | State: CLOSED | Buffered cals:10 FAILED counter = 66 Successful call count: 6 | Failed call count: 4 | Failure rate %:40.0 | State: CLOSED | Buffered cals:10 FAILED counter = 67 Successful call count: 5 | Failed call count: 5 | Failure rate %:50.0 | State: CLOSED | Buffered cals:10 FAILED counter = 68 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 69 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 70 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 71 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 72 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 73 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 74 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 75 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 76 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 77 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED counter = 78 Successful call count: 0 | Failed call count: 1 | Failure rate %:-1.0 | State: HALF_OPEN | Buffered cals:1 FAILED counter = 79 Hi Dinesh I am good. Nice to meet you Successful call count: 1 | Failed call count: 1 | Failure rate %:-1.0 | State: HALF_OPEN | Buffered cals:2 counter = 80 Hi Dinesh I am good. Nice to meet you Successful call count: 0 | Failed call count: 0 | Failure rate %:-1.0 | State: CLOSED | Buffered cals:0 ..... counter = 117 Successful call count: 7 | Failed call count: 3 | Failure rate %:30.0 | State: CLOSED | Buffered cals:10 FAILED counter = 118 Successful call count: 6 | Failed call count: 4 | Failure rate %:40.0 | State: CLOSED | Buffered cals:10 FAILED counter = 119 Successful call count: 5 | Failed call count: 5 | Failure rate %:50.0 | State: CLOSED | Buffered cals:10 FAILED counter = 120 Successful call count: 4 | Failed call count: 6 | Failure rate %:60.0 | State: OPEN | Buffered cals:10 FAILED Process finished with exit code 0 ","description":"Understanding how Resilience4j ringbit buffer works, is the key to understanding the internal working of [Resilience4j](https://resilience4j.readme.io/) circuit breaker state change. If you don't know this then you are missing how the buffer counts and hence you will fall into the trap of missing open/close counts in the logs.","id":3,"section":"posts","tags":null,"title":"Afraid you don't understand  Reslience4j state changes: Read this missing manual on Ring Bit Buffer","uri":"/2020/06/17/resiliene4j-circuitbreaker-ringbitbuffer/"},{"content":"So far in the series we have learned about forms on regression models. Each of those models was used to solve a target variable that was a linear number.\nNow we enter a territory where target variables might not be that straight forward. The target variables would be in the form binary, category, etc. Basically anything other than a number. Ex - Cat vs Dog, Yes or No, Reg, Green or Blue.\nThis form of machine learning is called Classification. One of the first algorithms in this series is called Logistic Regression\nGoal: We are provided a set of data that contains, Gender, Age, Salary \u0026amp; Purchased. The goal is to predict whether a person will make a purchase given the parameters - Age and Salary.\nData Exploration 1 2 3 import numpy as np import pandas as pd import matplotlib.pyplot as plt 1 2 #Load the file dataset = pd.read_csv(\u0026#34;Social_Network_Ads.csv\u0026#34;) 1 2 #View the first 5 rows dataset.head() User ID Gender Age EstimatedSalary Purchased 0 15624510 Male 19 19000 0 1 15810944 Male 35 20000 0 2 15668575 Female 26 43000 0 3 15603246 Female 27 57000 0 4 15804002 Male 19 76000 0 1 2 male= dataset[dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Male\u0026#39;][\u0026#39;Gender\u0026#39;].size females = dataset[dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Female\u0026#39;][\u0026#39;Gender\u0026#39;].size 1 2 3 4 5 #Plot male vs female? gender = [\u0026#39;Male\u0026#39;, \u0026#39;Female\u0026#39;] y_pos = np.arange(2) gender_count = [male, females] x_pos = [i for i, _ in enumerate(gender)] # 0,1 1 2 3 4 5 6 7 8 9 plt.bar(x_pos, gender_count, color=\u0026#39;green\u0026#39;) plt.xlabel(\u0026#34;Gender\u0026#34;) plt.ylabel(\u0026#34;Count\u0026#34;) plt.title(\u0026#34;Male Vs Female\u0026#34;) plt.xticks(x_pos, gender) ##==\u0026gt; ([0,1], [Male, Female]) plt.show() 1 2 3 4 5 #How many Men vs Female bought/Not Bought men_purchase = dataset[(dataset[\u0026#39;Purchased\u0026#39;]==1) \u0026amp; (dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Male\u0026#39;)][\u0026#39;Gender\u0026#39;].size men_no_purchase = dataset[(dataset[\u0026#39;Purchased\u0026#39;]==0) \u0026amp; (dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Male\u0026#39;)][\u0026#39;Gender\u0026#39;].size female_purchase = dataset[(dataset[\u0026#39;Purchased\u0026#39;]==1) \u0026amp; (dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Female\u0026#39;)][\u0026#39;Gender\u0026#39;].size female_no_purchase = dataset[(dataset[\u0026#39;Purchased\u0026#39;]==0) \u0026amp; (dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Female\u0026#39;)][\u0026#39;Gender\u0026#39;].size 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 x_label=[\u0026#39;Yes\u0026#39;, \u0026#39;No\u0026#39;] x_pos = np.arange(len(x_label)) width = 0.35 people_purchase = [men_purchase, men_no_purchase] people_no_purchase=[female_purchase,female_no_purchase] #All people fig, ax = plt.subplots() rects1 = ax.bar(x_pos - width/2, people_purchase, width, label=\u0026#39;Men\u0026#39;) rects2 = ax.bar(x_pos + width/2, people_no_purchase, width, label=\u0026#39;Women\u0026#39;) ax.set_ylabel(\u0026#39;Count\u0026#39;) ax.set_title(\u0026#39;Men and Women vs Purchase\u0026#39;) ax.set_xticks(x_pos) ax.set_xticklabels(x_label) ax.legend() def autolabel(rects): \u0026#34;\u0026#34;\u0026#34;Attach a text label above each bar in *rects*, displaying its height.\u0026#34;\u0026#34;\u0026#34; for rect in rects: height = rect.get_height() ax.annotate(\u0026#39;{}\u0026#39;.format(height), xy=(rect.get_x() + rect.get_width() / 2, height), xytext=(0, 3), # 3 points vertical offset textcoords=\u0026#34;offset points\u0026#34;, ha=\u0026#39;center\u0026#39;, va=\u0026#39;bottom\u0026#39;) autolabel(rects1) autolabel(rects2) fig.tight_layout() plt.show() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # What age range purchases more men_purchased=dataset[(dataset[\u0026#39;Purchased\u0026#39;]==1)\u0026amp; (dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Male\u0026#39;) ][\u0026#39;Age\u0026#39;] female_purchased=dataset[(dataset[\u0026#39;Purchased\u0026#39;]==1)\u0026amp; (dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Female\u0026#39;) ][\u0026#39;Age\u0026#39;] n_bins = 6 fig, axs = plt.subplots(2,1, sharey=True) # We can set the number of bins with the `bins` kwarg #plt.title(\u0026#39;Men Vs women Salary Range Purchase\u0026#39;) axs[0].hist(men_purchased, bins=n_bins,orientation =\u0026#39;vertical\u0026#39;,cumulative=True ) axs[0].set_ylabel(\u0026#39;Men Purchases\u0026#39;) axs[1].hist(female_purchased, bins=n_bins,orientation =\u0026#39;vertical\u0026#39;,cumulative=True) axs[1].set_ylabel(\u0026#39;Female Purchases\u0026#39;) axs[1].set_xlabel(\u0026#39;Age Range\u0026#39;) #fig.tight_layout() plt.show() For people who bought, it appears that men and women\u0026rsquo;s shopping habit is quite different. For both men and women, they make purchases gradually until age 40. After age 40, both men and women tend to purchase more. After age 50, men purchase habits drop but women continue the trend.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # What salary range purchases more men_purchased=dataset[(dataset[\u0026#39;Purchased\u0026#39;]==1)\u0026amp; (dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Male\u0026#39;) ][\u0026#39;EstimatedSalary\u0026#39;] female_purchased=dataset[(dataset[\u0026#39;Purchased\u0026#39;]==1)\u0026amp; (dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Female\u0026#39;) ][\u0026#39;EstimatedSalary\u0026#39;] n_bins = 12 fig, axs = plt.subplots(2,1, sharey=True) # We can set the number of bins with the `bins` kwarg #plt.title(\u0026#39;Men Vs women Salary Range Purchase\u0026#39;) axs[0].hist(men_purchased, bins=n_bins,orientation =\u0026#39;vertical\u0026#39; ) axs[0].set_ylabel(\u0026#39;Men Purchases\u0026#39;) axs[1].hist(female_purchased, bins=n_bins,orientation =\u0026#39;vertical\u0026#39;) axs[1].set_ylabel(\u0026#39;Female Purchases\u0026#39;) axs[1].set_xlabel(\u0026#39;Salary Range\u0026#39;) #fig.tight_layout() plt.show() Salary Range purchases are more interesting. Men\u0026rsquo;s and women\u0026rsquo;s purchases keep dropping from 19000 - 50000. Women\u0026rsquo;s purchases continue to increase from 75000 and upwards. Men\u0026rsquo;s purchases remain pretty stale beyond 70000 and upwards.\nSet up Training and Test Data 1 2 3 4 # Set up training and test data x=dataset.iloc[:,1:4].values y=dataset.iloc[:,4:5].values x[1:5] 1 2 3 4 array([[\u0026#39;Male\u0026#39;, 35, 20000], [\u0026#39;Female\u0026#39;, 26, 43000], [\u0026#39;Female\u0026#39;, 27, 57000], [\u0026#39;Male\u0026#39;, 19, 76000]], dtype=object) The dataset has a categorical field sex = {Male, Female}. Before we proceed to train the model, let\u0026rsquo;s encode the dataset.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #Adding the logistic regression from sklearn.preprocessing import OneHotEncoder, LabelEncoder from sklearn.compose import ColumnTransformer transformer = ColumnTransformer( transformers=[ (\u0026#34;Gender\u0026#34;, # Just a name OneHotEncoder(categories=\u0026#39;auto\u0026#39;), # The transformer class [0] # The column(s) to be applied on. ) ], remainder=\u0026#39;passthrough\u0026#39; ) x= transformer.fit_transform(x) x 1 2 3 4 5 6 7 array([[0.0, 1.0, 19, 19000], [0.0, 1.0, 35, 20000], [1.0, 0.0, 26, 43000], ..., [1.0, 0.0, 50, 20000], [0.0, 1.0, 36, 33000], [1.0, 0.0, 49, 36000]], dtype=object) Now you can see that Male has been set to 0,1 and Female as 1,0.\nNext, we split the data in tp train and test data. Here we are splitting into 75:25 ratio. The random_state is set to 10, which means that every 10th row will be set to train and test.\n1 2 3 #Split into training and test data from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=10) Next, we will standardize the value across the dataset. Standardized scaling is an important step here because as you will see the age range is between 1-100, while salary is in the 1000\u0026rsquo;s and sex is either 0 or 1.\n1 2 from sklearn.linear_model import LogisticRegression from sklearn.preprocessing import StandardScaler 1 2 3 sc = StandardScaler() X_train = sc.fit_transform(X_train) X_test = sc.transform(X_test) 1 X_train 1 2 3 4 5 6 7 array([[-1.06191317, 1.06191317, -0.93894518, 0.26049952], [ 0.94169658, -0.94169658, -0.93894518, 0.43327002], [ 0.94169658, -0.94169658, 0.3177076 , 0.05893394], ..., [-1.06191317, 1.06191317, -0.84227958, 0.2892946 ], [ 0.94169658, -0.94169658, 0.1243764 , -0.25781198], [ 0.94169658, -0.94169658, 0.4143732 , 1.09555693]]) Now you can see that each column has been standardized and scaled. Next, we need to define our regression class.\n1 2 lr = LogisticRegression(random_state=3, solver = \u0026#39;lbfgs\u0026#39;,\\ multi_class=\u0026#39;auto\u0026#39;).fit(X_train, y_train.ravel()) 1 y_pred = lr.predict(X_test) After training our Logistics Regression, we tested it against the test data to see what are values predicted for untrained data from the test.\nNext, we need to see our accuracy and look at the Confusion matrix\n1 2 3 from sklearn.metrics import accuracy_score, confusion_matrix print(\u0026#39;Accuracy: \\n\u0026#39; , accuracy_score(y_test,y_pred)) print(\u0026#39;Confusion Matrix:\\n\u0026#39; ,confusion_matrix(y_test,y_pred)) Accuracy: 0.9 Confusion Matrix: [[64 5] [ 5 26]]m And with this, we can see that our accuracy is 91% and 10 items (5 False Positive and 5 False Negative) were incorrect predictions\n","description":"Machine learning tutorial using Logistics regression. This post in the machine learning series will walk you through the process of solving binary classification problems using python.","id":4,"section":"posts","tags":null,"title":"Sick and tired of doing logistics regression the old way? read this","uri":"/2020/01/27/logistics-regression-using-python/"},{"content":" Part -1: How to pre-process and clean up data Part 2: Simple linear regression Part 3: Undesrtanding the P-Value Part 4: Multiple Linear Regression using machine learning Part 5: Backward elimination strategy Part 6: Support vector regression Part 7: Regression using Decision Tree algorithm Part 8: Logistics regression ","description":"","id":5,"section":"talks","tags":[null],"title":"Machine Learning Series","uri":"/talks/series/"},{"content":"In the previous post, we learnt about Support vector regression. In this post, we will see a new way of deciphering information using a simple format of traversing conditions.\nBusiness Goal: Can you spot the king? The people of Falkland are scared. Their king disguises as a common man and roams among them to gain knowledge about his kingdom and see if his policies are working in his kingdom. When the king is disguised, the common people don\u0026rsquo;t recognize him. If they accidentally mistreat the king when he is disguised, they get punished. Can you help the people of Falkland spot the king?\nHow to get dataset? Decision Tree dataset Decision tree notebook What is a \u0026ldquo;Decision Tree\u0026rdquo;\u0026rsquo;\u0026quot;? A Decision tree builds regression or classification models in the form of tree structure. It is a set of \u0026lsquo;yes\u0026rsquo; or \u0026rsquo;no\u0026rsquo; flow, which cascades downward like an upside down tree. For example, given a set of independent variables or features about a person, can we find if the person is healthy.\nParts of decision Tree Each decision point is called a Node. Ex - Age \u0026lt; 30 Each connector is called an Edge. Each node which does not have any subnode is called a Leaf. Ex - Fit or Unfit!. How is the tree built? To build a tree, we need to start with an Independent Feature as a root node. The possible attributes or unique values of that feature form the edges. Once the first level of the tree is completed, attach another feature node at the end of each node and traverse deeper. Once you have exhausted all the features, you will arrive at the dependent value or result.\nCan we just start with any random feature as the root node? This is a million $$$ question here. This is the meat of the whole algorithm. Let\u0026rsquo;s look at our business problem about the problem that people of Falkland are facing. We need to come up with a solution to spot the king when he is disguised to save the common man from mistreating him accidentally and hence punished in return. Here\u0026rsquo;s the data that we have collected about people leaving the castle.\nOk! So we have the data, but how do we find out which feature will be the root node?\nGoing back to our previous post on Backward Elimination, we can gather that the root node should be a feature which is the most important feature in making the decision. To find the most important feature, we will align each independent feature with dependent feature (Is_King).\nIf we look at the above mapping, we will see that Gold_Tooth feature is right most of the time in predicting the king, followed by the castle as it has the least number of false positive.\nWell, that\u0026rsquo;s good to know, but I noticed that you did talk about the last two features - Greedy and Slow.\nYes, the distinction between the two is difficult to figure out. Both Greedy and Slow features have an equal number of false positives. To understand, which feature is more important than the other, we need to understand Data Entropy_.\nWhat is Data Entropy? Entropy means how many times information changed that we got a positive result. Imagine if the king never left the castle, which means that all the information that we collected will show Is_King as 0. In our case, the entropy is 1 because anybody could be the king. If we just had Castle as the feature, predicting the king would be difficult without another piece of information.\nSo in simple terms Entropy is how many pieces of the data point(Independent feature) is required, to guess the Dependent variable - Is_King__\nTo further explain. Let\u0026rsquo;s say that instead of starting with Gold_tooth as the root node, we start with the castle. We will see that we are able to find the king only 3/10 times. On top of that, the left side gives very poor results. Just 1/5 or 20%.\nThere is another problem with the above tree. It is too overcomplicated and is overfitted. If we get new data the accuracy of our model could fall drastically.\nGoing back to our learning in the earlier post, the simpler model should be preferred over the complicated model to avoid overfitting.\nHow to avoid overfitting in decision Tree? Just remember the 3 golden rules to avoid overfitting:\nUse a smaller number of data points to build the tree. Ex - 10% of data points is a good place to build a generic model.\nDo not go overboard with the depth of the tree. A tree depth should only be increased if there is a significant improvement in the prediction.\nStop, if the number of data points at the split is less than 5%.\nHere\u0026rsquo;s a refined version of the tree.\nWould this model work on non-categorical or continuous values? Absolultely!! The splitting rules would still apply as I mentioned above.\nSo each Split is a leaf node above. Imagine if we wanted to find the dependent variable Y whose independent partners X1 and X2 are 10 and 150, then it would land in the first node as 300.5.\nI get why it landed in first leaf node position but where did we get value 300.5?\nThe value 300.5 is the average of all the data points in that box.\nPay attention and read the previous 2 lines again. The last two lines will help you understand why we need to divide it into different leaves and nodes. If you do not have splits, then the only option is to take the average of the ALL the data points!! The accuracy would be nowhere close to your expectation and would be same all values of X1 and X2.\nPython Implementation We are going to take a standard dataset called IRIS Dataset\n“The Iris flower dataset or Fisher’s Iris dataset is a multivariate dataset introduced by the British statistician and biologist Ronald Fisher in his 1936 paper ‘The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis’.” — Wikipedia\nIn layman terms, it is a set of data points about IRIS flower where we have the information about the length and the width of sepals and petals about 3 varieties.\nStep 1: Get the common imports\n1 2 3 4 5 6 # Importing the libraries import numpy as np import matplotlib.pyplot as plt import pandas as pd from sklearn.tree import DecisionTreeClassifier dataset = pd.read_csv(\u0026#34;iris.csv\u0026#34;) Step 2: Identify the missing data\n1 dataset.isnull().any() sepal-length False sepal-width False petal-length False petal-width False species False dtype: bool Step 3: Describe the data and identify the data types\n1 dataset.describe() sepal-length sepal-width petal-length petal-width count 150.000000 150.000000 150.000000 150.000000 mean 5.843333 3.054000 3.758667 1.198667 std 0.828066 0.433594 1.764420 0.763161 min 4.300000 2.000000 1.000000 0.100000 25% 5.100000 2.800000 1.600000 0.300000 50% 5.800000 3.000000 4.350000 1.300000 75% 6.400000 3.300000 5.100000 1.800000 max 7.900000 4.400000 6.900000 2.500000 1 dataset.dtypes sepal-length float64 sepal-width float64 petal-length float64 petal-width float64 species object dtype: object Step 4: Load the Iris data and create the X and Y variables\n1 2 3 X= dataset.iloc[0:, 0:4].values Y = dataset.iloc[:,4] Step 5: Plot the data\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 ##Get the dataset for each of the three species setosa=dataset[dataset[\u0026#39;species\u0026#39;]==\u0026#39;Iris-setosa\u0026#39;] versicolor =dataset[dataset[\u0026#39;species\u0026#39;]==\u0026#39;Iris-versicolor\u0026#39;] virginica =dataset[dataset[\u0026#39;species\u0026#39;]==\u0026#39;Iris-virginica\u0026#39;] #Create an empty figure with two windows pf size 21 by 10 plt.figure() fig,ax=plt.subplots(1,2,figsize=(21, 10)) #Plot each species using Sepal length and width on x-y axis setosa.plot(x=\u0026#34;sepal-length\u0026#34;, y=\u0026#34;sepal-width\u0026#34;, kind=\u0026#34;scatter\u0026#34;,ax=ax[0],label=\u0026#39;setosa\u0026#39;,color=\u0026#39;r\u0026#39;) versicolor.plot(x=\u0026#34;sepal-length\u0026#34;,y=\u0026#34;sepal-width\u0026#34;,kind=\u0026#34;scatter\u0026#34;,ax=ax[0],label=\u0026#39;versicolor\u0026#39;,color=\u0026#39;b\u0026#39;) virginica.plot(x=\u0026#34;sepal-length\u0026#34;, y=\u0026#34;sepal-width\u0026#34;, kind=\u0026#34;scatter\u0026#34;, ax=ax[0], label=\u0026#39;virginica\u0026#39;, color=\u0026#39;g\u0026#39;) #Plot each species using Petal length and width on x-y axis setosa.plot(x=\u0026#34;petal-length\u0026#34;, y=\u0026#34;petal-width\u0026#34;, kind=\u0026#34;scatter\u0026#34;,ax=ax[1],label=\u0026#39;setosa\u0026#39;,color=\u0026#39;r\u0026#39;) versicolor.plot(x=\u0026#34;petal-length\u0026#34;,y=\u0026#34;petal-width\u0026#34;,kind=\u0026#34;scatter\u0026#34;,ax=ax[1],label=\u0026#39;versicolor\u0026#39;,color=\u0026#39;b\u0026#39;) virginica.plot(x=\u0026#34;petal-length\u0026#34;, y=\u0026#34;petal-width\u0026#34;, kind=\u0026#34;scatter\u0026#34;, ax=ax[1], label=\u0026#39;virginica\u0026#39;, color=\u0026#39;g\u0026#39;) #Give Each figure its names ax[0].set(title=\u0026#39;Sepal comparasion \u0026#39;, ylabel=\u0026#39;sepal-width\u0026#39;) ax[1].set(title=\u0026#39;Petal Comparasion\u0026#39;, ylabel=\u0026#39;petal-width\u0026#39;) ax[0].legend() ax[1].legend() #Show the plot plt.show() \u0026lt;Figure size 432x288 with 0 Axes\u0026gt; Step 6: Encode the value of Flower types\nThe values of dependent the variable needs to be encoded to numbers as they are categorical values\n1 2 3 from sklearn.preprocessing import LabelEncoder labelEncoder_y = LabelEncoder() Y = labelEncoder_y.fit_transform(Y) Step 7: Split the data in training and test set\n1 2 from sklearn.model_selection import train_test_split x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=0) Step 8: Train the Decision Tree model\n1 2 3 from sklearn.tree import DecisionTreeRegressor regressor = DecisionTreeRegressor(random_state=0) regressor.fit(x_train, y_train) DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=0, splitter='best') Step 9: Predict and score the model\n1 2 3 y_predict=regressor.predict(x_test) print(regressor.score(x_test,y_test)) 1.0 Wow! Did we just predict that our model is correct 100% of the time?\nThe reason the accuracy is showing 100% is that our model is too complex as we did not define the maximum depth of tree and hence we broke a cardinal rule. Let\u0026rsquo;s take a look at the created tree.\n1 2 3 4 5 6 7 8 9 10 from sklearn.externals.six import StringIO from IPython.display import Image from sklearn.tree import export_graphviz import pydotplus from sklearn import tree dot_data = StringIO() tree.export_graphviz(regressor, out_file=dot_data) graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) Image(graph.create_png()) As you can see, that since we did not provide a maximum depth of the tree, it created a complex tree of 6 layers and hence for our model we are getting 100% accuracy. This means that the model is an overfitted model.\nLet\u0026rsquo;s fix this by creating a simpler model.\n1 2 3 4 5 6 7 #Creating a model that is only 2 layers deep by setting max_depth=3 regressor = DecisionTreeRegressor(random_state=0,criterion=\u0026#39;mse\u0026#39;, splitter=\u0026#39;best\u0026#39;, max_depth=3, min_samples_split=3, min_samples_leaf=2 ) regressor.fit(x_train, y_train) y_predict=regressor.predict(x_test) print(regressor.score(x_test,y_test)) 0.9739827477382705 As you can see that the model is not an overfit anymore and still gives us pretty good accuracy of 97.4%.\nLooking at the decision tree now.\n1 2 3 4 5 6 7 8 9 10 11 12 from sklearn.externals.six import StringIO from IPython.display import Image from sklearn.tree import export_graphviz import pydotplus from sklearn import tree dot_data = StringIO() tree.export_graphviz(regressor, out_file=dot_data) graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) Image(graph.create_png()) ![tree_fix.PNG](/images/decision/tree_fix.PNG) So keep climbing the tree of success with this DecisionTree regression model. In the next series, we will see how to use a kind of decision tree called Random forest regression.\n","description":"Machine learning tutorial using decision tree regression. This post in the machine learning series will walk you through the process of implementing decision tee regression using python.","id":6,"section":"posts","tags":null,"title":"Part 7 Decision tree regression or classification using python","uri":"/2019/03/02/decision-tree-using-python/"},{"content":"This website is collection of random technical topics. Most of these are issues that I come across at my work and this place serve as future reference for the solutions.\n","description":"A Morsel Of Code - One Byte At A Time","id":7,"section":"","tags":null,"title":"About","uri":"/about/"},{"content":"Business Goal: As an owner of MuShu Bike Rental CO. in New York. I want to know how many bicycles will be rented on any given day based on daily temperature, humidity and wind speed. Can you help MuShu Bike Rental CO. to predict the number of daily rentals?\nHow to get the dataset? Startup Dataset Support vector Regression notebook Let\u0026rsquo;s solve this problem using SVR - Support Vector Regression.\nBefore we begin, let\u0026rsquo;s see the key terms that will be used.\nKey terms Kernel A fancy word for the function used to map a lower dimension data into higher dimension data.\nHyper Plane This is a line that helps us predict the target values.\nBoundary Line There are two boundary lines which separate the classes. The support vectors can be on the boundary line or outside the boundary line.\nSupport Vectors Support vectors are the data points which are closest to the boundary line.\nWhat is a SVR model? In Simple/multiple regression we try to minimize the errors while in SVR, we try to fit the error within a threshold.\nBlue Line: Hyper Plane | Red Line: Boundary lines\nLooking at the above figure, our goal is to have the data points inside the boundary lines and hyperplane with the maximum number of data points.\nWhat is \u0026ldquo;Boundary again? The red lines that you see in the diagram above are called boundary lines. These lines are at equidistant from a hyper plane (Blue line). So basically, if one boundary line is at distance \u0026ldquo;e\u0026rdquo; distance from a hyper plane the other would be at distance of \u0026quot;-e\u0026rdquo;.\nIn mathematical equation.\nIf the hyper plane line is a straight line going through Y-AXIS and represented as\nmX + C =0\nThen the equation of boundary lines can be represented as\nmX + C = e\nmx +C = -e\nThe final equation of SVR can be represented as\ne≤ y-mx-c ≤+e\nTo summarize: The goal so far is to find the distance value e which is equidistant from hyper plane line with the maximum data points OR that they are inside the Boundary line.\nExploring the dataset 1 2 3 4 5 6 import numpy as np import pandas as pd import matplotlib.pyplot as plt ##Import the datset dataset = pd.read_csv(\u0026#39;BikeRental/bike_rental_train.csv\u0026#39;) 1 dataset.head() temp humidity windspeed bike_rent_count 0 9.02 80 0.0000 40 1 9.02 80 0.0000 32 2 9.84 75 0.0000 13 3 9.84 75 0.0000 1 4 9.84 75 6.0032 1 1 dataset.describe().T count mean std min 25% 50% 75% max temp 9801.0 20.230348 7.791740 0.82 13.9400 20.500 26.2400 41.0000 humidity 9801.0 61.903989 19.293371 0.00 47.0000 62.000 78.0000 100.0000 windspeed 9801.0 12.836534 8.177168 0.00 7.0015 12.998 16.9979 56.9969 bike_rent_count 9801.0 191.334864 181.048534 1.00 42.0000 145.000 283.0000 977.0000 1 dataset.columns Index(['temp', 'humidity', 'windspeed', 'bike_rent_count'], dtype='object') 1 plt.scatter( dataset.temp, dataset.bike_rent_count, c=\u0026#39;green\u0026#39;); 1 plt.scatter( dataset.humidity,dataset.bike_rent_count); 1 plt.scatter( dataset.windspeed, dataset.bike_rent_count); Summary\nBased on data description and histogram plot.\nTemp Range = 0 to 41 Humidity Range = 0 to 100 Windspeed = 0 to 57 1 dataset.corr(method=\u0026#39;pearson\u0026#39;, min_periods=1) temp humidity windspeed bike_rent_count temp 1.000000 -0.060524 -0.020792 0.393114 humidity -0.060524 1.000000 -0.317602 -0.312835 windspeed -0.020792 -0.317602 1.000000 0.096836 bike_rent_count 0.393114 -0.312835 0.096836 1.000000 Summary\nLooking at the correlation matrix, we see that there is a positive relationship between temperature and bike_rent_count Humidity has a negative effect on bike_rent_count. Higher the humidity, lower the number of rentals Windspeed has little effect on bike_rent_count.\nLooking at the correlation matrix, it confirms the visuals that bike count rental has a weak correlation with all of the 3 variables. What does a weak correlation mean?\nIt means that the equation of the model that we are going to plot is probably not going to give very accurate results. However, the goal of this post is to show you how to implement SVR.\nSo Let\u0026rsquo;s bring out our template from our first post on data pre-processing.\nStep 1: Let\u0026rsquo;s break the data into Dependent and Independent variable\n1 2 3 ### Break up in dependent and Independent variables X = dataset.iloc[:, 0:3].values y = dataset.iloc[:, 3].values Step 2 : Break the data into train and test set\n1 2 3 # Splitting the dataset into the Training set and Test set from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0) Step 3: Feature scaling. This step is required here beacause SVR library does not do feature scaling.\n1 2 3 4 5 6 7 # Feature Scaling from sklearn.preprocessing import StandardScaler sc_X = StandardScaler() X_train = sc_X.fit_transform(X_train) X_test = sc_X.transform(X_test) #sc_y = StandardScaler() #y_train = sc_y.fit_transform(y_train) Step 4: Create a Regressor and fit the model\n1 2 3 4 5 6 # Fitting the SVR Model to the dataset from sklearn.svm import SVR # Create your regressor here regressor = SVR(kernel=\u0026#39;linear\u0026#39;) regressor.fit(X_train,y_train) SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto_deprecated', kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False) In the above code, we are using the SVR class for fitting the model.\nSVR(\n[\u0026ldquo;kernel=\u0026lsquo;rbf\u0026rsquo;\u0026rdquo;, \u0026lsquo;degree=3\u0026rsquo;, \u0026ldquo;gamma=\u0026lsquo;auto_deprecated\u0026rsquo;\u0026rdquo;, \u0026lsquo;coef0=0.0\u0026rsquo;, \u0026rsquo;tol=0.001\u0026rsquo;, \u0026lsquo;C=1.0\u0026rsquo;, \u0026rsquo;epsilon=0.1\u0026rsquo;, \u0026lsquo;shrinking=True\u0026rsquo;, \u0026lsquo;cache_size=200\u0026rsquo;, \u0026lsquo;verbose=False\u0026rsquo;, \u0026lsquo;max_iter=-1\u0026rsquo;],\n)\nThe SVR model that we are using provides 4 types of Kernel - rbf, linear, poly, sigmoid. In our case, we are using linear since data appears to be linear based on visualizations. Another interesting attribute is verbose, which when set to true will show you the default values used of other attributes.\nStep 5: Predict the bike count based on test data\n1 2 # Predicting a new result y_pred = regressor.predict(X_test) Step 6: Check the model effeciency\n1 2 print(\u0026#39;Train Score: \u0026#39;, regressor.score(X_train, y_train)) print(\u0026#39;Test Score: \u0026#39;, regressor.score(X_test, y_test)) Train Score: 0.19926232721567205 Test Score: 0.2082800818663224 As mentioned earlier, since the correlation is weak, we can see that our model is extremely weak. One thing to note here is that I downloaded this random dataset from some website. So when I was working on SVR, I was not sure if the data is true or not.\nLet\u0026rsquo;s try the tweaking SVR model a little to see if we can do better.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Create your regressor here regressor = (SVR(kernel=\u0026#39;poly\u0026#39;, shrinking=True, degree=7, gamma=\u0026#39;scale\u0026#39;, epsilon = 0.01, coef0 =1.60 )) regressor.fit(X_train,y_train) # Predicting a new result y_pred = regressor.predict(X_test) print(\u0026#39;Train Score: \u0026#39;, regressor.score(X_train, y_train)) print(\u0026#39;Test Score: \u0026#39;, regressor.score(X_test, y_test)) Train Score: 0.25167703525198526 Test Score: 0.2484248213345378 So after playing around with different option and values, you will see that if you use poly or polynomial kernel, I was able to push the model prediction to 25.xx%.\nSo that\u0026rsquo;s it for this series. Try a different dataset, probably get one from the Multiple Linear regression about 50_Startups and predict using linear kernel.\nIn the next series, we will learn about our first ever classification model - Decision Trees. Till then happy Happy hyper-planing\n","description":"Machine learning tutorial using Support vector regression. This post in the machine learning series will walk you through the process of implementing Support vector Regression.","id":8,"section":"posts","tags":null,"title":"Part 6 Support Vector Regression","uri":"/2019/02/10/part-6-ml-svr/"},{"content":"In the previous post, we learnt about multiple linear regression. The problem with the last approach was that we used all the features without considering that some of the features may not be impacting or playing any role in the outcome. we also talked about 5 ways of reducing the noisy feature. Backward elimination is one of them.\nHow to get the dataset? Startup Dataset Multiple Regression notebook What is Backward Elimination? Backward elimination is a process to remove features that have little effect on the dependent variable.\nWhat could possibly be wrong with leaving the features if they are not impacting or have little impact? New England Patriots won the Superbowl on Feb 3, 2019. The team won because it had a better team, better skills and a good coach. If I say, the team also won because Patriots fans are great at cheering and that when Patriots play fans supporting the opposition is more tamed, then I would be wrong. If I say that all players in the team wore a white jersey and they won. They also won because they played it on Sunday and T. Brady thinks that it\u0026rsquo;s his luckiest day. You would call Baloney to all the facts that I just mentioned. It may have helped - may be slightly but too insignificant to make a real difference. The features in a data set are exactly that - Baloney. They only add noise in the actual model and many small non-significant data may actually provide us a model which is way off the margin. The simpler the model, the better the result.\nHow do we implement Backward elimination? In backward elimination, you take all the variables and create the algorithm. Select a significance level, then consider the predictor with Highest P-value and if P-Value \u0026gt; Significance level then eliminate the variable from the equation, else keep it.\nHow do we implement it in python? In the previous post, we were trying to figure out if a company is profitable or not by looking at 4 independent variables - R\u0026amp;D Spent, Administration cost, Market spending \u0026amp; State. We created a model with all the features. So let\u0026rsquo;s pick up from where we left off. Here\u0026rsquo;s how our dataset looks like\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 import numpy as np import matplotlib.pyplot as plt import pandas as pd #Read the dataset dataset = pd.read_csv(\u0026#34;50_Startups.csv\u0026#34;) #Divide the dataset in dependent and Independent variables X= dataset.iloc[:, :-1].values y = dataset.iloc[:, -1].values #Taking care of Categorical values. from sklearn.preprocessing import OneHotEncoder, LabelEncoder label_encoder = LabelEncoder(); X[:,3]=label_encoder.fit_transform(X[:, 3]) oneHotEncoder = OneHotEncoder(categorical_features=[3]) X= oneHotEncoder.fit_transform(X).toarray() #getting out of dummy variable trap X = X[:,1:] # Select all the rows and all the columns starting fom index 1 onwards. #Create training and test set from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, train_size=0.80, random_state=0) #Check for missing data null_columns=dataset.columns[dataset.isnull().any()] t = dataset[null_columns].isnull().sum() #Training the model from sklearn.linear_model import LinearRegression regressor = LinearRegression() regressor.fit(X_train, y_train) # Predicting the results of the training set y_pred = regressor.predict(X_test) print(regressor.coef_) print(regressor.intercept_) print(\u0026#39;Train Score: \u0026#39;, regressor.score(X_train, y_train)) print(\u0026#39;Test Score: \u0026#39;, regressor.score(X_test, y_test)) [-9.59284160e+02 6.99369053e+02 7.73467193e-01 3.28845975e-02 3.66100259e-02] 42554.16761772438 Train Score: 0.9501847627493607 Test Score: 0.9347068473282446 Take note of Train Score and Test Score\nTrain Score: 0.9501847627493607\nTest Score: 0.9347068473282446\nThe difference between them is 0.01547791542 or 1.548%\nSo far we used all the features. Now to use backward elimination we will use an entirely new package and class. However, before we begin, we need to decide on a significance level. In this case, let\u0026rsquo;s chose a level equal o 0.05.\n1 2 3 4 import statsmodels.formula.api as smf #Appending ones for constants X = np.append(arr=np.ones((50,1)).astype(int), values=X, axis=1) Why did we append 1\u0026rsquo;s in the existing dataset? Y = b0X0 + b1X1+ b2X2 + b3X3 + b4X4 + b5X5 + C\nIn the above equation, if you notice that every Xn has a multiplier bn but not the constant C. Actually if you have a X6 and set it to 1 that solves the problem. The question is why do we need a 1 multiplier for the constant. The answer lies in the library and the class that we use. The package statsmodel only considers a multiplier if it has a feature value. If there is no feature value then it would not get picked up while creating the model. So the C would be dropped. Hence we need to create a feature with value = 1.\n1 2 3 4 ##Creating a model with all varibales x_opt = X[:,[0,1,2,3,4,5]] regressor_OLS = smf.OLS(endog=y, exog=x_opt).fit() print(regressor_OLS.summary()) OLS Regression Results ============================================================================== Dep. Variable: y R-squared: 0.951 Model: OLS Adj. R-squared: 0.945 Method: Least Squares F-statistic: 169.9 Date: Sun, 10 Feb 2019 Prob (F-statistic): 1.34e-27 Time: 22:42:26 Log-Likelihood: -525.38 No. Observations: 50 AIC: 1063. Df Residuals: 44 BIC: 1074. Df Model: 5 Covariance Type: nonrobust ============================================================================== coef std err t P\u0026gt;|t| [0.025 0.975] ------------------------------------------------------------------------------ const 5.013e+04 6884.820 7.281 0.000 3.62e+04 6.4e+04 x1 198.7888 3371.007 0.059 0.953 -6595.030 6992.607 x2 -41.8870 3256.039 -0.013 0.990 -6604.003 6520.229 x3 0.8060 0.046 17.369 0.000 0.712 0.900 x4 -0.0270 0.052 -0.517 0.608 -0.132 0.078 x5 0.0270 0.017 1.574 0.123 -0.008 0.062 ============================================================================== Omnibus: 14.782 Durbin-Watson: 1.283 Prob(Omnibus): 0.001 Jarque-Bera (JB): 21.266 Skew: -0.948 Prob(JB): 2.41e-05 Kurtosis: 5.572 Cond. No. 1.45e+06 ============================================================================== Based on the process, we now have to find the feature with the highest P-value and if it greater than ould SL then we will drop it. In this case\nx2 has the highest P-value = 0.990 \u0026gt; 0.05.\nSo will drop the feature x2 which corresponds to the State dummy variable\nWe will continue and re-run the model with just 5 feature\n1 2 3 4 ## Removing index 2 as P\u0026gt;0.05 and is the highest P x_opt = X[:,[0,1,3,4,5]] regressor_OLS = smf.OLS(endog=y, exog=x_opt).fit() print(regressor_OLS.summary()) OLS Regression Results ============================================================================== Dep. Variable: y R-squared: 0.951 Model: OLS Adj. R-squared: 0.946 Method: Least Squares F-statistic: 217.2 Date: Sun, 10 Feb 2019 Prob (F-statistic): 8.49e-29 Time: 22:52:32 Log-Likelihood: -525.38 No. Observations: 50 AIC: 1061. Df Residuals: 45 BIC: 1070. Df Model: 4 Covariance Type: nonrobust ============================================================================== coef std err t P\u0026gt;|t| [0.025 0.975] ------------------------------------------------------------------------------ const 5.011e+04 6647.870 7.537 0.000 3.67e+04 6.35e+04 x1 220.1585 2900.536 0.076 0.940 -5621.821 6062.138 x2 0.8060 0.046 17.606 0.000 0.714 0.898 x3 -0.0270 0.052 -0.523 0.604 -0.131 0.077 x4 0.0270 0.017 1.592 0.118 -0.007 0.061 ============================================================================== Omnibus: 14.758 Durbin-Watson: 1.282 Prob(Omnibus): 0.001 Jarque-Bera (JB): 21.172 Skew: -0.948 Prob(JB): 2.53e-05 Kurtosis: 5.563 Cond. No. 1.40e+06 ============================================================================== Once again in the above output\nx1 has the highest P-value = 0.940 \u0026gt; 0.05\nSo we will drop X1, which in this case represents the second dummy variable for the State.\nSo we will continue until we don\u0026rsquo;t have variable that is greater than our significance level\n1 2 3 4 ## Removing index 1 as P\u0026gt;0.05 and is the highest P x_opt = X[:,[0,3,4,5]] regressor_OLS = smf.OLS(endog=y, exog=x_opt).fit() print(regressor_OLS.summary()) OLS Regression Results ============================================================================== Dep. Variable: y R-squared: 0.951 Model: OLS Adj. R-squared: 0.948 Method: Least Squares F-statistic: 296.0 Date: Sun, 10 Feb 2019 Prob (F-statistic): 4.53e-30 Time: 22:59:29 Log-Likelihood: -525.39 No. Observations: 50 AIC: 1059. Df Residuals: 46 BIC: 1066. Df Model: 3 Covariance Type: nonrobust ============================================================================== coef std err t P\u0026gt;|t| [0.025 0.975] ------------------------------------------------------------------------------ const 5.012e+04 6572.353 7.626 0.000 3.69e+04 6.34e+04 x1 0.8057 0.045 17.846 0.000 0.715 0.897 x2 -0.0268 0.051 -0.526 0.602 -0.130 0.076 x3 0.0272 0.016 1.655 0.105 -0.006 0.060 ============================================================================== Omnibus: 14.838 Durbin-Watson: 1.282 Prob(Omnibus): 0.001 Jarque-Bera (JB): 21.442 Skew: -0.949 Prob(JB): 2.21e-05 Kurtosis: 5.586 Cond. No. 1.40e+06 ============================================================================== 1 2 3 4 ## Removing index 1 as P\u0026gt;0.05 and is the highest P x_opt = X[:,[0,3,5]] regressor_OLS = smf.OLS(endog=y, exog=x_opt).fit() print(regressor_OLS.summary()) OLS Regression Results ============================================================================== Dep. Variable: y R-squared: 0.950 Model: OLS Adj. R-squared: 0.948 Method: Least Squares F-statistic: 450.8 Date: Sun, 10 Feb 2019 Prob (F-statistic): 2.16e-31 Time: 22:59:39 Log-Likelihood: -525.54 No. Observations: 50 AIC: 1057. Df Residuals: 47 BIC: 1063. Df Model: 2 Covariance Type: nonrobust ============================================================================== coef std err t P\u0026gt;|t| [0.025 0.975] ------------------------------------------------------------------------------ const 4.698e+04 2689.933 17.464 0.000 4.16e+04 5.24e+04 x1 0.7966 0.041 19.266 0.000 0.713 0.880 x2 0.0299 0.016 1.927 0.060 -0.001 0.061 ============================================================================== Omnibus: 14.677 Durbin-Watson: 1.257 Prob(Omnibus): 0.001 Jarque-Bera (JB): 21.161 Skew: -0.939 Prob(JB): 2.54e-05 Kurtosis: 5.575 Cond. No. 5.32e+05 ============================================================================== 1 2 3 4 ## Removing index 1 as P\u0026gt;0.05 and is the highest P x_opt = X[:,[0,3]] regressor_OLS = smf.OLS(endog=y, exog=x_opt).fit() print(regressor_OLS.summary()) OLS Regression Results ============================================================================== Dep. Variable: y R-squared: 0.947 Model: OLS Adj. R-squared: 0.945 Method: Least Squares F-statistic: 849.8 Date: Sun, 10 Feb 2019 Prob (F-statistic): 3.50e-32 Time: 22:59:43 Log-Likelihood: -527.44 No. Observations: 50 AIC: 1059. Df Residuals: 48 BIC: 1063. Df Model: 1 Covariance Type: nonrobust ============================================================================== coef std err t P\u0026gt;|t| [0.025 0.975] ------------------------------------------------------------------------------ const 4.903e+04 2537.897 19.320 0.000 4.39e+04 5.41e+04 x1 0.8543 0.029 29.151 0.000 0.795 0.913 ============================================================================== Omnibus: 13.727 Durbin-Watson: 1.116 Prob(Omnibus): 0.001 Jarque-Bera (JB): 18.536 Skew: -0.911 Prob(JB): 9.44e-05 Kurtosis: 5.361 Cond. No. 1.65e+05 ============================================================================== So in the end, we find that only the C constant and the R\u0026amp;D Spending are really the important or most significant feature to find out if we should invest in the new business venture.\nHow do I believe you that by just keeping R\u0026amp;D feature, will improve our model accuracy? Let\u0026rsquo;s recalculate our model using the Linear Regression library and find the difference between accuracy score\n1 2 3 4 5 6 7 8 9 10 11 import numpy as np import matplotlib.pyplot as plt import pandas as pd #Read the dataset dataset = pd.read_csv(\u0026#34;50_Startups.csv\u0026#34;) #Divide the dataset in dependent and Independent variables X= dataset.iloc[:, 0].values ##Get the R\u0026amp;D score only y = dataset.iloc[:, -1].values 1 2 3 4 5 6 7 #Create training and test set from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, train_size=0.80, random_state=0) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #Training the model from sklearn.linear_model import LinearRegression regressor = LinearRegression() regressor.fit(np.array(X_train).reshape(-1,1), y_train) # Predicting the results of the training set y_pred = regressor.predict(np.array(X_test).reshape(-1,1)) print(regressor.coef_) print(regressor.intercept_) print(\u0026#39;Train Score: \u0026#39;, regressor.score(np.array(X_train).reshape(-1,1), y_train)) print(\u0026#39;Test Score: \u0026#39;, regressor.score(np.array(X_test).reshape(-1,1), y_test)) [0.8516228] 48416.297661385026 Train Score: 0.9449589778363044 Test Score: 0.9464587607787219 Let\u0026rsquo;s look at the Train score and Test Score with all the feature and with just R\u0026amp;D spending.\nWith all Features\nTrain Score: 0.9501847627493607 \u0026amp; Test Score: 0.9347068473282446\nDifference = 0.01547791542 or 1.548%\nWith just R\u0026amp;D spending feature\nTrain Score: 0.9449589778363044 \u0026amp; Test Score: 0.9464587607787219\nDifference = 0.0014997829424 or 0.150%\nAlso the if you see that the test score has improved when from 93.6% to 94.6%.\nHopefully, you enjoyed this series. In the next series, we will look at slightly more interesting topic called SVMs or Support Vector Regression.\n","description":"Machine learning tutorial using multiple linear regression. This post in the machine learning series will walk you through the process of automatic backward elimination and show you to improve your multiple regression model and teach you an important concept that simple is always better.","id":9,"section":"posts","tags":null,"title":"Part 5 Machine Learning Backward Elimination","uri":"/2019/02/10/part-5-ml-mltr-backward-elimination/"},{"content":"In the previous post, we learnt about a P-Value, a prerequisite for learning Multiple Linear Regression.\nBusiness Problem: In this series, we will take a look at a dataset of 50 startup companies.\nA venture capitalist has hired you as a data scientist and wants you to help him select which type of company he should invest so that he can make the most profit. You need to review spending on R\u0026amp;D, Admin cost, marketing cost and location to make the decision\nHow to get the dataset? Startup Dataset Multiple Regression notebook What is Multiple Linear Regression? In the second post on linear regression, our equation was simple and straight-forward\nY = mX + C\nwhere Y was the dependent variable, X was the dependent variable and c was the Y-intercept when X = 0. The reason the equation was simple because the Y was dependent on one variable only. If there were multiple variables affecting the value of Y, then what should it be called? - :-). You know the answer to that question.\nMultiple Linear Regression!!!\nThe equation would also be something as simple as that\nY = b0X0 + b1X1+b2X2+ \u0026hellip;. + C\nSteps to solve the problem? Step 1: Data pre-processing and analysis Take a closer look at dataset. You will notice that all the Independent Variables, except State, is numerical. The variable State is either California or New York. From our first post, you would know that this type of data is called categorical data. We should always convert categorical data into numerical data to avoid bias and find if there is collinearity between Profit and State. Collinearity is just a fancy way of asking - \u0026ldquo;Is there some relation between Profit and State?.\nWhen you convert a categorical data to numeric data, the new column is called Dummy Variable. So as we learned from our first post, we should convert it to a sparse matrix.\nQuestion\n*Do you need two columns to represent New York and California states?\nThe answer is No.\nIt is easy to derive from the above screenshot that if New York is 1 then California by default would be 0 and vice-versa. So this actually works like a switch which can have only 2 states 0 or 1.\nImportant tip: You should never use all of your dummy variables in your Regression column. They should always be 1 less than the number of values.\nIf we drop one dummy variable then are we not making this a biased equation\nWithout dropping column my equation would look like this\nY = b0X0 + b1X1+ b2X2 + b3X3 + b4X4 + b5X5 + C\nAfter Dropping one dummy variable\nY = b0X0 + b1X1+ b2X2 + b3X3 + b4X4 + C\nIf we dropped the variable then it may appear that when California is the state then the value of b4X4 will be 0, hence we lose one variable. In reality, the regression algorithm marks that the first dummy variable which is represented by 0 is set as default. So, the regression equation will never be biased. The regression equation is going to use constant C to adjust the value of California.\nBut what is wrong with using all the dummy variable?\nWhen you use both the values, your equation would be something\nY = b0X0 + b1X1+ b2X2 + b3X3 + b4X4 + b5X5 + C\nIf we do this then we will introduce multi-collinearity, where the algorithm will not be able to able to distinguish the effect on Price. This is because D2 is always equal to 1 - D1. The algorithm will then try to predict the effect of D2 over D1 and would think that there is a relation between Independent variable as well.\nStep 2: Understanding all possible methods to build a model using Multiple Linear Regression models There are 5 methods to build a model\n- All in one\n- Backward Elimination\n- Forward Selection\n- Bi-Directional Elimination\n- Score comparison\nAll In: All in means that you use all the variables when you know for sure that all the independent variables have a definite effect on the dependent variable. An example is that if doctors told you for sure that to live past 80 yrs of age, you should eat good food and exercise daily. In other words, you have domain expert telling you that all the variables directly affect the dependent variable.\nBackward elimination: In backward elimination, you take all the variables and create the algorithm. Select a significance level, then consider the predictor with Highest P-value and if P-Value \u0026gt; Significance level then eliminate the variable from the equation, else keep it.\nForward Selection: In forward selection, you start with linear regression using every single variable. You will end up with n simple linear equation. Next, you chose the one with the lowest P-Value. This is your starting equation. Y = m0X0. Next, you pick one variable again and create an equation with two variables and out of n-1 possibilities again chose the one with the lowest P-value. The process continues until we don\u0026rsquo;t have any variable that is lower than our selected Significance level.\nBi-Directional elimination: In bi-directional elimination, you chose 2 significance level. One to enter the equation and one to stay. You start with the forward selection using condition P-Value \u0026lt; SL Enter and then follow backward elimination using condition P-value \u0026lt; SLstay. You stop and declare the final equation when no new variable can enter or exit the equation.\nScore Comparison: In this model, you create all possible combination of the equation, compare the performance using say MSE(Mean Square Error) and use the one with the lowest MSE. That is an insane amount of possible equation. For Example - A model with 10 variables will have 1023 possible combination.\nNote for the purpose of brevity and sanity, we will be using Backward Elimination model to solve this problem. Also, because this model is fastest and we will still be able to see how the step by method works.\nStep 3: Data preprocessing in python We will now start the calculation using the process that we learnt in the first post of this series. If you remember from Linear regression post\n1 2 3 4 5 6 7 8 9 10 11 # -*- coding: utf-8 -*- import numpy as np import matplotlib.pyplot as py import pandas as pd #Read the dataset dataset = pd.read_csv(\u0026#34;50_Startups.csv\u0026#34;) #Divide the dataset in dependent and Independent variables X= dataset.iloc[:, :-1].values y = dataset.iloc[:, -1].values Next part of data processing is to find if there is any missing data. If there is missing data then we need to use Imputer to fix the missing data. To do that we will first check the data description, then try to get a count of missing values in the dataset\n1 2 3 4 5 6 #Describe the dataset pd.DataFrame.describe(dataset) #Check for missing data null_columns=dataset.columns[dataset.isnull().any()] num_emptycolumns = dataset[null_columns].isnull().sum() print(num_emptycolumns) Series([], dtype: float64) Currently, there are no missing values in the dataset hence the result of num_emptycolumns.\nMoving on to the next item in the data clean up is taking care of categorical values in the State column.\n1 2 3 4 5 6 #Taking care of Categorical values. from sklearn.preprocessing import OneHotEncoder, LabelEncoder label_encoder = LabelEncoder(); X[:,3]=label_encoder.fit_transform(X[:, 3]) oneHotEncoder = OneHotEncoder(categorical_features=[3]) X= oneHotEncoder.fit_transform(X).toarray() Hey, what about all the talk about keeping n-1 categorical items?\nSo you are right to notice that whatever we did will lead us directly to the dummy variable trap. I fell into one when I was trying to learn it. So how do we fix it? If you have been thinking about just crossing out one of the columns as we did in the pic few scrolls above \u0026hellip;\u0026hellip;. you are right!!! That\u0026rsquo;s exactly how we are going to fix it.\n1 2 #getting out of dummy variable trap X = X[:,1:] # Select all the rows and all the columns starting from index 1 onwards. Now divide the data in training and test set\n1 2 3 4 5 6 #Create training and test set from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, train_size=0.80, random_state=0) Step 4: Training the model\nNow that we have cleaned up our data, we can train our data. We are not going to do any feature scaling here, because the library and class that we are going to use, will do that automatically for us. We will use the same LineaRegression class that we used in the linear regression post.\n1 2 3 from sklearn.linear_model import LinearRegression regressor = LinearRegression() regressor.fit(X_train, y_train) The above code trained our data. Now we need to check how does our model score or how good is it at predicting the data?\nTo Predict we just need to call the predict function.\n1 y_pred = regressor.predict(X_test) You can see that the predicted values y-pred is pretty close to y_test. Some of the rows do have a significant difference and the numbers may look far apart but the others are pretty close. So how close are we? How confident are we that the trendline would fit closely. To answer this we need to look at our training and test score.\n1 2 print(\u0026#39;Train Score: \u0026#39;, regressor.score(X_train, y_train)) print(\u0026#39;Test Score: \u0026#39;, regressor.score(X_test, y_test)) Train Score: 0.9501847627493607 Test Score: 0.9347068473282446 The above score tells us that our model has 95% and 93.5% accurate for training and test data. This not bad.\nOne last thing that I learnt was that if someone asked me how do I calculate the future values that may come up? To do that we need to get the co-efficient and intercept of the regression equation. The regression equation as discussed earlier would look something like this -\nY = b0X0 + b1X1+ b2X2 + b3X3 + b4X4 + b5X5 + C\n1 2 print(regressor.coef_) print(regressor.intercept_) [-9.59284160e+02 6.99369053e+02 7.73467193e-01 3.28845975e-02 3.66100259e-02] 42554.16761772438 If we take the first row from X_test - 1\t0\t66051.5\t182646\t118148\n1*-9.59284160e+02 + 06.99369053e+02 + 66051.5 * 7.73467193e-01 + 1826463.28845975e-02 + 118148 * 3.66100259e-02 + 42554.16761772438\nThe output would be 103015.19329118208, which is same as first row of y_pred.\n1 1 * -9.59284160e+02 + 0 * 6.99369053e+02 + 66051.5 * 7.73467193e-01 + 182646 * 3.28845975e-02 + 118148 * 3.66100259e-02 + 42554.16761772438 103015.19329118208 So that is the most basic way to do to solve a problem using Multiple Linear regression. Hope you enjoyed this series. Stay tuned for the next series where we will actually see the continuation of Multiple Linear regression and learn the Backward Elimination process.\n","description":"Machine learning tutorial using multiple linear regression. This post in the machine learning series will walk you through the basics of exploring the data set and predicting the result using multiple linear regression.","id":10,"section":"posts","tags":null,"title":"Part 4 Machine Learning Multiple Regression","uri":"/2019/02/02/part-4-ml-multiple-linear-regression/"},{"content":"In the previous post, we learnt about Simple Linear regression. I wanted to start this section with multiple linear regression tutorial but as I was going over the content on the template to run create the regression model, I felt that we need understand P-Value concept before we move ahead.\nSo what is P-Value ?\nBefore I bore you with stats definition of the P-Value. Let\u0026rsquo;s start with something simple.\nMr X and Mr Y are good friends. One day Mr X and Mr Y decided to go scuba diving. The water in the lake was perfect blue and you could see the bottom and all the fishes swimming in there. After a while,\nMr X:\nI deem that more than 10% of the fishes in the lake are male\u0026quot;.\nMr Y who was also the warden of the lake.\nIt is not possible as they release more female fishes than male.\nMr X:\nEvery other fish that I see is male, hence my statement stands correct.\nMr Y:\nLet\u0026rsquo;s use stats and find out if your statement is true. As I am the warden and know the fact that there are more female than male. Let\u0026rsquo;s call my statement as\n*H0: \u0026ldquo;There are more female than male.\u0026rdquo;\nand your statement as *\nHa: \u0026ldquo;The number of male fish in the lake is more than 10%\nMr Y:\nNow if only I can prove that chances of my statement H0 happening is much higher than then your statement Ha can be rejected. Let\u0026rsquo;s use P-value\nMr X:\nWhat\u0026rsquo;s a P-Value?\nMr Y:\nSo based on the definition below, if we catch 10 samples of fish from the lake and 2 or more of those are male. We will then repeat the experiment multiple times and note down the result. Then we will find out the probability of the number of males caught in 100 experiments and conclude that my statement H0 is true and you cannot reject my argument.\nMr X\nI caught 10 fishes and got 7 are female and 3 are male. I will now repeat this experement 100 times.\nBased on the above experiment what is the likelihood that Mr X would have got the same result? Calculating this likelihood is called P-Value.\nWhat do we do with this P-Value?\nThe P-Value is used to validate a hypothesis. In the above example, the significance level chosen was 0.05. The P-Value calculated(Standard way using historgram)\nSo based on the above histogram shows how many females were caught. The diagram above is a random diagram that I copied from a different dataset. But assume that number of times the male figure was more than 1 is 21. Then the\nprobability(fish is male) = 21/100 or 0.21 or 21%\nSo Hypothesis rule is that if the\np-value is less than Significance level - Reject the H\u0026lt;sub\u0026gt;0\u0026lt;/sub\u0026gt;\np-value is greater than or equal to Significance level - Cannot reject the H\u0026lt;sub\u0026gt;0\u0026lt;/sub\u0026gt;. We do not have enough eveidence for the claim H\u0026lt;sub\u0026gt;a\u0026lt;/sub\u0026gt;\nIn the above case we chose Significance level = 0.01 and our p-value=0.21, so which means that we cannot reject the null hypothesis or H\u0026lt;sub\u0026gt;0\u0026lt;/sub\u0026gt; and we do not have enough evidence to say that Number of male fishes is more than 10% in the lake\nCommon conception about P-VALUE There are two things that you need to understand about P-Value. The two most common things that I had to keep reminding myself(every few months as I tend to forget) are\n**The p-value is NOT the probability the claim is true. **\nWouldn\u0026rsquo;t it be amazing if that was true! Imagine - “there is 30% chance that this M\u0026amp;M pack is heavier than 100g”. Sadly, that\u0026rsquo;s not the case.\nThe p-value is NOT the probability the null hypothesis is true.\nThis one trips me up all the time. When I was trying to refresh my notes from Khan Academy about hypothesis testing, I had to keep repeating this rule as I got almost every question wrong, when it asked someting like - \u0026ldquo;You should accept that null hypothesis is true. The correct way to interpret the result is by reminding that \u0026ldquo;Null hypothese cannot be rejected\u0026rdquo;. Another way of saying it is - I will give you benefit of doubt that Null hypothesis is true - until a more conclusive proof comes forward.\nThe P-Value only tells us whether there is a Strong or Weak/low evidence that our null hypothesis H\u0026lt;sub\u0026gt;0\u0026lt;/sub\u0026gt; is true or not.\nHow to calculate P-Value There are a number of ways to calulate P-value, a topic which I am not going to touch in this series. Here are some of the resources which will help you understand different techniques:\nP-Value calculator Wikihow - Calculate P-Value This conclues this series on P-Value. In the next series we will review Multiple linear regression and you will understand how P-Value fits in the bigger picture.\n","description":"Machine learning tutorial on Data preprocessing","id":11,"section":"posts","tags":null,"title":"Part 3 Machine Learning Understanding P Value","uri":"/2019/01/27/part-3-ml-understanding-p-value/"},{"content":"In the previous post we learned about data pre-processing. In this post we will review the simplest algorithm - Simple Linear Regression.\nBusiness Problem: In this series, we are going to learn about Simple Linear Regression. We will review a data set about Salary and Experience in age. As a data scientist, your job is to help the HR department predict the salary of a person based on his years of experience if he or she accepts the job offer. If you offer too low, the person will not accept the job offer. If you offer too high, then you will be wasting the company\u0026rsquo;s resources($$).\nGetting the dataset Jupyter Notebook \u0026amp; images Simple Regression What is Simple Linear regression? If we draw a graph of salary vs Experience, you will see a linear trend.\nBased on the graph, it is clear that this is a positive slope. If the co-efficient b1 is big, the slope is going to steeper, which means that if there is a small increase in the age, then there will be a big increase in the salary. If the value of b1 is small, the slope is going to be more gentle and with change is experience, the salary is going to increase gently.\nHow is a trendline determined by a model? The model tries to find the trendline by determining the least of Sum of errors. In the below diagram, imagine the red cross as observed value and green cross as determined value(model prediction). The algorithm finds the difference between the and squares them. The algorithm does this for all the observed values and determines the slope of trendline which given the minimum of SUM(y - y^)2\nSteps to solve the problem. Step 1: Data Preprocessing We will follow the same process as we did in the first series. We will import the libraries and read the csv file and take a look at the data.\n1 2 3 4 5 6 7 8 9 # Importing the libraries import numpy as np import matplotlib.pyplot as plt import pandas as pd # Importing the dataset dataset = pd.read_csv(\u0026#39;../Salary_Data.csv\u0026#39;) X = dataset.iloc[:, :-1].values y = dataset.iloc[:, 1].values Step 2: Split the data into training and test data Since there are 30 rows, we will divide the data in 20:10(training:test) 1 2 3 #Split the data into training and test data from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=1/3, random_state=0) Step 3: Feature Scaling\nWe won\u0026rsquo;t be feature scaling or normalizing here because the library that will execute the model takes care of it. So we are going to skip this step.\nStep 4: Train the model\nAt this point our data pre-processing is complete and we will use the library to run the regression on the training data set.\n1 2 3 4 #Fittiing the Simple linear regression on the training set from sklearn.linear_model import LinearRegression regressor = LinearRegression( ) regressor.fit(X_train, y_train) LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) In the above code, we have trained our model and saved it in the variable regressor.\nStep 5: Predict and compare with the actual test set Next, we are going to predict the values of the test sample and get the predicted results in variable y_pred.\n1 2 # Predicting the salary of the test sample y_pred = regressor.predict(X_test) Let\u0026rsquo;s see how did the model predict.\nStep 5: Plot the data To better understand, let\u0026rsquo;s create plot the trendline of our model and look for two things\nWhat is the fit of trendline for training data? What is the fit of trendline on test data against predicted values? 1 2 3 4 5 6 plt.scatter(X_train, y_train, color=\u0026#39;red\u0026#39;) plt.plot(X_train, regressor.predict(X_train), color=\u0026#39;blue\u0026#39;) plt.title(\u0026#39;Salary vs Experience (Training Set)\u0026#39;) plt.xlabel(\u0026#39;Years of Experience\u0026#39;) plt.ylabel(\u0026#39;Salary\u0026#39;) plt.show() Here\u0026rsquo;s how the graph would like for Training data\nCouple of things to note. The scatter function just plots the x,y values on the graph as red dots\nplt.scatter(X_train, y_train, color=\u0026lsquo;red\u0026rsquo;)\nThe plot function also maps the data as blue dots but it joins them via line starting from first mapping to the last. Additionally, you will also notice that in the y-axis, we have passed model function predict(X_train) and not predict(x_test) because we want to use the function created using the training set - y=mx+c.\nplt.plot(X_train, regressor.predict(X_train), color=\u0026lsquo;blue\u0026rsquo;)\nPlot vs Scatter The primary difference of plt.scatter from plt.plot is that it can be used to create scatter plots where the properties of each individual point (size, face color, edge color, etc.) can be individually controlled or mapped to data.\nThe purpose of the above code is to show trendline against the training data points(red dots). If we wanted to show predicted line as set plotted dots, we would have used\nplt.scatter(X_train, regressor.predict(X_train), color=\u0026lsquo;blue\u0026rsquo;)\nIn that case the graph would have looked like this.\nHere\u0026rsquo;s how the graph would like for Test data\n1 2 3 4 5 6 7 #Plot the data against test set plt.scatter(X_test, y_test, color=\u0026#39;red\u0026#39;) plt.plot(X_train, regressor.predict(X_train), color=\u0026#39;blue\u0026#39;) plt.title(\u0026#39;Salary vs Experience (Test Set)\u0026#39;) plt.xlabel(\u0026#39;Years of Experience\u0026#39;) plt.ylabel(\u0026#39;Salary\u0026#39;) plt.show() As explained earlier, the trend line is what the model was trained against the training data set. Hence\nplt.plot(X_train, regressor.predict(X_train), color=\u0026lsquo;blue\u0026rsquo;)\nand not\nplt.plot(X_test, regressor.predict(X_test), color=\u0026lsquo;blue\u0026rsquo;)\nNow let\u0026rsquo;s create a more complete picture - the training set(RED DOTS), test set(GREEN DOTS) and predicted value (BLACK DOTS).\n1 2 3 4 5 6 7 8 9 10 #Plot the data against test set plt.scatter(X_train, y_train, color=\u0026#39;red\u0026#39;) plt.scatter(X_test, y_test, color=\u0026#39;green\u0026#39;) plt.scatter(X_test, y_pred, color=\u0026#39;black\u0026#39;) plt.plot(X_train, regressor.predict(X_train), color=\u0026#39;blue\u0026#39;) plt.title(\u0026#39;Salary vs Experience (Test Set)\u0026#39;) plt.xlabel(\u0026#39;Years of Experience\u0026#39;) plt.ylabel(\u0026#39;Salary\u0026#39;) plt.show() So you will notice that all the black dots lie on the trend line because they are created using the trendline equation.\nThat\u0026rsquo;s it. We just trained a model using Simple linear regression and predicted the values, then compared it against test data.\n","description":"Machine learning tutorial on Data preprocessing","id":12,"section":"posts","tags":null,"title":"Part 2 Machine Learning Simplelinear Regression","uri":"/2019/01/22/part-2-ml-simplelinear-regression/"},{"content":"This is the first of many series on machine learning.\nGet the Dataset Download the following zip files\nJupyter Notebook \u0026amp; images Data Unzip the folder and copy Files and Data under folder location Machine Learning A-Z Template Folder\\Part 1 - Data Preprocessing\nReview the dataset The above dataset shows Country, Age, Salary and Purchased. The field that we need to research is called Dependent field and others are called Independent Field\nDependent Field A dependent field is a whose outcome or value is derived from other fielda. In this example, we are trying to find Whether a customer made a purchase or not. Hence, Purchased here becomes the dependent field. In terms of coordinate, if we map this on the graph then Purchased will be plotted on the y-axis.\nIndependent field Independent fields are values that we observe. Example - If I stand on the side of the freeway and start noting down the color of each car passed, whether it is a car or a truck, is it raining that day or sunny? etc. These values are called Independent fields. In the above datasheet, Country, Age and Salary are independent fields.\nIn data science, everything is a function. Hence if Purchased field = Y and Country, Age and Salary can be represented as c, a \u0026amp; i respectively. Then the above function can be represented as\nY = Xc + Ta + Zi\nImporting the essential library There are three essential libraries for most basic machine learning projects. Add the below library\nimport numpy as np import matplotlib.pyplot as plt import pandas as pd\n1 2 3 4 # Importing the libraries import numpy as np import matplotlib.pyplot as plt import pandas as pd Import the dataset Use panadas to import the file data.csv file\n1 2 #Import the dataset dataset = pd.read_csv(\u0026#34;../data.csv\u0026#34;) 1 dataset.head(6) Country Age Salary Purchased 0 France 44.0 72000.0 No 1 Spain 27.0 48000.0 Yes 2 Germany 30.0 54000.0 No 3 Spain 38.0 61000.0 No 4 Germany 40.0 NaN Yes 5 France 35.0 58000.0 Yes Create the dependent and Independent Variable matrix of features 1 2 x = dataset.iloc[:, :3].values y = dataset.iloc[:, 3:4].values Identify the missing data In the real world when you are handed a dataset. You will find that a lot of data might be missing. Ex - Row 6 Salary is empty and Row 7 Age is missing in our data.csv\nStrategies to handle missing data Remove the rows that have missing data. This approach is simplest but will skew our dataset if lots of fields are missing. Replace the missing data with Mean Replace the missing data with Median Replace the missing data with Mode or Frequency As a general rule of thumb mean and median can be applied to numerical values only. It cannot be applied to alphanumeric or String values. This is where we can use Mode or Frequency.\nTaking Care of missing data * (Numerical values)* Scikit library in python provides a class called Imputer which helps in fixing the missing values using the above strategies.\n1 2 3 4 from sklearn.impute import SimpleImputer imputer = SimpleImputer(missing_values = np.nan, strategy=\u0026#39;mean\u0026#39;) imputer = imputer.fit(x[:,1:3]) x[:, 1:3] = imputer.transform(x[:, 1:3]) In the above code we define a SimpleImputer class object.\nimputer = SimpleImputer(missing_values = np.nan, strategy='mean')\nThe next line imputer = imputer.fit(x[:,1:3]) is telling imputer object on which matrix columns it needs to look for missing value and mark them for filling value as mean\nThe last line x[:, 1:3] = imputer.transform(x[:, 1:3]) fills in the cells of X matrix that were marked by the imputer.\nOne thing that I wanted to try was that would happen if I just used imputer.fit(x) and did not provide the columns which actually had the missing values. What happens is that since you have marked the strategy as strategy='mean', the imputer will try to take the average/mean of each row country, Age \u0026amp; Salary. Since Country is of type String, python will shit in its pant and complain about it. However, if the Country column was numeric, then this imputer.fit(x) would have worked. Additionally, on the left side we have defined that data be copied into x[:, 1:3]. This is because if you write x = imputer.transform(x[:, 1:3]), imputer has marked the cell to be transformed is (1,5) as there are two columns it is looking at Age and Salary but if put only x on the left side, then (1,5) refers to Age 40, while imputer is expecting it to be a Salary column.\nAs you can see, the imputer has filled in the missing values for Salary as $63777.78 and Age as 38.7.\nTaking care of Categorical data Categorical data is any data that is not numeric. Think of it as attributes of an object. Ex - If I am observing cars on a freeway and noting down the speed at which the car is driving and the color of the car. The cars may have different colors such as red, green, blue etc. I can only observe them but cannot do anything else with them like add, subtract, find mean or anything. However, a machine learning algorithm may see value in finding a relation between dependent and independent feature. The algorithm can only make use of item if it is defined in numbers.\nOne way to define them is by assigning them numbers ex- Red =1, Blue =2 and so on.\nIn our current example, we have a categorical data - Country. To convert or encode as it is called in ML, we will again use a library from Scikit\n1 2 3 4 from sklearn.preprocessing import LabelEncoder labelEncoder_x = LabelEncoder() x[: ,0] =labelEncoder_x.fit_transform(x[:, 0]) x array([[0, 44.0, 72000.0], [2, 27.0, 48000.0], [1, 30.0, 54000.0], [2, 38.0, 61000.0], [1, 40.0, 63777.77777777778], [0, 35.0, 58000.0], [2, 38.77777777777778, 52000.0], [0, 48.0, 79000.0], [1, 50.0, 83000.0], [0, 37.0, 67000.0]], dtype=object) The above code uses LabelEncoder class to encode the values of the country. Here, France =0, Spain = 2, Germany=1\nThere is however a simple problem here.\n#####Problem:\nThe models are based on equation. Since the LabelEncoder here, has assigned them values 0,1,2, the equation would think that Germany has higher value than France and Spain has a higher value than Germany. This certainly is not the case. These are supposed to be treated as observational values. Example - Picking on our earlier example of observing car speeds and color. If we use LabelEncoder for encoding car colors, the model may come back and say that A red Prius will always be faster than a White Ferrari\nTo get over this problem and use category as markers, we will use another class which will create dummy encoding and this gives equal value to all categorical data. It does that by creating a sparse matrix.\n1 2 3 4 from sklearn.preprocessing import OneHotEncoder oneHotEncoder = OneHotEncoder(categorical_features=[0]) x= oneHotEncoder.fit_transform(x).toarray() So after dummy encoding, the complete sparse matrix of x looks like this\nSo now let\u0026rsquo;s convert the dependent column Purchased as well. However, we do not need to use dummy encoding as there are only two variables and that it is a dependent variable.\n1 2 labelEncoder_y = LabelEncoder() y =labelEncoder_y.fit_transform(y) Splitting dataset into training and test set Why do we need to split the data into training and test set?\nThis is about an algorithm that will create the equation to predict the result of new information based on history. If you let it run on all of the data then it will learn too much and will have correlation value or in other words overfitting. A simple example in the real world is of a boy who memorizes the book word by word but fails in the actual exam because instead of asking what is 2 +2 like he read in the book, the exam asked what is 1+3. The student learnt too much but cannot relate or imply the same knowledge on a new data set.\nSometimes you may have limited data to build the model and may not additional data to test your model.\n** What is a good ratio to split the data?**\nUsually, 80/20 or up to 70/30 is a good number. Going beyond 70/30 is not recommended.\nTo split a dataset into training and test set. We will use another class called train_test_split, which returns 4 different values - Training_X, Test_X,Training_Y, Test_Y\n1 2 from sklearn.model_selection import train_test_split x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=0) The data is now split into 8 and 2 observation.\nFeature Scaling/ Normalization/Standardization If you look your dataset and pay attention to independent features Age and Salary, the range varies for Age between 27 - 50 and Salary between 48000 - 83000. When an equation is created, the distance between two dat apoints is huge and the values can be skewed because one of the columns have 27 for age and 83000 for salary.\nThe models are usually based on Euclidean distance. In our case since Salary has a higher range, it will dominate the age values which means when we do distance between observation (27, 48000) and (48, 79000) then (x2-x1) ^2 vs (y2-y1) ^2 is\n441 vs 961000000. Hence Age is overshadowed by Salary.\nIf you are from statistics field, you probably are already familair with standardization or Z-index etc. Above is the two way to calculate the standard range which will always give us a value between 0 and 1\n1 2 3 4 from sklearn.preprocessing import StandardScaler sc_x = StandardScaler() x_train = sc_x.fit_transform(x_train) x_test = sc_x.transform(x_test) NOTE: We are not fitting and transforming the x_test because it is already fitted based on xtrain so that they are now on the same scale. If we would have used fit_transform on both test and train then their scale would have been different say one could between -1 and +1 while the other could be on -3 and +3\nWhy did we not apply feature scaling on y or dependent variable?\nIn this case, the values are 0 and 1 only or in other words, this is a classification problem which has two choices, whether a customer bought the product or he did not buy the product. In other scenarios such as that related to multiple regression, we may have situation where we may have to do feature scaling on y as well. That\u0026rsquo;s all for the first series. Stay tuned for next series.\n","description":"Machine learning tutorial on Data preprocessing","id":13,"section":"posts","tags":null,"title":"Part 1 Machine Learning Data Preprocessing","uri":"/2019/01/21/part-1-ml-data-preprocessing/"},{"content":"The Difference Between @Bean and @Component and When to Use What? This is the most common question that new as well as experienced Spring users get confused about. There are literally hundreds of questions on this Stackoverflow. This article will clear all the confusion.\nSimilarities between @Bean and @Autowired @Bean\n@Bean is an annotation based configuration and hence is used in @Configuration based class. This is an explicit way of defining a bean and is also used on the methods defined in configuration class. @Component\nThis is used in classes which you create in your app. This will only work after you enable component scan on the package that contains your class. With component scan, Spring framework will scan the classpath and add all the classes that are marked with a @Component annotation.\n-This is also called the automated way of binding and discovering your bean. So the bottom line is that both can do the job of wiring your bean. It\u0026rsquo;s just that with @Bean you have to define each class explicitly and in case of @Component, Spring does this automatically for you. The @Bean way of wiring your bean is analogous to defining Beans in XML, prior to Spring 2.5. Now that you understand what each does(the end result is the same), let\u0026rsquo;s take a look at what is the difference between the two and when you should choose one over the other.\nDifference between @Bean and @Autowired Scenario: We have a jar file which contains different services ex - Address check service, credit check service etc. This jar file is shared by many different applications/companies Ex - AT\u0026amp;T wants to use Address validator service while FICO wants to use only credit check service.\nIf you use @Component on those service classes and use component scan in the application, then both AT\u0026amp;T and FICO applications will end up detecting credit check in case of AT\u0026amp;T and address validator in case of FICO. As a result, you would face one of the two problems -\nYou will end up adjusting the filter on the component scan. In case you have classes sharing the same name by any chance then you would have to add qualifier otherwise application would complain that it found more than two classes were found with same bean name and will fail to run. Hence, in this scenario, you should use @Bean\nScenario : You downloaded a jar file from GitHub and it is not using Spring. The jar file is a simple and basic java program. Your app wants to use this third-party jar file but since your application is using Spring while the third party jar is not, you will have to write new() keyword to access the functionalities. You want to wire the third party classes.\nSay your class name is MyClass.java and you want to use ThirdPartyClass.java. In this case if you write\n1 2 3 4 5 6 7 public class MyClass{ ..... @Autowired ThirdPartyClass thirdPartyClass; } Your code will throw NullPointerException if you try and access any method of class object thirdPartyClass. In this scenario, you should use @Bean.\nRule of Thumb A simple way to decide between @Component and @Bean is that\nif you want to use third-party classes or jar then use @Bean. If you are writing your own classes for your application then use Component. If you want to use a third party class or jar that is not written using Spring Component then use @Bean. ","description":"","id":14,"section":"posts","tags":null,"title":"Spring Bean vs Spring Component","uri":"/2018/12/30/spring-bean-vs-component/"},{"content":"Tail recursion is a basic but important concept in Functional programming. Recursive functions has always been a pain point for me. I would be eliminated out of several interview rounds if interviewers places emphasis on recursion. In Java world thankfully, most people I know hate recursion because when nesting goes too deep, it impacts the performance if the nested recursion is more than 100 levels deep.\nUnfortunately(Fortunately), functional programming languages like Scala and Haskell have solved this concept with the term Tail Recursion. We will look into the concept of Tail recursion using a sample code below by implementing a function that calculates “factorial”.\nRegular Recursion code: Calculate factorial\ndef factorial(n:Int) :Int={ if(n\u0026gt;0) n * factorial(n-1) else 1 } So the problem with above code is that if I pass a value factorial(5) , then the code will create a series of wait to get the result back ex –\nCall 1: 5 * factorial(4)\nCall 2: 4* factorial(3)\nCall 3: 3* factorial(2)\nCall 4: 2* factorial(1)\nCall 5: 1*1\nNow the call retraces the nested flow to jump back to Step 4 to provide the value as 2*1, which traces back to Step 3 – 3*(2*1) and so on.\nImagine what will happen if you pass a factorial(100)??\nNow let’s take a look at how it is done properly in Functional progaramming using scala.\ndef factorial(n:Int) :Int={ def calculateFactorial(n: Int, acc:Int){ if(n\u0026lt;=0) acc else calculateFactorial(n-1, n* acc) } calculateFactorial(n,1) } Do you see the difference in code? No?. Let me explain what we just did. In Scala, you can define a local method inside another method. So I created a new method called “calcuateFactorial” that takes two parameter, n:Int and **acc:Int, **where acc is accumalor of the result. Now when I call the function **factorial(5), **the recursion code is not doing any processing or calculation on the method. It just returns the accumalator acc as a result. Ex –\ncall 1 – Intput 5,1\ncall 2 – Input 4, 5*1\ncall 3 – Input 3, 4*(5*1)\ncall 4 – Input 2, 3*(4*(5*1))\ncall 6 – Input 1, 2*(3*(4*(5*1)))\ncall 7 – Input 0, 1*(2*(3*(4*(5*1)))) – **RETURN RESULT as 1*2*3*4*5 which is the second input param\n**\nThat is when a recursion becomes tail recursion. The final call when nesting stops, just returns the result and the previous nested call is not waiting for a result to complete the call/result.\nHope the concept will stay with me and with those of you who hated recursion earlier. It just got real so learn and deal with it 🙂\n~ Ciao\n","description":"","id":15,"section":"posts","tags":null,"title":"Scala: Tail Recursion","uri":"/2017/03/20/scala-tail-recursion/"},{"content":"I am a little late to the java 8 party and was trying to quickly get some hands on with lambdas and ran into an issue where I got the error message Variables used in lambda should be final or effectively final . I know what final is but what is effectively final.\nHere is what I was trying to do. I had a HashMap which had values like “one : 1”, “two : 2”, “three : 3” and wanted to replace the String ${one} with 1 etc.\npublic String evaluate(HashMap\u0026lt;String, String\u0026gt; variables){ String result = \u0026quot;${One}, ${two}, ${three}\u0026quot;; variables.forEach((k,v)-\u0026amp;gt;{ String regex = \u0026quot;\\\\$\\\\{\u0026quot; + k + \u0026quot;\\\\}\u0026quot;; result=result.replaceAll(regex, v); }); return result; } When I assigned result=result.replaceAll(regex, v); I got the error message –\nVariables used in lambda should be final or effectively final . On further research using SO forums and blog I learned that Java 8 has new concept called “Effectively final” variable. It means that a non-final local variable whose value never changes after initialization is called “Effectively Final”. This concept was introduced because prior to Java 8 we could not use a non-final local variable in an anonymous class. If you have access to a local variable in Anonymous class, you have to make it final.\nWhen Lambdas was introduced, this restriction was eased. Hence to the need to make local variable final if it’s not changed once it is initialized as Lambda in itself is nothing but an anonymous class. Java 8 realized the pain of declaring local variable final every time developer used Lambda and introduced this concept and made it unnecessary to make local variables final. So if you see the rule for anonymous class still not changed, it’s just you don’t have to write final keyword every time when using lambdas.\nOK. So now I understand what the error means but how do I solve my issue where I want to replace the variables using regex. Surprisingly, before I looked up\ndocumentation and SO forums, I checked the options suggested by IntelliJ. It said – “Transform result variable into final one element array”. As I clicked continue, My code transformed to\npublic String evaluate(){ final String[] result = {\u0026quot;${One}, ${two}, ${three}\u0026quot;}; variables.forEach((k,v)-\u0026amp;gt;{ String regex = \u0026quot;\\\\$\\\\{\u0026quot; + k + \u0026quot;\\\\}\u0026quot;; result[0] = result[0].replaceAll(regex, v); }); return result[0]; }\nNow what the heck just happened? Why is a String not allowed to change but an Array is allowed to change? Going back to basics of Java I realized that when we decalre a variable final, it is the reference to the object that is set to final. So in this case when I write\nfinal String result= “abc”; The reference is STRING OBJECT result —memory location —\u0026gt; “abc” and because the result is declared final, it cannot change the memory reference and point to memory location who value is say ” DEF”.\nWhen I write\nfinal String [] result = {“abc”} In this case, result is pointing to a reference that is a Array and that array has value that reference memory location of String “abc”.\nFINAL STRING [] result —- Memory location –\u0026gt; Single Array —–Memory location —\u0026gt; “abc”.\nSo as you see our result now references the memory location of Array element but the value Array element can change. Remember what is constant here is the reference, not its values.\n~~ Smell the Java ~~\nDinesh\n","description":"","id":16,"section":"posts","tags":null,"title":"Understanding Java 8 Lambda final finally variable","uri":"/2016/06/16/understanding-java-8-lambda-final-finally-variable/"},{"content":" I am learning about Apache Storm and the guide had long and winding instructions on how to install Apache Storm. I installed the single node using brew and it was a breeze. I did not had to spend time figuring out out if I was installing latest version.\nPre-requisites:\nMake sure that you have ‘HomeBrew‘ installed. One reason that I prefer ‘brew’ is that I do not have to remember where things are installed and brew manages and fixes any updates that have been introduced. It also makes installation and uninstall super easy. Everything this is saved under\n/url/local/Cellar. Step 1: Install Zookeeper ‘ brew install zookeeper’\nAfter the installation is complete, you will see this message.\nTo have launchd start zookeeper at login:\nln -sfv /usr/local/opt/zookeeper/*.plist ~/Library/LaunchAgents\nThen to load zookeeper now:\nlaunchctl load ~/Library/LaunchAgents/homebrew.mxcl.zookeeper.plist\nOr, if you don’t want/need launchctl, you can just run:\nzkServer start\nI prefer not to launch zookeeper at login as it will sow down my mac login. So I prefer to start and stop Zookeeper using the command-\n‘zkServer start/stop’\nStep 2: Install ZeroMQ ‘brew install zeromq’\nStep 3: Install Apache storm ‘brew install storm’\nThis above command will install everything in Cellar folder and will have a symlink in ‘/usr/local/opt/storm’ folder.\nStep 4: Update the storm config file storm.yaml. This file will be in /usr/local/opt/storm/libexec/conf folder.\nAfter opening this file you will see that everything is commented out. So we will add the following.\nstorm.zookeeper.servers:\n– “localhost”\n# – “server2”\n#\nnimbus.host: “localhost”\nnimbus.thrift.port: 6627\nui.port: 8772\nstorm.local.dir: “/Users/dinesharora/storm/data”\njava.library.path: /usr/lib/jvm”\nsupervisor.slots.ports:\n– 6700\n– 6701\n– 6702\n– 6703\nIf you will notice that I have added “storm.local.dir”. Make sure that whatever folder you create, they have the right permissions because I initially added “/home/user/storm/data” and did not realize that you cannot create any directory under “/home” folder. This was causing issues when I started nimbus and supervisor.\nStep 5: start zookeeper, nimbus, supervisor and ui Below are the location on shell scripts. Start them in the given sequence\n‘zkServer start’\n‘/usr/local/opt/storm/libexec/bin/storm nimbus’\n‘/usr/local/opt/storm/libexec/bin/storm supervisor’\n‘/usr/local/opt/storm/libexec/bin/storm ui’\nStep 6: Check that everything is running smoothly.\nTo do that run the below command.\n‘jps’\nThe above command should give the following result.\nDineshs-MBP:bin dinesharora$ jps\n5282 supervisor\n5267 nimbus\n5460 core\n5735 Jps\n4235 QuorumPeerMain\nStep 7: Check the server index page. Access the url – ‘http://localhost:8772/index.html’. If you are able to access the page then your installation is successful.\nP.S. If you upgraded to new OSX – El Captain then you might have issues with brew itself. Do yourself a favor and reinstall brew again.\n~ Stir a storm\n","description":"","id":17,"section":"posts","tags":null,"title":"How to set up Apache Storm on mac using brew","uri":"/2015/12/26/how-to-set-up-apache-storm-on-mac-using-brew/"},{"content":"Last week, I was working on an application where I had to do LDAP authentication. My cmpany has been using a very old jar file that had the required code for authenticating and authorizing users. There were two problems for me.\nI had to revisit the documentation on LDAP setting in Jboss 4 and figure how to do the set up. Making changes in login-config.xml etc.\nMy new application is using Spring-boot, which comes with built in tomcat libraries. I had to either find some documentation on Timcat with Spring boot 4 or build the app as war and deploy in Jboss 7 and not Jboss 4, which means going over documentation and tutorial.\nWhat is waffle? While trying to figure out a lazy way of doing things, I ran into Waffle project. WAFFLE is a native Windows Authentication Framework consisting of two C# and Java libraries that perform functions related to Windows authentication, supporting Negotiate, NTLM and Kerberos. Waffle also includes libraries that enable drop-in Windows Single Sign On for popular Java web servers, when running on Windows. While Waffle makes it ridiculously easy to do Windows Authentication in Java, on Windows, Waffle does not work on *nix. In Short, if a user logs into his company computer, he would be authenticating over LDAP to make sure that he is authorized to use the computer. Waffle gives you an opportunity to make use of the exixsting infrastrutuce and help you authenticate and authorzie the user.\nSet Up:: To use waffle in java, we just need to add the maven dependency:\n\u0026lt;properties\u0026gt; \u0026lt;waffle.version\u0026gt;1.5\u0026lt;/waffle.version\u0026gt; \u0026lt;/properties\u0026gt;` \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.dblock.waffle\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;waffle-jna\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${waffle.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt; net.java.dev.jna\u0026lt;/\u0026lt;wbr /\u0026gt;groupId\u0026gt; \u0026lt;artifactId\u0026gt; platform\u0026lt;/\u0026lt;wbr /\u0026gt;artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Create a new instance of waffle.windows.auth.impl.WindowsAuthProviderImpl.\nHere are a couple of scenario that you can do without any nasty setup in Java, Jboss, Tomcat etc.\nScenario 1: Logon a user and get his domain and local groups This calls Win32-LogonUser, checks the user token and extracts all local domain information.\nIWindowsAuthProvider prov = new WindowsAuthProviderImpl() IWindowsIdentity identity = prov.logonUser(\u0026#34;userName\u0026#34;, \u0026#34;pwd\u0026#34;) System.out.println(\u0026#34;User identity: \u0026#34; + identity.getFqn()) for(IWindowsAccount group : identity.getGroups()) { System.out.println(\u0026#34; \u0026#34; + group.getFqn() + \u0026#34; (\u0026#34; + group.getSidString() + \u0026#34;)\u0026#34;) } Output::\nUser identity: acnna\\darora acnna\\\\None (S-1-5-21-42300245183-42300245183-3597729351-513) Everyone (S-1-1-0) acnna\\\\HomeUsers (S-1-5-21-42300245183-42300245183-3597729351-2418) BUILTIN\\Administrators (S-1-5-32-544) BUILTIN\\Users (S-1-5-32-545) NT AUTHORITY\\NETWORK (S-1-5-2) Scenario 2: Active directory: get the list of trusted domains IWindowsAuthProvider prov = new WindowsAuthProviderImpl() IWindowsDomain[] domains = prov.getDomains() for(IWindowsDomain domain : domains) { System.out.println(domain.getFqn() + \u0026#34;: \u0026#34; + domain.getTrustDirectionString()) } Output::\nScenario 3:: Is computer active on a domain? IWindowsAuthProvider prov = new WindowsAuthProviderImpl() IWindowsComputer computer = prov.getCurrentComputer() System.out.println(computer.getComputerName()) System.out.println(computer.getJoinStatus()) System.out.println(computer.getMemberOf()) For systems that run both with and without active directory you need to programmatically figure out whether a computer is joined to a domain or a workgroup. If it’s joined to a domain or a workgroup you want to know what domain the computer is joined to.\nScenario 4: Negotiate Single Sign on This lets both client and server side to negotatite the sign on protocol. The code below, gets the token which can be shared between client and server and be used to lookup its domains.\nString securityPackage = \u0026#34;Negotiate\u0026#34; // client credentials handle IWindowsCredentialsHandle clientCredentials = WindowsCredentialsHandleImpl.getCurrent(securityPackage) clientCredentials.initialize() // initial client security context WindowsSecurityContextImpl clientContext = new WindowsSecurityContextImpl() clientContext.setPrincipalName(Advapi32Util.getUserName()) clientContext.setCredentialsHandle(clientCredentials.getHandle()) clientContext.setSecurityPackage(securityPackage) clientContext.initialize() // accept on the server WindowsAuthProviderImpl provider = new WindowsAuthProviderImpl() IWindowsSecurityContext serverContext = null do { if (serverContext != null) { // initialize on the client SecBufferDesc continueToken = new SecBufferDesc(Sspi.SECBUFFER_TOKEN, serverContext.getToken()) clientContext.initialize(clientContext.getHandle(), continueToken) } // accept the token on the server serverContext = provider.acceptSecurityToken(clientContext.getToken(), securityPackage) } while (clientContext.getContinue() || serverContext.getContinue()) ` System.out.println(serverContext.getIdentity().getFqn()) for (IWindowsAccount group : serverContext.getIdentity().getGroups()) { System.out.println(\u0026amp;#8221 \u0026amp;#8221 + group.getFqn()) } serverContext.dispose() clientContext.dispose() clientCredentials.dispose() ~Ciao\n","description":"","id":18,"section":"posts","tags":null,"title":"Waffle : Windows Single Sign On","uri":"/2015/09/27/waffle-windows-single-sign-on/"},{"content":"Last year my company decided to move from JBoss 4.x/5.x to Jboss AS 7. We use Maven and IZPack plugin to create automated deployment to Jboss 4. As a part of IZPack plugin, we would write the install.xmls for various environment, which would help us deploy war files, log.xml, jars, properties file in respective folders. So the advantage was that Jboss-4 allows you to deploy several xxx-ds.xml files in deploy folder and you can have multiple apps deployed in same Jboss and each app uses it’s respective xxx-ds.xml file.\nWhen we started with Jboss AS 7 we learnt that all datasource setting had to be done in standalone.xml file. **Jboss 7.0 ** got rid of xxx-ds.xml file concept. The problem with this approach was that we could not use IZPack plugin to replace the environment variable if we were deploying multiple apps in the Jboss because every IZPack installation would overwrite the previous standalone.xml setting for datasource section. So our deployment engineer had to manually go and configure each datasource in standalone.xml. God forbid when we have to update expiring passwords for database every few months, then changing all these passwords would have created a havoc.\nAs a result, we abandoned or let’s say delayed the Jboss4 to Jboss AS 7 upgrade. I was not involved in this first attempt however last week I had some time on hand so I started looking into the issue. It turns out the newer version of Jboss AS 7.1.1-FINAL had re-introduced the concept of deployable datasources.\nLet me walk you through 4 ways of configuring the datasources in Jboss AS 7.1.1-FINAL.\n**METHOD 1: Standard way. Setting up datasource using standalone.xml(**Not preferred if you have multiple apps in the deployments folder). In this example let’s assume we are using Oracle database.\n**Step 1: **Add the Ojdbc14.x.x jar file in the folder\nJboss/modules/com/oracle/jdbc/main\nKeep in mind that the folder structure is really important.\nStep 2: Create a file module.xml and it along with for jdbc jar file. Add the below xml in the module.xml file.\nSo in the above file, we are defining the location of the jar file in \u0026lt;**resource-root\u0026gt; **tag. You can actually put the jar file in some other folder as well and define the path here but that is not an advisable approach as you will have to provide the full path of the jar file which will cause issues if you have to move the Jboss folder to some other server location.\n**Step 3: **Open the standalone.xml file under jboss-as-7.1.0.Final\\standalone\\configuration folder. In the datasources section define datasources. EX:\nThat’s it. But this is the standard way of adding the datasource. The next time I want to deploy another application in the same Jboss which uses MySQl, I would have to manually update the **standalone.xml **so that I do not change mess up the datasource set up for Oracle.\nMethod 2: Deploy datasource in stanadalone jar. Assume we are configuring for Oracle datasource.\n**Step 1: **Copy ojdbc14.xx.jar in the Jboss/standalone/deployments folder.\ncp ojdbc14.10.1.05.jar /usr/jboss-as-7.1.1.Final/standalone/deployments\nStep 3: Start the Jboss server to see if the jar file is successfully deployed.\n\u0026lt;strong\u0026gt;09:32:10,400 INFO [org.jboss.as.server] (DeploymentScanner-threads - 2) JBAS018559:\u0026lt;br /\u0026gt; Deployed \u0026quot;mysql-connector-java-5.1.18-bin.jar\u0026quot;\u0026lt;/strong\u0026gt;\nStep 4: Deploy the datasource file\nJust fill in an xml file which ends (as we used to do) in -ds.xml, for example this is a oracle-ds.xml which is suitable for Oracle database. ** **\nStep 5: Deploy your web app and you are good to go.\nAt this point you might wonder if there is any pitfall when using the older -ds.xml approach ? well actually if you “bypass” the management interface and deploy the datasource in the old way, you will not be able to manage it through the CLI or Web admin interface. As you can see from this snapshot, our datasource is not enlisted through the manageable resources of the Web interface.\nMETHOD 3: Deploying the datasource along with your application\nYou can actually deploy your datasource along with your application, just you used to do in the past.\nHere’s a sample Web application Structure which ships with a datasource (in the WEB-INF folder). For other a JAR archive you would rather need copying the datasource in the META-INF folder:\n*Method 4: Hybrid approach using -ds.xml + standalone.xml\nI found this approach to be the best because I do not like put jar files inside a WAR applcation which is written in MAVEN. I also do not like to drop JDBC jar files in deployments folder as it I consider it a sacred place for WAR files only. So I figured out a hybrid approach.\n**Step 1: **Add the Ojdbc14.x.x jar file in the folder\nJboss/modules/com/oracle/jdbc/main\nKeep in mind that the folder structure is really important.\nStep 2: Create a file module.xml and it along with for jdbc jar file. Add the below xml in the module.xml file.\nSo in the above file, we are defining the location of the jar file in \u0026lt;**resource-root\u0026gt; **tag. You can actually put the jar file in some other folder as well and define the path here but that is not an advisable approach as you will have to provide the full path of the jar file which will cause issues if you have to move the Jboss folder to some other server location.\n**Step 3: **Open the standalone.xml file under jboss-as-7.1.0.Final\\standalone\\configuration folder. In the datasources section define datasources. Here you only define the drivers in the datasources section.\nNotice that I have defined 2 drivers and have named them as “mssql” and “oracle“. Also notice the module, this is suppose to be exactly like the folder structure of jar file under **jboss/modules ** section.\n**Step 4: **Create a **xx-ds.xml **file and drop it in deployments folder.\nNotice that I have commented out the ** section. **The way Jboss figures out the driver is by looking at tag name **oracle **in my xx-ds.xml.\nThat’s it.\n~Ciao\n","description":"","id":19,"section":"posts","tags":null,"title":"4 ways to set up datasources in Jboss AS 7","uri":"/2015/07/22/4-ways-to-set-up-datasources-in-jboss-as-7/"},{"content":"“I HAVE THE POWER!!” – I had this feeling a few days ago. I will be honest that at work I do not get time to write unit test cases for each and every piece of code that I write. Often when I do have time, I make an effort to write test cases even for the trivial piece of code blocks such as — Check if properties file is present.\nI was working on new code where I had the luxury to write the code in peace (a rarity at my work place where every project is like a fire drill). While writing test cases I came across a situation where I had a class with two methods:\n1 2 3 4 public void my_public_method() private void my_private_method() I wanted to write test cases for both the method. However Junit would not allow me to write a test case for a private method. I searched over internet forums and every one suggested that I use Java Reflection API to write my test cases or make my private method public, which I did not want to do.\nThat’s when POWERMOCK steps in and in a tiny little section of its documentation I noticed a piece of “**WhiteboxImpl” ** class which can help me test private methods.\nSo that’s what I am going to demonstrate in this tutorial.\nSTEP 1: Add Maven jar files\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \u0026lt;properties\u0026gt; \u0026lt;relative.path\u0026gt;relative/svn/path\u0026lt;/relative.path\u0026gt; \u0026lt;powermock.version\u0026gt;1.6.2\u0026lt;/powermock.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026amp;#8230;\u0026amp;#8230;.. \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.11\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.powermock\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;powermock-module-junit4\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${powermock.version}\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.powermock\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;powermock-api-easymock\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${powermock.version}\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependencies\u0026gt; STEP 2: Create a class MyClass.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class MyClass { //PUBLIC METHOD public String my _public _method(){ String msg=\u0026#34;This is my PUBLIC method\u0026#34;; System.out.println(msg); return msg; } //PRIVATE METHOD private String my _private _method(){ String msg=\u0026#34;This is my PRIVATE method\u0026#34;; System.out.println(msg); return msg; } } STEP 3: Write a test case for public method : my _public _method\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 import org.junit.Assert; import org.junit.Test; import org.junit.runner.RunWith; import org.powermock.core.classloader.annotations.PrepareForTest; import org.powermock.modules.junit4.PowerMockRunner; import org.powermock.reflect.internal.WhiteboxImpl; @RunWith(PowerMockRunner.class) @PrepareForTest(MyClass.class) public class MyClassTest { final String publicMsg = \u0026#34;This is my PUBLIC method\u0026#34;; final String privateMsg = \u0026#34;This is my PRIVATE method\u0026#34;; @Test public void testMy _public _method() throws Exception { MyClass myClass = new MyClass(); String msg=myClass.my _public _method(); Assert.assertEquals(publicMsg,msg); } } As you can see above that there is no issue with calling a public method and it will run successfully but when you try and call the private method, the code will show error that private method is not visible.\nSTEP 4: Use PowerMock’s WhiteboxImpl class to test a private method.\nBefore you do anything you need to make sure that you added Powermock annotations correctly.\nAdd these two annotations to your class. [java]\n@RunWith(PowerMockRunner.class)\n@PrepareForTest(MyClass.class)\n[/java]\nWrite the code to test private method. 1 2 3 4 5 6 7 8 9 10 11 12 @Test public void testMy _private _method() throws Exception { MyClass myClass = new MyClass(); String msg= WhiteboxImpl.invokeMethod(myClass, \u0026#34;my _private _method\u0026#34;); Assert.assertEquals(privateMsg,msg); } The syntax is pretty simple WhiteboxImpl.invokeMethod(, “,input param1, input param2,…);\nThe WhiteBoxImpl class actually uses “Java Reflection API” in the background to make a call, but for the lazy coders like me, who do not want to write Reflection API(Read hate Reflection API), the WhiteBoxImpl class is a small piece of coding heaven.\nNow run the test class and you will see that test cases have passed.\n~Ciao –Repeat the mantra – “I HAVE THE POWER{MOCK}!!!”\n","description":"","id":20,"section":"posts","tags":null,"title":"PowerMock : How to test a private method","uri":"/2015/04/23/powermock-how-to-test-a-private-method/"},{"content":"A few weeks ago my Mac hard drive crashed and I had to get a new grad drive. As part of upgrade, I had to wipe my drive clean and install Yosemite. What I did not realize was that Apple had goofed up Java instlation on Mac, as result of which my IntelliJ idea compalained that it requires legacy Jdk version of Java 6. The dilemma that I had was hwo am I going to mainain the different version of Java.\nHomeBrew as always came to my rescue. For those who are not sure what is HomeBrew and what it is used for should definitely install brew. With so many apps and softwares out there, one needs to maintain several versions of Java JDK as not all of them are compatible with all the versions of Java. The problem with that approach is that you may have downloaded all the versions of Java JDK but you have to tweak around the the bash profiles, set environment, JAVA_HOME settings etc., which is kind of a pain and error prone. This is where neat little tool called jEnv comes into picture. This tool allows you to change different java versions using a simple command. It will be familair to anyone who has used RVM. To read more about, see this post.\nSo Let’s begin by installing jEnv\nStep 1: Run this in the terminal\nbrew install https://raw.github.com/gcuisinier/jenv/homebrew/jenv.rb\nStep 2: Add jEnv to the bash profile\nif which jenv \u0026gt; /dev/null; then eval \u0026quot;$(jenv init -)\u0026quot;; fi\nStep 3: When you first install jEnv will not have any JDK associated with it.\nFor example, I just installed JDK 8 but jEnv does not know about it. To check Java versions on jEnv\nAt the moment it only found Java version(jre) on the system. The ‘*’ shows the version currently selected. Unline rvm and rbenv, jEnv cannot install JDK for you. You need to install JDK manually from Oracle website.\nStep 4: Install JDK 6 from Apple website. This will install Java /System/Library/Java/JavaVirtualMachines/ . The reason we are installing Java 6 from Apple website is that SUN did not come up with JDK 6 for MAC, so Apple created/modified its own deployment version.\nStep 5: Similarly install JDK7 and JDK8.\nStep 6: Add JDKs to jEnv.\nJDK 6:\nJDK 7:\nJDK 8:\nStep 8: Check the java versions installed using jenv\nStep 9: So now we have 3 versions of Java on our system. To set a default version use the command\njenv local \u0026lt;jenv version\u0026gt;\nEx – I wanted Jdk 1.6 to start IntelliJ\njenv local oracle64-1.6.0.65\nStep 10: check the java version\njava -version\nThat’s it. We now have multiple versions of java and we can switch between them easily. jEnv also has some other features, such as wrappers for Gradle, Ant, Maven, etc, and the ability to set JVM options globally or locally. Check out the documentation for more information.\n~~Ciao\n","description":"","id":21,"section":"posts","tags":null,"title":"Install Or Manage multiple versions of Java on OS X","uri":"/2015/03/30/install-or-manage-multiple-versions-of-java-on-os-x/"},{"content":"Last week I was working on a new application which required me to build a web service to access it’s functionality. I decided to check out Spring 4 RestController.\nI was amazed at how far we have come from writing all the boiler template code, xmls etc for making a restful call. With Spring4 boot, it was matter of adding simple annotation for RestController.\nI will be honest, I have not been up to date on how to use a Restful webservice, I built a couple of Restful service a couple of year ago, but most of the services in my current project are old school (SOAP calls), so I never got a chance to build one from scratch and at peace.\nPrerequisites: Read Carefully\nSpring 4 requires you to use Maven 3 in fact it will force you to use Maven 3. This is very important point because it took me an hour to figure this out. If you try to use Maven 2, it will build and “might” compile but the code will complain that some of the RestController class methods are not found. This happens because by default, maven 2 will pull in Spring 2.5.x jar files.\nRequires a minimum of JDK 6.\nWhat are we building?\nWe will build a service that will accept HTTP GET request at: http://localhost:9000/welcome\nand respond with a JSON message:\n{\u0026quot;content\u0026quot;:\u0026quot;Hello Dinesh\u0026quot;}\nStep 1: Create a maven project using command line tools or your favorite IDE.\nStep 2: In the pom.xml add the following information\na) Parent:\nb) Add spring-boot dependency\nc) Add spring-boot plugin\nd) Add spring repositories\nWhy do we need Spring Boot Maven Plugin?\nYou might be wondering what happened to the good old maven build plugin. Well that plugin still works and will compile and build your project, but Spring-boot-maven-plugin searches for the public static void main() method to mark it as runnable class if you use the command “mvn:run”. Secondly, it comes with its own dependency resolver for the version number to match the Spring-boot-starter-web dependencies.\nStep 3: Create JSON Message POJO class\nsrc/main/java/dinesh/Welcome.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 package dinesh; public class Welcome { private final String content; public Greeting(String content) { this.content = content; } public String getContent() { return content; } } Note: Spring 4 Boot automatically uses Jackson JSON library to marshal instances of Welcome into JSONObjects.\nStep 4: Create a resource Controller\nAll Spring HTTP requests are handled by Spring controllers. For Restful services Spring 4 comes with a new annotation @RestController annotation. This will handle the requests which are posted to url /welcome by returning a new instance of Welcome class.\nsrc/main/java/dinesh/WelcomeController.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package hello; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.RestController; @RestController public class WelcomeController { private static final String template = \u0026#34;Hello, %s!\u0026#34;; @RequestMapping(\u0026#34;/welcome\u0026#34;) public Welcome welcome(@RequestParam(value=\u0026#34;name\u0026#34;, defaultValue=\u0026#34;World\u0026#34;) String name) { return new Greeting(String.format(template, name)); } } If you look closely, you will know why I said Maven 2 will not work. Maven 2 will pull in RequestParm class from old Springmvc jar file which does not have method defined for defaultValue(). It is going cry out loud during compilation.\n@RestController – annotation marks the class as controller where every method returns a domain object instead of a view, which is major distinction between @Controller and @RestController which is a short hand for @Controller + @ResponseBody\nThe @RequestMapping annotation helps Spring to identify what method to invoke when some one accesses “/welcome” url.\nThe @RequestParam binds the value of parameter “name” into the name parameter of the welcome() method. If you do not pass any value in the query string then the default value is “world” – default value=”World”. If you do not add default value and forget to pass a “name=xx” in the query string, you will hear a loud cracking, lots of smokes, some curses and code will complain of NP exceptions :-).\nOne important thing that you notice is that we have not done anything to marshall request/response as JSONobject. The old of way of doing this would need you to use Jackson libraries and a lot of annotation to make them as JSON properties. Thanks to Spring 4, it takes of it using Jackson dependencies in the background.\nStep 5: Create an executable “jar” file. yes you read it right. Although you can create a war file, for smaller project like the one I build and the one for this example, I am not going to go through those steps. you cn check the Spring documentation on this topic. Just a high level view what is required is that you get right of the boot plugin, change the packaging tag in the pom.xml to war.Here’s a good post src/main/java/dinesh/Execute.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 package dinesh; import org.springframework.boot.autoconfigure.EnableAutoConfiguration; import org.springframework.boot.SpringApplication; import org.springframework.context.annotation.ComponentScan; @ComponentScan(basePackages = \u0026#34;dinesh.*\u0026#34;) @EnableAutoConfiguration public class Execute { public static void main(String[] args) { SpringApplication.run(Execute.class, args); } } @ComponentScan tells the app to check for @component annotation and it makes sure that Spring finds and registers WelcomeController, because it is marked as “@RestController” .\nStep 6: Build and run\nMethod 1 :\nRun ‘mvn clean install’ in the command line\nAfter the jaris built, run\njava -jar target/xxx.jar\nMethod 2:\nRun spring-boot:run\nSpring 4 comes with built-in Tomcat 7, so you do not need a full-blown JEE application server to deploy and run your web service. Either of the method will fire up the application on port 8080.\nHow do I change port number?\njust run\nspring-boot:run -Dserver.port=9000\nStep 7: Test your service\nOnce the service is up, visit http://localhost:8080/welcome?name=your-name and you will get back a response\n1 2 3 { Hello, your-name } ~Ciao\n","description":"","id":22,"section":"posts","tags":null,"title":"Restful Webservice in 7 Steps using Spring boot","uri":"/2015/01/26/restful-webservice-7-steps-using-spring-boot/"},{"content":"We ran into an issue last week. I had to call a third party web service that was built in PHP. Anyone who wokrs with Java will tell you that calling a web service is not more 15 minutes coding. You take the wsdl, run wsdl2Java command from Axis2 and start calling the service.\nLike I said before, things are never so straightforward. No matter what version of Axis or CXF we used, we kept getting this error:\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026gt; Caused by: org.apache.axiom.soap.SOAPProcessingException: Transport level information does not match with SOAP Message namespace URI \u0026gt; at org.apache.axis2.builder.BuilderUtil.validateSOAPVersion(BuilderUtil.java:772) \u0026gt; at org.apache.axis2.builder.SOAPBuilder.processDocument(SOAPBuilder.java:58) \u0026gt; at org.apache.axis2.transport.TransportUtils.createDocumentElement(TransportUtils.java:179) \u0026gt; at org.apache.axis2.transport.TransportUtils.createSOAPMessage(TransportUtils.java:145) \u0026gt; at org.apache.axis2.transport.TransportUtils.createSOAPMessage(TransportUtils.java:108) \u0026gt; \u0026amp;#8230; 13 more Now what this usually means is that client and server are using different version of SOAP(1.1 vs 1.2). For a long time my colleague tried to look for a solution on various forums, blogs etc. and everyone confirmed the same that the issue is at the service provider end. However, the same service was being used by 20 other vendors without an issue. Our Canada office reported that they were able to call the service without any issue albeit in PHP(OOPS!!).\nOne fine afternoon it just struck me that Axis, CXF etc. are nothing but a wrapper around Java’s SAAJ API. Imagine how did developers call services before Axis and CXF? They coded QNAME, SOAPMessage manually! Lo and Behold but I went down to … let’s call it low level programming because I had to write code for all the XML node element, define namespaces etc.. which was not fun at all.\nSo this tutorial will walk you through basics of SAAJ, how and when to use the SAAJ API.\nWHY DO I NEED SAAJ over AXIS2 or CXF?\nI so badly want to say that when you want to avoid the above error, use SAAJ :-). SAAJ is helpfule when you want complete control over SOAP elements. For example if you need to change name spaces or modify soap message attributes then SAAj comes in handy.\nA typical SOAP message looks like this\nAs you can see SAAJ provides SOAPMessage, SOAPHeader, SOAPBody classes to capture the message. When you create a new SOAPMessage object, it will automatically have the parts that are required to be in a SOAP message. In other words, a new SOAPMessage object has a SOAPPart object that contains a SOAPEnvelope object. The SOAPEnvelope object in turn automatically contains an empty SOAPHeader object followed by an empty SOAPBody object. If you do not need the SOAPHeader object, which is optional, you can delete it. The rationale for having it automatically included is that more often than not you will need it, so it is more convenient to have it provided. The SOAPHeader object may contain one or more headers with information about the sending and receiving parties. The SOAPBody object, which always follows the SOAPHeader object if there is one, provides a simple way to send information intended for the ultimate recipient. For example, if there is a SOAPFault object, it must be in the SOAPBody object.\nSo If have a service where I need the request SOAP Message should look like\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 \u0026gt; \u0026lt;soapenv:Envelope xmlns:soapenv=\u0026amp;#8221;http://schemas.xmlsoap.org/soap/envelope/\u0026amp;#8221; xmlns:urn=\u0026amp;#8221;urn:http://com.mycompany.IamDoingSomething\u0026amp;#8221;\u0026gt; \u0026gt; \u0026lt;soapenv:Header/\u0026gt; \u0026gt; \u0026lt;soapenv:Body\u0026gt; \u0026gt; \u0026lt;urn:getPresaleByAddress\u0026gt; \u0026gt; \u0026lt;stnum\u0026gt;123 \u0026gt; \u0026lt;stnumsuff\u0026gt;\u0026lt;/stnumsuff\u0026gt; \u0026gt; \u0026lt;stnam\u0026gt;Forest\u0026lt;/stnam\u0026gt; \u0026gt; \u0026lt;sttyp\u0026gt;DR\u0026lt;/sttyp\u0026gt; \u0026gt; \u0026lt;stdir\u0026gt;\u0026lt;/stdir\u0026gt; \u0026gt; \u0026lt;loctypa\u0026gt;\u0026lt;/loctypa\u0026gt; \u0026gt; \u0026lt;locnuma\u0026gt;\u0026lt;/locnuma\u0026gt; \u0026gt; \u0026lt;loctypb\u0026gt;\u0026lt;/loctypb\u0026gt; \u0026gt; \u0026lt;locnumb\u0026gt;\u0026lt;/locnumb\u0026gt; \u0026gt; \u0026lt;muni\u0026gt;OTTAWA\u0026lt;/muni\u0026gt; \u0026gt; \u0026lt;post\u0026gt;K1A1A1\u0026lt;/post\u0026gt; \u0026gt; \u0026lt;prov\u0026gt;on\u0026lt;/prov\u0026gt; \u0026gt; \u0026lt;!--\u0026lt;span class=\u0026#34;hiddenSpellError\u0026#34; pre=\u0026#34;\u0026#34; data-mce-bogus=\u0026#34;1\u0026#34;--\u0026gt;urn:getPresaleByAddress\u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026lt;!--\u0026lt;span class=\u0026#34;hiddenSpellError\u0026#34; pre=\u0026#34;\u0026#34; data-mce-bogus=\u0026#34;1\u0026#34;--\u0026gt;soapenv:Body\u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026lt;!--\u0026lt;span class=\u0026#34;hiddenSpellError\u0026#34; pre=\u0026#34;\u0026#34; data-mce-bogus=\u0026#34;1\u0026#34;--\u0026gt;soapenv:Envelope\u0026gt; and I need to send this message to web service url “http://some-webservice-url.com”\nSTEPS\nCreate a SOAP Message 1 2 3 \u0026gt; MessageFactory factory = MessageFactory.newInstance(); \u0026gt; SOAPMessage message = factory.createMessage(); Result:\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026gt; xmlns:SOAP-ENV=\u0026amp;#8221;http://schemas.xmlsoap.org/soap/envelope/\u0026amp;#8221;\u0026gt; \u0026gt; \u0026lt;SOAP-ENV:Header/\u0026gt; \u0026gt; \u0026lt;SOAP-ENV:Body/\u0026gt; \u0026gt; \u0026lt;/SOAP-ENV:Envelope\u0026gt; 2. Access Soap parts or message \u0026gt; SOAPHeader header = message.getSOAPHeader(); \u0026gt; SOAPBody body = message.getSOAPBody(); Add Message Content 1 2 3 4 5 6 7 \u0026gt; SOAPBody body = message.getSOAPBody(); \u0026gt; \u0026gt; SOAPFactory soapFactory = SOAPFactory.newInstance(); \u0026gt; Name bodyName = soapFactory.createName(\u0026amp;#8220;getPresaleByAddress\u0026amp;#8221;,\u0026amp;#8221;urn\u0026amp;#8221;, \u0026amp;#8220;http://com.mycompany.IamDoingSomething\u0026amp;#8221;); \u0026gt; SOAPBodyElement bodyElement = body.addBodyElement(bodyName); Result:\n1 2 3 4 5 \u0026gt; \u0026lt;urn:getPresaleByAddress\u0026gt; \u0026gt; \u0026gt; \u0026amp;#8230; \u0026gt; \u0026gt; \u0026lt;!--\u0026lt;span class=\u0026#34;hiddenSpellError\u0026#34; pre=\u0026#34;\u0026#34; data-mce-bogus=\u0026#34;1\u0026#34;--\u0026gt;urn:getPresaleByAddress\u0026gt; Add Message Headers namespaces if Any 1 2 3 4 5 6 7 8 9 10 11 \u0026gt; MimeHeaders headers = soapMessage.getMimeHeaders(); \u0026gt; headers.addHeader(\u0026amp;#8220;SOAPAction\u0026amp;#8221;, leonidUrl+ \u0026amp;#8220;/getPresaleByAddress\u0026amp;#8221;); \u0026gt; SOAPPart soapPart = soapMessage.getSOAPPart(); \u0026gt; // SOAP Envelope \u0026gt; SOAPEnvelope envelope = soapPart.getEnvelope(); \u0026gt; envelope.addNamespaceDeclaration(\u0026amp;#8220;urn\u0026amp;#8221;, \u0026amp;#8220;urn:http://com.mycompany.IamDoingSomething\u0026amp;#8221;); Add Basic Authentication if any 1 2 3 \u0026gt; String authorization = new sun.misc.BASE64Encoder().encode((\u0026amp;#8220;myUserName\u0026amp;#8221;+\u0026amp;#8221;:\u0026amp;#8221;+\u0026amp;#8221;myPassword\u0026amp;#8221;).getBytes()); \u0026gt; headers.addHeader(\u0026amp;#8220;Authorization\u0026amp;#8221;, \u0026amp;#8220;Basic \u0026amp;#8221; + authorization); Add child elements 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026gt; QName bodyName = new QName(\u0026amp;#8220;urn:http://com.mycompany.IamDoingSomething\u0026amp;#8221;,\u0026amp;#8221;getPresaleByAddress\u0026amp;#8221;,\u0026amp;#8221;urn\u0026amp;#8221;) ; \u0026gt; SOAPBodyElement bodyElement = body.addBodyElement(bodyName); \u0026gt; QName node_name = new QName(qName); \u0026gt; SOAPElement node_element = null; \u0026gt; try { \u0026gt; node_element = bodyElement.addChildElement(\u0026amp;#8220;stnum\u0026amp;#8221;); \u0026gt; if(hasNodeValue){ \u0026gt; node_element.addTextNode(\u0026amp;#8220;123\u0026amp;#8221;); \u0026gt; } \u0026gt; } Result:\n1 \u0026gt; \u0026lt;stnum\u0026gt;123\u0026lt;/stnum\u0026gt; Get a Soap Connection Object 1 2 3 4 \u0026gt; SOAPConnectionFactory soapConnectionFactory = SOAPConnectionFactory.newInstance(); \u0026gt; SOAPConnection connection = soapConnectionFactory.createConnection(); \u0026gt; SOAP messages are sent and received over a connection. This connection is represented by a SOAPConnection object, which goes from the sender directly to its destination. This kind of connection is called a point-to-point connection because it goes from one endpoint to another endpoint. Messages sent using the SAAJ API are called request-response messages. They are sent over a SOAPConnection object with the method call, which sends a message (a request) and then blocks until it receives the reply (a response).\nSend the message 1 2 3 4 5 6 7 \u0026gt; // Create an endpoint point which is either URL or String type \u0026gt; java.net.URL endpoint = new URL(\u0026amp;#8220;http://some-webservice-url.com\u0026amp;#8221;); \u0026gt; \u0026gt; // Send a SOAPMessage (request) and then wait for SOAPMessage (response) \u0026gt; SOAPMessage response = connection.call(message, endpoint); Print the SOAP Response XML 1 2 3 4 5 6 7 8 9 10 11 \u0026gt; Transformer transformer = transformerFactory.newTransformer(); \u0026gt; Source sourceContent = response.getSOAPPart().getContent(); \u0026gt; ByteArrayOutputStream outputStream = new ByteArrayOutputStream(); \u0026gt; StreamResult result = new StreamResult(outputStream); \u0026gt; transformer.transform(sourceContent, result); \u0026gt; log.info(\u0026amp;#8220;nResponse SOAP Message ::n {}\u0026amp;#8221; , result.getOutputStream().toString()); That’s it!!\nThere are many other things that you can do with SAAJ. To read more about SAAJ and it’s capabilities you can read here and here\n~Ciao\n","description":"","id":23,"section":"posts","tags":null,"title":"A quick tutorial on SAAJ API","uri":"/2014/10/17/quick-tutorial-saaj-api/"},{"content":"About a year or two ago I was working with finance team where they wanted to pull the credit card transactions for all the customer using various combinations. Ex –\n– Get the credit card txns for today or certain date.\n– Get the txns for customer who used Mastercard or Visa.\nHowever they wanted this application to generate a Excel file and save it on their local machine so that they could prepare reports for our CEO. I used a Apache POI project to create jar files. This tutorial will walk you through the process of reading and writing excel sheet. So let’s see – How to read and write excel files in Java?\nBrief History on Apache POI\nApache POI is a powerful Java library to work with different Microsoft Office file formats such as Excel, Power point, Visio, MS Word etc. The name POI was originally an acronym for Poor Obfuscation Implementation, referring humorously to the file formats that seemed deliberately obfuscated, but poorly, since they were successfully reverse-engineered. In short, you can read / write MS Excel files using Java. In addition, you can read/write MS Word and MS PowerPoint files using Java. Apache POI is your Java Excel solution .\nApache POI can be used to create both old ( 2003-2008) and new( 2010 – newer) format. I think the newer jar file to create XLSX document is out of BETA phase now. Back when I used this POI it was still in Beta format.\nSo let’s see what does it entails to read /write Excel files in Java.\nI am will be using Maven and IntelliJ to create my project, however you are welcome to use Eclipse or Netbeans.\nApache POI dependencies\nThere are two different maven dependencies one for creating an older version of excel – XLS format and other for creating new version of Excel – XLSX format. I am listing both the dependencies here.\n\u0026lt;!– For Excel 2007 –\u0026gt;\norg.apache.poi\npoi\n3.9\norg.apache.poi\npoi-ooxml\n3.9\nCreate a new module in IntelliJ.\nAdd the dependency in your pom.xml\nPAUSE \u0026amp; THINK: KEY POI CLASSES\nBefore we go ahead here’s quick primer on 3 key classes in POI.\nHSSF – Java implementation of the Excel ’97(-2007) file format. e.g. HSSFWorkbook, HSSFSheet. XSSF – Java implementation of the Excel 2007 OOXML (.xlsx) file format. e.g. XSSFWorkbook, XSSFSheet. SXSSF – Used when very large spreadsheets have to be produced, and heap space is limited. e.g. SXSSFWorkbook, SXSSFSheet. There are other wide range of classes as well which can be used to manipulate the Excel sheet.\nEx – BuiltinFormats, ConditionalFormattingRule,ComparisonOperator,CellStyle, FontFormatting\n, IndexedColors, PatternFormatting, SheetConditionalFormatting. These used for formatting the sheet and formula evaluation.\nHOW TO CREATE A NEW EXCEL SHEET\nThis involves the following steps.\nSo go ahead and create a new file called NewExcel.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 package com.dinesh; import org.apache.poi.ss.usermodel.Cell; import org.apache.poi.ss.usermodel.Row; import org.apache.poi.xssf.usermodel.XSSFSheet; import org.apache.poi.xssf.usermodel.XSSFWorkbook; import java.io.File; import java.io.FileNotFoundException; import java.io.FileOutputStream; import java.io.IOException; import java.util.HashMap; import java.util.Map; import java.util.Set; import java.util.TreeMap; /** * Created by darora on 4/18/14. */ public class NewExcel { public static void main(String[] args) { //Create a new Workbook XSSFWorkbook workbook = new XSSFWorkbook(); //Create a blank sheet XSSFSheet sheet = workbook.createSheet(\u0026#34;Student data\u0026#34;); //Create the data for the excel sheet Map\u0026amp;lt;string, object[]=\u0026#34;\u0026#34;\u0026amp;gt; data = new TreeMap\u0026amp;lt;string, object[]=\u0026#34;\u0026#34;\u0026amp;gt;(); data.put(\u0026#34;1\u0026#34;, new Object[] {\u0026#34;ID\u0026#34;, \u0026#34;FIRSTNAME\u0026#34;, \u0026#34;LASTNAME\u0026#34;}); data.put(\u0026#34;2\u0026#34;, new Object[] {1, \u0026#34;Randy\u0026#34;, \u0026#34;Maven\u0026#34;}); data.put(\u0026#34;3\u0026#34;, new Object[] {2, \u0026#34;Raymond\u0026#34;, \u0026#34;Smith\u0026#34;}); data.put(\u0026#34;4\u0026#34;, new Object[] {3, \u0026#34;Dinesh\u0026#34;, \u0026#34;Arora\u0026#34;}); data.put(\u0026#34;5\u0026#34;, new Object[] {4, \u0026#34;Barbra\u0026#34;, \u0026#34;Klien\u0026#34;}); //Iterate over data and write it to the sheet Set keyset = data.keySet(); int rownum = 0; for (String key : keyset) { Row row = sheet.createRow(rownum++); Object [] objArr = data.get(key); int cellnum = 0; for (Object obj : objArr) { Cell cell = row.createCell(cellnum++); if(obj instanceof String) cell.setCellValue((String)obj); else if(obj instanceof Integer) cell.setCellValue((Integer)obj); } } //Save the excel sheet try{ FileOutputStream out = new FileOutputStream( new File(\u0026#34;c:\\Dinesh\\javahabitExcelDemo.xlsx\u0026#34;)); workbook.write(out); out.close(); System.out.println(\u0026#34;javahabitExcelDemo.xlsx Successfully created\u0026#34;); } catch (FileNotFoundException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } } } OUTPUT\nHOW TO READ A NEW EXCEL SHEET\nSo now that we have written an excel sheet. let’s try to read it back.\nThe steps involved are\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 package com.dinesh; import org.apache.poi.ss.usermodel.Cell; import org.apache.poi.ss.usermodel.Row; import org.apache.poi.xssf.usermodel.XSSFSheet; import org.apache.poi.xssf.usermodel.XSSFWorkbook; import java.io.File; import java.io.FileInputStream; import java.io.FileNotFoundException; import java.io.IOException; import java.util.Iterator; /** * Created by darora on 4/18/14. */ public class ReadExcel { //Create Workbook instance from excel sheet public static void main(String[] args) { try { //Get the Excel File FileInputStream file = new FileInputStream( new File(\u0026#34;c:\\Dinesh\\javahabitExcelDemo.xlsx\u0026#34;)); XSSFWorkbook workbook = new XSSFWorkbook(file); //Get the Desired sheet XSSFSheet sheet = workbook.getSheetAt(0); //Increment over rows for (Row row : sheet) { //Iterate and get the cells from the row Iterator cellIterator = row.cellIterator(); // Loop till you read all the data while (cellIterator.hasNext()) { Cell cell = cellIterator.next(); switch (cell.getCellType()) { case Cell.CELL_TYPE_NUMERIC: System.out.print(cell.getNumericCellValue() + \u0026#34;t\u0026#34;); break; case Cell.CELL_TYPE_STRING: System.out.print(cell.getStringCellValue() + \u0026#34;t\u0026#34;); break; } } System.out.println(\u0026#34;\u0026#34;); } file.close(); } catch (FileNotFoundException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } } } OUTPUT\nUsing formulas in excel sheet When working on excel sheets, we sometimes have to create cells which use formulas to calculate their values. Apache POI has supports methods for adding formula to cells and evaluating the already present formula in the cells. Neat!!\nSo Let’s see an example on setting a formula cells in the excel sheet.\nIn this code we will try to calculate the Simple interest. Formula – Principal * Interest * Time.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 package com.dinesh; import org.apache.poi.ss.usermodel.Row; import org.apache.poi.xssf.usermodel.XSSFSheet; import org.apache.poi.xssf.usermodel.XSSFWorkbook; import java.io.File; import java.io.FileNotFoundException; import java.io.FileOutputStream; import java.io.IOException; /** * Created by darora on 4/18/14. */ public class CalculateFormula { public static void main(String[] args) { //Create the workbook XSSFWorkbook workbook = new XSSFWorkbook(); //Create the sheet XSSFSheet sheet = workbook.createSheet(\u0026#34;Calculate Simple Interest\u0026#34;); //Create Wor Headers Row header = sheet.createRow(0); header.createCell(0).setCellValue(\u0026#34;Principal\u0026#34;); header.createCell(1).setCellValue(\u0026#34;Interest\u0026#34;); header.createCell(2).setCellValue(\u0026#34;Time\u0026#34;); header.createCell(3).setCellValue(\u0026#34;OUTPUT (P * r * t)\u0026#34;); //Create the Rows Row dataRow = sheet.createRow(1); dataRow.createCell(0).setCellValue(1000d); dataRow.createCell(1).setCellValue(12.00); dataRow.createCell(2).setCellValue(6d); dataRow.createCell(3).setCellFormula(\u0026#34;A2*B2*C2\u0026#34;); //Save the File try { FileOutputStream out = new FileOutputStream( new File(\u0026#34;c:\\Dinesh\\javahabitformulaDemo.xlsx\u0026#34;)); workbook.write(out); out.close(); System.out.println(\u0026#34;Excel File with formla is created!\u0026#34;); } catch (FileNotFoundException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } } } OUTPUT\nSo experiment your way with this jar file and do post your comments and suggestions on topics you had like to see in my future posts.\n~ Ciao\n–\n","description":"","id":24,"section":"posts","tags":null,"title":"Read / Write Excel file in Java using Apache POI","uri":"/2014/04/18/apache-poi-tutorial-reading-writing-excel-files-java/"},{"content":"I was working on a project last month where I had to call a third-party web service. The third-party web service wanted me to add a SSL keystore and I struggled. I could have gone to my UNIX Admin and asked him to do this job but decided to learn about all about keystores. I went through couple of forums and SO and ended my spending 2 – 3 hours reading about keystores and commonly used commands.\nTo give you a quick run here what I was doing. I had to use a third party wsdl to create a client. I tried to use Maven jaxws plugin to generate the client. I downloaded the wsdl to my local machine and was able to successfully create a client. For production I wanted to generate the client using the current wsdl so decided to generate the client using the wsdl url of the third-party website but ran into keystore issue. I had to download their certificate and add it to my CACERT.\nThe whole charade led me to compile this post. Before I begin here is a quick run through Keystore\nWhy Do I need a keystore?\nBy using a public/private key mechanism. This provides a layer of security that prevents, among other things, remote attackers from pushing malicious updates to your application (all updates must be signed with the same key)\nWhat is a Java Keytool?\nIt is a key and certificate management utility. It allows users to manage their own public/private key pairs and certificates. It also allows users to cache certificates. Java Keytool stores the keys and certificates in keystore. It protects private keys with a password. A Keytool keystore has the private key and any certificates necessary to complete a chain of trust and set up the trustworthiness of the primary certificate.\n_Each certificate in a Java keystore is associated with a unique alias. When creating a Java keystore you will first create the .jks file that will initially only contain the private key. You will then generate a CSR and have a certificate generated from it. Then you will import the certificate to the keystore including any root certificates. _\nHere is a list of 13 most common commands CREATING AND IMPORTING COMMANDS 1. Create a Java Keystore and value pair\nkeytool -genkey -alias yourDomainName -keyalg RSA -keystore YourkeystoreName.jks 2. Creating a signing request (CSR) for an existing keystore\nkeytool -certreq -alias yourDomainName -keystore keystore.jks -file yourDomainName.csr\n3. Importing a signed primary certificate to an existing keystore**\n**\nkeytool -import -trustcacerts -alias yourDomainName -file yourDomainName.crt -keystore YourkeystoreName.jks\n4. Importing a root or intermediate CA certificate to an existing keystore\nkeytool -import -trustcacerts -alias root -file Thawte.crt -keystore YourkeystoreName.jks\n5. Creating a keystore and self-signed certificate\nkeytool -genkey -keyalg RSA -alias selfsigned -keystore Yourkeystore.jks -storepass password -validity 360\nCHECKING COMMANDS When you need to check the information about a certificate or keystore then you use these commands.\n6. Checking a particular certificate\nkeytool -printcert -v -file Yourdomain.crt\n7. Checking all certificates in a keystore\nkeytool -list -v -keystore Yourkeystore.jks\n9. Checking a particular keystore entry using an alias\nkeytool -list -v -keystore Yourkeystore.jks -alias Yourdomain\nEDIT/IMPORT COMMANDS 10. Deleting a certificate from a keystore\nkeytool -delete -alias Yourdomain -keystore Yourkeystore.jks\n11. Changing a keystore password\nkeytool -storepasswd -new new_password -keystore keystore.jks\n12. Exporting a certificate from a keystore\nkeytool -export -alias Yourdomain -file Yourdomain.crt -keystore Yourkeystore.jks\n13. Listing Trusted CA Certs\nkeytool -list -v -keystore $JAVA_HOME/jre/lib/security/cacerts\nP.S. – If you liked the post please click on one of the ads in the right hand column to help me keep up this site and do drop a me a line to suggest some topics that would like to see on this site.\nSo Long ……\n","description":"","id":25,"section":"posts","tags":null,"title":"13 Most Common Java Keytool Keystore Commands","uri":"/2014/03/16/13-common-java-keytool-keystore-commands/"},{"content":"Linux nerds/geeks happily flaunt their keyboard skills when they get a chance. I admit that I am not a shortcut junky but I too have some keyboard shortcuts under my sleeve that I use in day to day work. I have to say that not only have these shortcuts increased my productivity but they have also made my life a lot easier.\nI am sharing my 10 most used shortcuts at work.\n1. Comment or Un-Comment: CTRL + L\nYou will often run into situation where you need to add debug statement temporarily and remove or comment the line after the debug is complete. Instead of manually going to the beginning of the line and manually typing //, you can use the keyboard shortcut CTRL + L. A cool thing to know is that you can comment out multiple lines at once. 2. Documentation Comment Block : / + Enter**\nI may not follow other coding standard but I do follow this – “Leave the place cleaner before you leave”. One of my biggest pet peeves is developers not documenting about a method or sub routine. What are you conveying or trying to do in a particular method? I hate when I come across such code or even my code when I was beginner. So if commenting single line was not cool enough for you then you can use this to create documentation comments or comment out the code without ugly // marks showing at each line. To compare the difference, I have commented the same code using **CTRL+L and / + Enter VS\n3. Delete Line : CTRL + Y\nThis one is easy. If you have any vim experience or have used sublime text in the past then this would come easy. Simply place the cursor on the beginning of the line and hit CTRL + Y. Now it might not seem intuitive because the obvious choice of deleting should have been CTRL **+ D **(It actually adds a new line if you wondered what it does) but a cool way to remember is to think about confirmation dialog boxes in Unix. For example – Are you sure you want to delete this folder? (Y/N)\n4. Argument Documentation For Method Calls: CTRL + P\nThis one is a true life saver. Imagine you are about to call method which accepts 10 parameters. You start by typing – MyClass.someMethodWith10Params(.., ..,) and you forget what was the third parameter that I need to pass. One ugly way of doing is use your mouse and place the cursor at the beginning of the open bracket and wait for a second until the highlight shows you that the third parameter that you need to pass is a String variable. However if you are like me who forgets the fourth and then next parameters, you would be pulling your hair out. Here comes your knight in the shining armor – **CTRL+P. **This will tell pull up a callout with the information you need.\n5. Continuous Code Selection: CTRL + W\nRaise your hand if you never had to copy paste the code. Any one? This shortcut lets you select a word, block or comment without touching your mouse. When you press **CTRL+W **it will select the code next to the cursor and will continue to select intelligently. When I say intelligently I really mean it. Say you place your cursor in the middle of the code block and hit the key combination it will copy code from opening braces to closing braces and so on. Here’s a sample.\n6. Paste from history: CTRL + V + Shift\nA lot of time I copy and paste code. Sometimes I open multiple projects and files and copy paste code from one project file to another project file. Occasionally I have to use a copy of code which I copied two steps behind and in that case I would think hard what file did I copy it from. Well I found this cool shortcut that saves me all the trouble to recall the file name and line numbers. Usually one uses CTRL + V to paste, but if you use CTRL + V + Shift then IDEA will show the last five copies that you can choose from to paste.\n7. Last Changed files: CTRL + SHIFT + E\nI used SVN at work and git or Bazaar for my personal project. At times when I am not using either it can be hard to track and remember what files did I change in last 1-2 hours. Usually if you are using SVN then you can see uncommitted files to figure out the file changes. However how do you track the files that changed in the last one hour if you are not using SVN or git or mercurial tools. It turns out that IntelliJ keeps a track of your recent file changes. You can just use the shortcut CTRL + SHIFT + E to see the last edited files.\n8. File Structure popup: CTRL + F12\nThis shortcut comes in handy if you are traversing through a huge file looking for a particular method name. You can either do CTRL + F to search for the method name. But at times you may not remember the name of the method or are not sure what methods or members are present in that file. In that case you use this shortcut.\n9. Evaluate Expression : ALT + F8\nThis is one feature that comes in handy in the debug mode. This features allows you to quickly test the output of an expression. For ex – Say I have a method that accepts a number from user and adds 2. When you are in debug mode and need to test a program that is already running need to figure out what would happen if I add 290.756 instead of adding 2, then you would normally have to make code a change or rerun the program. Some IDEs let you do hot deploy while some do not also in a large project this restart and change may take up long time to test one expression. This is when you can use this shortcut to quickly test different expressions without restarting or making a code change. 10. System.out.println() : sout + tab\nI kept the easiest and most used shortcut as the last piece. This is not really a shortcut but when I was looking for a way to avoid typing this verbose piece of code, I was surprised to see that many people did not know this fact. Unlike Netbeans or Eclipse where you can specify shortcut for commonly used text, I could not find this option in IntelliJ until I found the solution in SO. Just type **sout **and hit TAB to print out the complete text. ~Ciao … Enjoy the shortcuts and more.\nP.S. – If you liked the post please click on one of the ads in the right hand column to help me maintain this site and do drop a me a line to suggest some topics that would like to see on this site.\n","description":"","id":26,"section":"posts","tags":null,"title":"10 IntelliJ IDEA Keyboard Shortcuts That You Must Know","uri":"/2014/01/31/10-intellij-idea-keyboard-shortcuts-must-know/"},{"content":"Still to come\n","description":"","id":27,"section":"","tags":null,"title":"About Me","uri":"/about-me/"},{"content":"I have made up my mind to get rid of WSO2 ESB at my office. It is clumsy, buggy, hard to test, no body wants to work on it and the documentation is horrible. I looked at various alternative and Apache Camel was free and easy to set up and work with me.\nTo cut the story short, I was able to run most of the example but was struggling with CXF to call a third party service hosted at a random url. The documentation on the website is focused on exposing web service built in Camel. I was finally able to figure this out with a couple of slide show on slideshare.\nHere\u0026rsquo;s the scenario: I have a third party webservice hosted on the web which gives you the the conversion rate between two currencies. I am going to call this web service and log the response.\nAs usual I will start from scratch. My webservice is hosted at this url -http://www.webservicex.net/CurrencyConvertor.asmx?WSDL. This webservice exposes a operation called - “ConversionRate\u0026quot;.\nI am using Fuse Ide(free - Developer version) but you can use Intellij Or Eclipse.\nPrerequisites - Must have Maven.\nStep 1: Create a new Camel-Spring project.\nStep 2: Add the following dependencies in your pom.xml. “camel-cxf\u0026quot;\n1 2 3 4 5 6 7 8 9 \u0026lt;scope\u0026gt;\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.camel\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;camel-cxf\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.10.0.redhat-60024\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;\u0026lt;/scope\u0026gt; My pom.xml looks like this -\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 \u0026lt;!-?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;com.mycompany\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;camel-spring\u0026lt;/artifactId\u0026gt; \u0026lt;packaging\u0026gt;jar\u0026lt;/packaging\u0026gt; \u0026lt;version\u0026gt;1.0.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;A Camel Spring Route\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://www.myorganization.org\u0026lt;/url\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;project.reporting.outputEncoding\u0026gt;UTF-8\u0026lt;/project.reporting.outputEncoding\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;release.fusesource.org\u0026lt;/id\u0026gt; FuseSource Release Repository \u0026lt;url\u0026gt;http://repo.fusesource.com/nexus/content/repositories/releases\u0026lt;/url\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;snapshot.fusesource.org\u0026lt;/id\u0026gt; FuseSource Snapshot Repository \u0026lt;url\u0026gt;http://repo.fusesource.com/nexus/content/repositories/snapshots\u0026lt;/url\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; \u0026lt;pluginRepositories\u0026gt; \u0026lt;pluginRepository\u0026gt; \u0026lt;id\u0026gt;release.fusesource.org\u0026lt;/id\u0026gt; FuseSource Release Repository \u0026lt;url\u0026gt;http://repo.fusesource.com/nexus/content/repositories/releases\u0026lt;/url\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;/pluginRepository\u0026gt; \u0026lt;pluginRepository\u0026gt; \u0026lt;id\u0026gt;snapshot.fusesource.org\u0026lt;/id\u0026gt; FuseSource Snapshot Repository \u0026lt;url\u0026gt;http://repo.fusesource.com/nexus/content/repositories/snapshots\u0026lt;/url\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;/pluginRepository\u0026gt; \u0026lt;/pluginRepositories\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.camel\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;camel-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.10.0.redhat-60024\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.camel\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;camel-spring\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.10.0.redhat-60024\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!- logging -\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-log4j12\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;log4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;log4j\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.17\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!- testing -\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.camel\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;camel-test-spring\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.10.0.redhat-60024\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.camel\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;camel-cxf\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.10.0.redhat-60024\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;defaultGoal\u0026gt;install\u0026lt;/defaultGoal\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;source\u0026gt;1.6\u0026lt;/source\u0026gt; \u0026lt;target\u0026gt;1.6\u0026lt;/target\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-resources-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.4.3\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;encoding\u0026gt;UTF-8\u0026lt;/encoding\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;!- allows the route to be ran via mvn camel:run -\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.camel\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;camel-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.10.0.redhat-60024\u0026lt;/version\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; Step 2: Under src/main.resources/META-INF folder(if not there then create one) create file called camel-context.xml Your camel file should like this -\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:cxf=\u0026#34;http://camel.apache.org/schema/cxf\u0026#34; xsi:schemaLocation=\u0026#34; http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://camel.apache.org/schema/cxf http://camel.apache.org/schema/cxf/camel-cxf.xsd http://camel.apache.org/schema/spring http://camel.apache.org/schema/spring/camel-spring.xsd\u0026#34;\u0026gt; \u0026lt;cxf:\u0026lt;span class=\u0026#34;hiddenSpellError\u0026#34;\u0026gt;cxfEndpoint id=\u0026#34;wsdlEndpoint\u0026#34; address=\u0026#34;http://www.webservicex.net/CurrencyConvertor.asmx\u0026#34; endpointName=\u0026#34;c:SOAPOverHTTP\u0026#34; serviceName=\u0026#34;c:CurrencyConvertor\u0026#34; xmlns:s=\u0026#34;http://www.webserviceX.NET\u0026#34;/\u0026gt; \u0026lt;camelContext xmlns=\u0026#34;http://camel.apache.org/schema/spring\u0026#34;\u0026gt; \u0026lt;route\u0026gt; here is a sample which processes the input files (leaving them in place - see the \u0026amp;#8216;noop\u0026#39; flag) then performs content based routing on the message using XPath\u0026lt;/description\u0026gt; src/data/order?noop=true\u0026#34;/\u0026gt; \u0026lt;log message=\u0026#34;${body}\u0026#34;/\u0026gt; wsdl\u0026amp;serviceName={http://www.webserviceX.NET/}CurrencyConvertor\u0026amp;portName={http://www.webserviceX.NET/}CurrencyConvertorSoap\u0026amp;dataFormat=MESSAGE\u0026#34;/\u0026gt; \u0026lt;log message=\u0026#34;${body}\u0026#34;/\u0026gt; \u0026lt;/route\u0026gt; \u0026lt;/camelContext\u0026gt; \u0026lt;/beans\u0026gt; Step 4: Place the payload or input data xml in src/data/input/order.xml. The order.xml should like this -\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026lt;soapenv:Envelope xmlns:soapenv=\u0026#34;http://schemas.xmlsoap.org/soap/envelope/\u0026#34; xmlns:web=\u0026#34;http://www.webserviceX.NET/\u0026#34;\u0026gt; \u0026lt;soapenv:Header/\u0026gt; \u0026lt;soapenv:Body\u0026gt; \u0026lt;web:ConversionRate\u0026gt; \u0026lt;web:FromCurrency\u0026gt;AUD\u0026lt;/web:FromCurrency\u0026gt; \u0026lt;web:ToCurrency\u0026gt;USD\u0026lt;/web:ToCurrency\u0026gt; \u0026lt;/web:ConversionRate\u0026gt; \u0026lt;!-\u0026lt;span class=\u0026#34;hiddenSpellError\u0026#34;\u0026gt;soapenv:Body\u0026gt;-\u0026gt; \u0026lt;/soapenv:Envelope\u0026gt; That\u0026rsquo;s it!!!!\nThe interesting part is all in the camel-context.xml. Here\u0026rsquo;s what is happening in this file\nsrc/data/order?noop=true\u0026quot;/\u0026gt;\nThis line reads the file order.xml. The option noop=true makes the file to be read again and again. By default this values is false. If this value is false, then after one read, camel marks it as read and when you run the example for second time, it will not read this file.\nThis line will simply log the contents of order.xml.\nserviceName={http://www.webserviceX.NET/}CurrencyConvertor\u0026amp;portName={http://www.webserviceX.NET/}CurrencyConvertorSoap\u0026amp;dataFormat=MESSAGE\u0026quot;/\u0026gt;\nThis line tells cxf component that it needs to call the webservice - http://www.webservicex.net/CurrencyConvertor.asmx?wsdl\n-URL - is the url of the wsdl http://www.webservicex.net/CurrencyConvertor.asmx?wsdl\nserviceName - is the name of the service. Remember it is the name of teh service not the oepration!! The value between {} is the namespace. If you do not want to write {http://….} then add another tag_xmlns \u0026gt; {http://www.webserviceX.NET/}CurrencyConvertor. portName - is the name of the port.\nportName={http://www.webserviceX.NET/}CurrencyConvertorSoap. This is again preceded by {http://…} which is the namespace value. This value is defined in the wsdl as -wsdl:port name=\u0026quot;CurrencyConvertorSoap\u0026quot; binding=\u0026quot;tns:CurrencyConvertorSoap\u0026quot;\nThe last piece is dataFormat - dataFormat=MESSAGE This tells that the body is of type message.\nPart 2 - In production you would want to avoid writing cxf in the above format as it is prone to error because the string value is very long and difficult to test independently and cannot be reused if you want to call the service in another route. So the best way is to define this as cxf endpoint. All you need to do is slightly modify the camel-context.xml\nAdd this(be sure to remove the earlier version of \u0026lt;to uri=\u0026ldquo;cxf….\u0026rdquo;) Define the cxf endpoint called wsdlEndpoint (You call it whatever you want). 1 2 3 4 5 6 7 8 9 \u0026lt;cxf:\u0026lt;span class=\u0026#34;hiddenSpellError\u0026#34;\u0026gt;cxfEndpoint id=\u0026#34;wsdlEndpoint\u0026#34; address=\u0026#34;http://www.webservicex.net/CurrencyConvertor.asmx\u0026#34; endpointName=\u0026#34;c:SOAPOverHTTP\u0026#34; serviceName=\u0026#34;c:CurrencyConvertor\u0026#34; xmlns:s=\u0026#34;http://www.webserviceX.NET\u0026#34;/\u0026gt; That\u0026rsquo;s it.\nNow just run the app. This will print the following-\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [ead #0 - file://src/data/order] route1 INFO \u0026lt;soapenv:Header/\u0026gt; \u0026lt;soapenv:Body\u0026gt; \u0026lt;web:ConversionRate\u0026gt; \u0026lt;web:FromCurrency\u0026gt;AUD\u0026lt;/web:FromCurrency\u0026gt; \u0026lt;web:ToCurrency\u0026gt;USD\u0026lt;/web:ToCurrency\u0026gt; \u0026lt;/web:ConversionRate\u0026gt; \u0026lt;/soapenv:Body\u0026gt;-\u0026gt; \u0026lt;/soapenv:Envelope\u0026gt;-\u0026gt; ~ Enjoy Cameling ….\n","description":"","id":28,"section":"posts","tags":null,"title":"Apache Camel : How to call  java webservice","uri":"/2013/12/16/apache-camel-how-to-call-an-external-webservice/"},{"content":"I wrote this blog about a year ago and left it in the draft because this post somehow was not getting auto saved on WordPress and since its long post it took time for me type, take screenshots and paste. I did not have energy and time to do it all over again. I had a copy of it though in my google drive and I cannot tell you how many times this document has helped me. Now I have a short-term memory. I remember phone numbers which I heard 10-15 years ago but some how command line arguments, street names etc. have always been elusive. My wife keeps poking fun at me when I drive and says that I am “directionally challenged”. I just cannot remember a route. I am absent-minded, not blank, but my mind just keep thinking all the time. I follow the same route to office every day, however as it often happens that I am always lost in my thoughts, I would take I-85 South ramp instead of I-85 north ramp and I am baffled a minute or two later, at the exit signs and wonder why are the exit numbers decreasing.\nAnyway the point is that this document will help some absent-minded like me who do the set up once but when something goes wrong do the research all over again and wonder what did I do the last time.\nAs usual I am going to start from scratch and would put this in steps.\nCreate a new Amazon web services account.\nGo to your Console and select EC2 tab.\nNow Lunch and instance. You will be shown a screen to select a wizard. You can choose between classic and quick wizard. The difference is that with classic wizard, you have fine grain control over what instance and software you want to install while Quick wizard is prebuilt server, for example – Ubuntu+Apache+Mysql+PHP. If you want the same instance set up on Classic wizard then you need install on your own. I choose Classic Wizard. Click Continue.\nNext I chose UBUNTU 12.04 32 bit.\nNext choose your instance. I choose Micro instance.\nYou can also chose Request Spot Instance where you basically requests your own quote and can specify the largest amount that you intend to pay. Something like price negotiator.\nClick \u0026gt;Continue\nClick \u0026gt;Continue.\nNext name your instance and click Continue.\nNext create a Key-Value pair. Name your key and click\u0026gt; Create and Download your Key Pair\nSave the key on your local system and click continue.\nNext configure your security settings. It will be named quick-launch by default with port 22 for sftp open. You can add more ports if you like. I added port 80(Http) and 443(Https).\nNow you are ready to launch your server.\nA confirmation page lets you know your instance is launching. Click Close to close the confirmation page.\nIn the Navigation pane, click Instances to view the status of your instance. It takes a short time for an instance to launch. The instance’s status will be pending while it’s launching.\nRecord the Public DNS name for your instance because you’ll need it for the next task. If you select the instance, its details (including the public DNS name) are displayed in the lower pane. You can also click Show/Hide in the top right corner of the page to select which columns to display.\nec2-xx-xx-xx-xx.compute-1.amazonaws.com\nConnecting to your Linux instance Just Right click and click Connect…. It will give you option to connect via ssh or java client. Choose java client. For Ubuntu, the user name is ubuntu. Specify the location of your key-value pair that you downloaded earlier. Hit Connect. You are now connected.\nUpdate ubuntu packages. Run this command – apt-get update\napt-get upgrade –show-upgraded\nNow we already have default user “\u0026gt;ubuntu”. However I wanted to create my username. So create one – sudo adduser example_user\nYou will be asked several questions like Full Name, Room number etc. Just click Enter and continue\nEnter the new value, or press ENTER for the default\nFull Name []\nRoom Number []\nWork Phone []\nHome Phone []\nOther []\nIs the information correct? [Y/n] y\nNow we need to allow this new user to administer the system. So to do this we need to give it admin rights. Run this: sudo usermod -a -G sudo example_user\nInstall Git sudo apt-get install build-essential git-core curl\nInstall RVM to support different version of Ruby. curl -L get.rvm.io | bash -s stable\nAdd RVM to bashrc echo ‘[[ -s “$HOME/.rvm/scripts/rvm” ]] \u0026amp;\u0026amp; source “$HOME/.rvm/scripts /rvm”‘ » ~/.bashrc\nReload bashrc file . ~/.bashrc\nNow exit from the session and type type rvm| head -1\nThis will give you a message that \u0026gt;“rvm is a function”\nNext we will install ruby. rvm install 1.9.3\nUse ruby 1.9.3 as default rvm –default use 1.9.3\nTo check the version of ruby- ruby -v\nThis should tell you that you are using\n“ruby 1.9.3p194”\nLet’s install RAILS now. gem install rails -v 3.2.1\nNow you may run into issue and get this error\nubuntu@domU-12-31-39-09-84-B8:~$ gem install rails -v 3.2.1\nERROR: Loading command: install (LoadError)\ncannot load such file — zlib\nERROR: While executing gem … (NameError)\nuninitialized constant Gem::Commands::InstallCommand\nIf you get this error that do not worry, it is just telling you that you need to install some more packages.\nRun these commands:\nrvm pkg install zlib\nrvm remove 1.9.3\nrvm install 1.9.3\nrvm –default use 1.9.3\ngem install rails -v 3.2.1\nTime to install Mysql sudo apt-get update\nsudo apt-get upgrade –show-upgraded\nsudo apt-get install libmysqlclient-dev\nsudo apt-get install mysql-server\nYou will be prompted with Mysql installation screen. \u0026gt;Just follow the instructions to set up root user name and password.\nUpdate the git configuration git config –global user.name “Firstname Lastname”\ngit config –global user.email “your_email@youremail.com“\nInstall passenger and Nginx gem install passenger\npassenger-install-nginx-module\nIf you run into issues then run the following\napt-get install libopenssl-ruby\napt-get install libcurl4-openssl-dev\napt-get install libssl-dev\nIf you still run into issues where the installation instructions says that \u0026gt;openssl-dev is not installed then run this command\nrvm pkg install openssl\nrvm remove 1.9.3\nrvm install 1.9.3\nrvm –default use 1.9.3\nrvmsudo passenger-install-nginx-module \u0026gt;//You have to use rvmsudo if you are not logged in as root.\nDownload the code from now. To do that you need to create new ssh key and set it up on github. ssh-keygen -t rsa -C “Your-emial-address@youremial.com”\n– Copy the key value from /root/.ssh/id_rsa.pub and copy the key in your git hub account.(If you do not know how to add ssh key then see github help document. Basically just goto github settings–\u0026gt; ssh-keys–\u0026gt; Add Key)\n– Now create your app folder. I created mine under /home/apps/. Now go to apps folder and run this command in terminal – \u0026gt;git clone git@……….xxxx.git (Your git url).\nNow we will install bundler.\nSwitch to your application folder, such as – cd /home/apps/albums and run the command gem install bundler\nbundle install\nRan into error below for Rmagick gem\nGem::Installer::ExtensionBuildError: ERROR: Failed to build gem native extension.\n/home/ubuntu/.rvm/rubies/ruby-1.9.3-p194/bin/ruby extconf.rb\nchecking for Ruby version \u0026gt;= 1.8.5… yes\nextconf.rb:128: Use RbConfig instead of obsolete and deprecated Config.\nchecking for gcc… yes\nchecking for Magick-config… no\nCan’t install RMagick 2.13.1. Can’t find Magick-config in /home/ubuntu/.rvm/gems/ruby-1.9.3-p194/bin:/home/ubuntu/.rvm/gems/ruby-1.9.3-p194@global/bin:/home/ubuntu/.rvm/rubies/ruby-1.9.3-p194/bin:/home/ubuntu/.rvm/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games\n*** extconf.rb failed *** Could not create Makefile due to some reason, probably lack of\n\u0026gt;necessary libraries and/or headers. Check the mkmf.log file for more\n\u0026gt;details. You may need configuration options.\n\u0026gt;Provided configuration options:\n\u0026gt; –with-opt-dir\n\u0026gt; –with-opt-include\n\u0026gt; –without-opt-include=${opt-dir}/include\n\u0026gt; –with-opt-lib\n\u0026gt; –without-opt-lib=${opt-dir}/lib\n\u0026gt; –with-make-prog\n\u0026gt; –without-make-prog\n\u0026gt; –srcdir=.\n\u0026gt; –curdir\n\u0026gt; –ruby=/home/ubuntu/.rvm/rubies/ruby-1.9.3-p194/bin/ruby\n\u0026gt;Gem files will remain installed in /home/ubuntu/.rvm/gems/ruby-1.9.3-p194/gems/rmagick-2.13.1 for inspection.\n\u0026gt;Results logged to /home/ubuntu/.rvm/gems/ruby-1.9.3-p194/gems/rmagick-2.13.1/ext/RMagick/gem_make.out\n\u0026gt;An error occured while installing rmagick (2.13.1), and Bundler cannot continue.\n\u0026gt;Make sure that gem install rmagick -v \u0026amp;#8216;2.13.1\u0026amp;#8217; succeeds before bundling.\nIf you get the same error for Rmagick or Mysql or anything else, then run the below command.\nsudo apt-get install libmagickwand-dev\nNow re run the command\nbundle install\nStarting up the passenger now. However before we start passenger we need make sure that our database exist. So let’s create database and do the database migrations. Run the below commands – rake db:create\nrake db:migrate //// Now this will not create a production db, but will create dev, test db for you. If you intend to create a production DB as well then run this command –\n\u0026gt;RAILS_ENV=production rake db:create\n\u0026gt;RAILS_ENV=production rake db:migrate\nI ran into issue and got the below error –\nrake aborted!\nCould not find a JavaScript runtime. See https://github.com/sstephenson/execjs for a list of available runtimes.\nThe forums said that I need to install nodeJs. So here’s the list of command to install nodeJs.\n\u0026gt;sudo apt-get install python-software-properties\nsudo add-apt-repository ppa:chris-lea/node.js\nsudo apt-get update\nsudo apt-get install nodejs\nNow the last thing you need to before starting passenger is pre compile your assets(css, images, js etc.). If you do not do this you will not be able to see the images and css. So run this command\nbundle exec rake assets:precompile\nOh by the way if your images are not being served even after running the above command and starting passenger then you need to read my other post – http://railgaadi.wordpress.com/2012/01/28/engineyard-rails-3-x-nginx-passenger-assets-not-displayed/\nP.S. The above issue is pretty common and first time user who are trying to promote run into the above issue and give up eventually. I stopped looking at it after 2 days… took a 3 day break and attacked the issue again 🙂\nNow start the passenger.(Make sure that you have started Nginx before starting Passenger else… see my earlier post – http://railgaadi.wordpress.com/2012/01/28/engineyard-rails-3-x-nginx-passenger-assets-not-displayed/)\npassenger start -e production\nI got error that “\u0026gt;can’t connect to mysqlserver through socket tmp/mysql.sock”. If you run into this server then run this command\nmysqladmin variables | grep socket\nIf you have a root password then use\nsudo mysqladmin -p variables | grep socket\nThe above command will give you socket name. In my case it gave me \u0026gt;/tmp/var/mysq.lock.\nNote this value and update your \u0026gt;database.yml file and update the socket as given below.\ndevelopment:\n\u0026gt; adapter: mysql2\n\u0026gt; host: localhost\n\u0026gt; username: root\n\u0026gt; password: xxxx\n\u0026gt; database: xxxx\n\u0026gt; socket: /tmp/mysql.sock\nAfter you have updated the \u0026gt;database.yml file you should be able to start the passenger.\nSetting up NGINX\nMake sure that you nginx.conf under /opt/nginx/conf file’s server section looks like this \u0026gt;server {\n\u0026gt; listen 80;\n\u0026gt; server_name www.mysitename.com;\n\u0026gt; access_log /srv/www/mysitename.com/logs/access.log;\n\u0026gt; error_log /srv/www/mysitename.com/logs/error.log;\n\u0026gt; root /home/myapp/album/public;\n\u0026gt; passenger_enabled on;\n\u0026gt; passenger_base_uri /home/myapp/album/public;\n\u0026gt; #This property allows you to upload huge pictures files else you will get error 413- File too large\n\u0026gt; client_max_body_size 5M;\n\u0026gt; #charset koi8-r;\n\u0026gt; #access_log logs/host.access.log main;\n\u0026gt;# location / {\n\u0026gt; # root /home/dinesh19aug/album/public;\n\u0026gt; # index index.html index.htm;\n\u0026gt; # }\nHappy launching 🙂\nIn case you are wondering what did I launch —- P.S. If you have been following my blog it’s my wife’s photography website. Wifeys website\n~~Ciao\nP.S. – Look forward for my first hand experience with Node.js in the next post.\n","description":"","id":29,"section":"posts","tags":null,"title":"Launch Website in Amazon EC2","uri":"/2013/10/24/launch-website-in-amazon-ec2/"},{"content":"This is a simple process but if you try and search on the web you will come across various incomplete solutions which will leave you more confused than you already were. This configuration involves just four simple steps that I will walk through to help you set up JNDI on Jboss. I am using Jboss 4.3, but this should be valid for other version of Jboss as well.\nI have a web application which is built on Spring 3.2 and uses Hibernate 4. To set up a new JNDI configuration we will first create a datasource xml file. This file needs to be deployed in Jboss/Deploy folder along with your war file.\nStep 1:\nCreate a datasource file oracle-ds.xml. The content of the file will look like this\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE datasources PUBLIC -//JBoss//DTD JBOSS JCA Config 1.5//EN\u0026#34; http://www.jboss.org/j2ee/dtd/jboss-ds_1_5.dtd\u0026#34;\u0026gt; \u0026lt;datasources\u0026gt; \u0026lt;local-tx-datasource\u0026gt; \u0026lt;jndi-name\u0026gt;\u0026lt;strong\u0026gt;jdbc/listener-dss \u0026lt;/jndi-name\u0026gt; \u0026lt;connection-url\u0026gt;jdbc:oracle:thin:@dbsrvossdevl:1521:US91\u0026lt;/connection-url\u0026gt; \u0026lt;driver-class\u0026gt;oracle.jdbc.driver.OracleDriver\u0026lt;/driver-class\u0026gt; \u0026lt;user-name\u0026gt;myuser\u0026lt;/user-name\u0026gt; \u0026lt;password\u0026gt;mypassword\u0026lt;/password\u0026gt; \u0026lt;min-pool-size\u0026gt;5\u0026lt;/min-pool-size\u0026gt; \u0026lt;max-pool-size\u0026gt;50\u0026lt;/max-pool-size\u0026gt; \u0026lt;idle-timeout-minutes\u0026gt;10\u0026lt;/idle-timeout-minutes\u0026gt; \u0026lt;exception-sorter-class-name\u0026gt;org.jboss.resource.adapter.jdbc.vendor.OracleExceptionSorter\u0026lt;/exception-sorter-class-name\u0026gt; \u0026lt;metadata\u0026gt; \u0026lt;type-mapping\u0026gt;Oracle9i\u0026lt;/type-mapping\u0026gt; \u0026lt;/metadata\u0026gt; \u0026lt;/local-tx-datasource\u0026gt; \u0026lt;/datasources\u0026gt; Explanation:\n1 \u0026lt;jndi-name\u0026gt;jdbc/listener-dss \u0026lt;/jndi-name\u0026gt; This line tells what is the jndi name that we are going to use across configuration files.\nStep 2: Now open your web.xml file and add the resource-ref. This tells that jee container that your web application is using JNDI.\nYour web.xml should be under WEB-INF folder. Add the below lines in your web.xml (see the highlighted section ). This step is common whether you use Jboss or Tomcat or Websphere or any other application server.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;web-app version=\u0026#34;2.5\u0026#34; xmlns=\u0026#34;http://java.sun.com/xml/ns/javaee\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\u0026#34;\u0026gt; \u0026lt;display-name\u0026gt;ACN Web Application\u0026lt;/display-name\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;listener\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.springframework.web.servlet.DispatcherServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;load-on-startup\u0026gt;1\u0026lt;/load-on-startup\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;listener\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;context-param\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;/WEB-INF/listener-servlet.xml\u0026lt;/param-value\u0026gt; \u0026lt;/context-param\u0026gt; \u0026lt;resource-ref\u0026gt; \u0026lt;description\u0026gt;Listener Database\u0026lt;/description\u0026gt; \u0026lt;res-ref-name\u0026gt;jdbc/listener-dss\u0026lt;/res-ref-name\u0026gt; \u0026lt;res-type\u0026gt;javax.sql.DataSource\u0026lt;/res-type\u0026gt; \u0026lt;res-auth\u0026gt;Container\u0026lt;/res-auth\u0026gt; \u0026lt;/resource-ref\u0026gt; \u0026lt;listener\u0026gt; \u0026lt;listener-class\u0026gt;org.springframework.web.context.ContextLoaderListener\u0026lt;/listener-class\u0026gt; \u0026lt;/listener\u0026gt; \u0026lt;welcome-file-list\u0026gt; \u0026lt;welcome-file\u0026gt;index.jsp\u0026lt;/welcome-file\u0026gt; \u0026lt;/welcome-file-list\u0026gt; \u0026lt;/web-app\u0026gt; Step 3: Next we will update the Spring context xml file to tell the Spring container that it needs to do a JNDI look up. My Spring context file name is listener-servlet.xml and this is under WEB-INF folder. Add the following(See highlighted section)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34; xmlns:mvc=\u0026#34;http://www.springframework.org/schema/mvc\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:tx=\u0026#34;http://www.springframework.org/schema/tx\u0026#34; xmlns:p=\u0026#34;http://www.springframework.org/schema/p\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd \u0026gt; \u0026lt;context:component-scan base-package=\u0026#34;com.acn.cslistener\u0026#34; /\u0026gt; \u0026lt;mvc:annotation-driven /\u0026gt; \u0026lt;tx:annotation-driven/\u0026gt; \u0026lt;bean class=\u0026#34;org.springframework.web.servlet.view.InternalResourceViewResolver\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;prefix\u0026#34;\u0026gt; \u0026lt;value\u0026gt;/WEB-INF/pages/\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;suffix\u0026#34;\u0026gt; \u0026lt;value\u0026gt;.jsp\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;sessionFactory\u0026#34; class=\u0026#34;org.springframework.orm.hibernate4.LocalSessionFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;dataSource\u0026#34; ref=\u0026#34;dataSource\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;hibernateProperties\u0026#34;\u0026gt; \u0026lt;props\u0026gt; \u0026lt;prop key=\u0026#34;hibernate.dialect\u0026#34;\u0026gt;org.hibernate.dialect.Oracle10gDialect\u0026lt;/prop\u0026gt; \u0026lt;prop key=\u0026#34;hibernate.show_sql\u0026#34;\u0026gt;true\u0026lt;/prop\u0026gt; \u0026lt;/props\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;packagesToScan\u0026#34; value=\u0026#34;com.acn.cslistener\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;dataSource\u0026#34; class=\u0026#34;org.springframework.jndi.JndiObjectFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;jndiName\u0026#34; value=\u0026#34;java:comp/env/jdbc/listener-dss\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;transactionManager\u0026#34; class=\u0026#34;org.springframework.orm.hibernate4.HibernateTransactionManager\u0026#34; p:sessionFactory-ref=\u0026#34;sessionFactory\u0026#34;\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;persistenceAnnotation\u0026#34; class=\u0026#34;org.springframework.orm.jpa.support.PersistenceAnnotationBeanPostProcessor\u0026#34; /\u0026gt; \u0026lt;/beans\u0026gt; Step 4: This is the crucial step. If you are using Jboss then it requires that you tell the web container that Jboss will provide the datasource .xml file where you have defined your jndi properties. Create a new file jboss-web.xml. Place this file under WEB-INF folder. The contents of the file whould like this.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;jboss-web\u0026gt; \u0026lt;resource-ref\u0026gt; \u0026lt;res-ref-name\u0026gt;jdbc/listener-dss\u0026lt;/res-ref-name\u0026gt; \u0026lt;res-type\u0026gt;javax.sql.DataSource\u0026lt;/res-type\u0026gt; \u0026lt;jndi-name\u0026gt;java:/jdbc/listener-dss\u0026lt;/jndi-name\u0026gt; \u0026lt;/resource-ref\u0026gt; \u0026lt;/jboss-web\u0026gt; That\u0026rsquo;s all we need to do.\n","description":"","id":30,"section":"posts","tags":null,"title":"How to configure JNDI with Spring and Jboss4/5","uri":"/2013/09/18/how-to-configure-jndi-with-spring-and-jboss45/"},{"content":"It’s been a while I have posted anything. I have been extremly busy and have been working on an extremely critical project where we were asked to become PCI 2.0 compliant. I worked on some interesting problems however today I will be discussing on something trivial and discuss my frustration about Rails. I have to admit that a number of times I thought I should just give up and start learning Python or stick to my forte i.e. Java. BUT Ruby/Rails has been a love hate relationship for me. Every few months I pick up Rails again and struggle fixing the set up before I can start working on my website.\nSo a couple of months back my wife complained that she is not using her website to update client’s picture because there is no client login and the if she upload their album, the album is visible to everyone. So I fixed that and deployed the application. No issues.\nSo two months later about a week ago, I checked again with her and like all nagging wife she complained that she is still not using it because she cannot upload multiple images. So like a dutiful husband I set out to set up rails on my new mac and begin coding however my production branch was not working fine. I was seeing issue with flexslider and found that non of my images were not showing up and Rails complained that JQuery was not defined. I tried everything but I could not make it work.\nSo if you have been issues with JQuery make sure that you have checked these things:\nYour gem file should have this line. gem ‘jquery-rails’\ngem “flexslider” — This if you are using flexslider\nIn your application.js, make sure that you have defined jquery and the most important thing …… notice the sequence. //= require jquery_ujs\n//= require jquery\n//= require flexslider\n//= require_tree .\nMy sequence was incorrect and I had defined juqery before jquery_ujs which was throwing error in my application.\nHope this post helps.\n~Ciao\n","description":"","id":31,"section":"posts","tags":null,"title":"Rails: Jquery is not loading","uri":"/2013/08/01/rails-jquery-is-not-loading/"},{"content":"I am working a new project and I recently ran into an interesting problem. One of the web site that I keep up at work was supposed to take the user to another website which required me to add post parameters.\nEX - www.mywebsite.makeapayment.com ==\u0026gt; Collects Billing information ex - name, amount, address etc.==\u0026gt; Post this information to www.vendor-website.com.\nI did not realize the problem until I started coding and my colleague pointed out that as soon as www.mywebsite.makeapayment.com goes to my servlet, the servlet will not pass params to external web site if use \u0026ldquo;POST\u0026rdquo;, I had to use \u0026ldquo;GET\u0026rdquo; because servlet will look up relative path only and the HTTPServletRequest/Response object is specific to an application. So if I wanted to send parameters using servlet I could only that using action = GET. Now since I was passing sensitive information so I did not want to use GET.\nA couple of solutions were discussed as follows:\nInsert the params in database and use servlet get from the mywebsite.com to pass the primary key of the database. Ex - www.mywebsite.makeapayment.com ==\u0026gt; www.vendor-website.com?key=10001. The vendor application look up the required params from the database.\nCreate a new JSP and use JavaScript onLoad() to pass the params as Hidden Input and submit as post to www.vendor-website.com.\nEx - www.mywebsite.makeapayment.com==\u0026gt; Servlet==\u0026gt; New Blank JSP with Hidden params loaded on onLoad() and submitted to vendor website ==\u0026gt; www.vendor-website.com.\nThird approach is interesting and I had not tried this ever but looked promising and this is what I eventually implemented. Make an Ajax call to from the JSP page to your servlet and when the Ajax Call returns, post it to vendor web site. Ex - www.mywebsite.makeapayment.com on hitting submit==\u0026gt; calls the JS, uses DWR to post to call the servlet==\u0026gt; Servlet does back ground processing like saving the records etc ==\u0026gt; Returns the control back to the JavaScript ==\u0026gt; Upon return in Ajax Call ==\u0026gt; Post to www.vendor-website.com.\nI implemented the combination of one and three but here I am going to show you how post params to a different URL - i.e. solution 3\nLet\u0026rsquo;s say I have a submit form with Name and address which needs to be saved in database when I submit the form and then I need to post the same information to different web site.\nPersonalInformation.jsp\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;script\u0026gt; \u0026gt; // I am not showing the code for DWR. You will need to include dwr and engine.js. Add dwr.xml in your web-inf and specify the class name and method you want to use as dwr call. This method is called in the dwr Ajax call back. function submitAndGoToVendorSite() var form = document.createElement(\u0026#34;FORM\u0026#34;); form.method = \u0026#34;POST\u0026#34;; form.style.display = \u0026#34;none\u0026#34;; document.body.appendChild(form); var url=\u0026#34;www.vendor-website.com\u0026#34;; form.action = url; //My dwr ajax call gets a Json string from the servlet response. var jsonString = \u0026#34;{\u0026#34;transactionId\u0026#34;:\u0026#34;1368505156670\u0026#34;,\u0026#34;requesterType\u0026#34;:\u0026#34;APP\u0026#34;,\u0026#34;billingEmail\u0026#34;:\u0026#34;null@cybersource.com\u0026#34;,\u0026#34;billingState\u0026#34;:\u0026#34;NC\u0026#34;,\u0026#34;amount\u0026#34;:\u0026#34;42.7699999999999999433786257441170164384\u0026#34;,\u0026#34;refund\u0026#34;:\u0026#34;N\u0026#34;,\u0026#34;billingCity\u0026#34;:\u0026#34;CONCORD\u0026#34;,\u0026#34;billingLine1\u0026#34;:\u0026#34;Progress Pl\u0026#34;,\u0026#34;billingFirstname\u0026#34;:\u0026#34;test\u0026#34;,\u0026#34;billingLine2\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;shopperIP\u0026#34;:\u0026#34;127.0.0.1\u0026#34;,\u0026#34;application\u0026#34;:\u0026#34;OEP2\u0026#34;,\u0026#34;currencyCode\u0026#34;:\u0026#34;USD\u0026#34;,\u0026#34;billingCompany\u0026#34;:\u0026#34;ACN\u0026#34;,\u0026#34;revenueSource\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;billingLastname\u0026#34;:\u0026#34;test\u0026#34;,\u0026#34;countryCode\u0026#34;:\u0026#34;US\u0026#34;,\u0026#34;billingAddrNum\u0026#34;:\u0026#34;1000\u0026#34;,\u0026#34;cardType\u0026#34;:\u0026#34;VISA\u0026#34;,\u0026#34;businessPurpose\u0026#34;:\u0026#34;TOOL\u0026#34;,\u0026#34;profileConfig\u0026#34;:\u0026#34;cybersource-MLTEST1\u0026#34;,\u0026#34;language\u0026#34;:\u0026#34;en\u0026#34;,\u0026#34;billingZip\u0026#34;:\u0026#34;28025\u0026#34;,\u0026#34;repOrCustID\u0026#34;:\u0026#34;1233836\u0026#34;,\u0026#34;user\u0026#34;:\u0026#34;DARORATEST\u0026#34;,\u0026#34;paymentMethod\u0026#34;:\u0026#34;CC\u0026#34;,\u0026#34;billingPhone\u0026#34;:\u0026#34;\u0026#34;}\u0026#39; // Create a JSON object from the JSON String var jsonObj = jQuery.parseJSON(jsonString); //Iterate over Json object and set them as hidden input params to the form for(obj in jsonObj) { var input = document.createElement(\u0026#34;INPUT\u0026#34;); input.type = \u0026#34;hidden\u0026#34;; input.name = obj; input.value = jsonObj[obj]; form.appendChild(input); } //Submit the form form.submit(); \u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form\u0026gt; \u0026lt;label\u0026gt;Name:\u0026lt;/label\u0026gt;\u0026lt;Input type=\u0026#34;text\u0026#34;/\u0026gt; \u0026amp;#8230;\u0026amp;#8230;\u0026amp;#8230;. \u0026lt;input type=\u0026#34;button\u0026#34; onclick=\u0026#34;submitAndGoToVendorSite();\u0026#34;/\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; That\u0026rsquo;s It!\n~Keep Coding\n","description":"","id":32,"section":"posts","tags":null,"title":"How to post parameters to a url using Ajax/Javascript between two website","uri":"/2013/05/15/how-to-post-parameters-to-a-url-using-ajaxjavascript-between-two-website/"},{"content":"It’s possible that many of you already knew this but if not then here’ some basic info on Maven profiles. I have been using maven for over 2 and half years now, and have been copy pasting assembly and install files. I never bothered to know how Maven figures out how to read assembly and install file names. For example-\nPROBLEM:\nFor all my projects I have been using assembly-jboss.xml to put the file/directory information and telling maven about my desired directory structure i.e. Pick files from a/b directory and put it in out directory c/d. The second file install-jboss.xml where I specify my panels, target files etc. It never occurred to me what happens if I change the file names to assembly-zzz.xml and intsall-zzz.xml.\nWell to cut the story short I checked out a fellow developer code on my machine and the command\nmvn clean install\nthrew build error which said -\n[1] [INFO] Searching for file location: C:\\Dinesh\\workspace\\prov-ld-anin-trunk\\artifacts\\src\\assembly\\assembly-jboss4.xml [2] [INFO] File: C:\\Dinesh\\workspace\\prov-ld-anin-trunk\\artifacts\\src\\assembly\\assembly-jboss4.xml does not exist. [3] [INFO] File: C:\\Dinesh\\workspace\\prov-ld-anin-trunk\\src\\assembly\\assembly-jboss4.xml does not exist. Now I was using IZPack plugin and always thought the assembly and install xmls are part of IZPack configuration, so for half an hour I was searching “IZPack assembly descriptor”. Needless to say I did not get any releveant search result. After scratching my head a little and doing a text search in Eclipse to figure out how am I telling maven to find the specific files (in my case the fellow developer had named them as assembly-wso2carbon40.xml and install-wso2carbon40.xml). No results.\nSOLUTION:\nIn Maven you set up a profile in your .m2/settings.xml. For example my settings.xml looks like this\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;settings\u0026gt; \u0026lt;profiles\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;jboss4\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.home\u0026gt;\u0026lt;/java.home\u0026gt; \u0026lt;compileSource\u0026gt;1.5\u0026lt;/compileSource\u0026gt; \u0026lt;server\u0026gt;jboss4\u0026lt;/server\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt; \u0026lt;/settings\u0026gt; If you will notice I have specified that jboss4 tag has value jboss4. When maven is building your app, it looks for two files assemby-xxx.xml and install-xxx.xml. Here xxxin assembly-xxx.xml is the profile name. So in my case it looks in the settings.xml and sees that profile is jboss, so it uses to find a file assembly-jboss.xml and install-jboss4.xml.\nSo now the problem was that my developer friend had named the files as assembly-wso2Carbon40.xml and install-wso2Carbon40.xml. The first thing that came to my mind was let’s change the **jboss4**to ****wso2, that would resolve my issue. However I had other application where the file was named assembly-jboss.xml and install-jboss4.xml, which meant that my other application will error out on maven clean install and throw error message could not locate assembly file assembly-wso2Carbon40.xml .\nHere’s comes the neat part, you can have multiple profiles in your settings file. So I updated my .m2/settings.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u0026lt;settings\u0026gt; \u0026lt;profiles\u0026gt; \u0026lt;profile\u0026gt; **\u0026lt;id\u0026gt;jboss\u0026lt;/id\u0026gt;** \u0026lt;properties\u0026gt; \u0026lt;svn.username\u0026gt;\u0026lt;/svn.username\u0026gt; \u0026lt;svn.password\u0026gt;\u0026lt;/svn.password\u0026gt; \u0026lt;java.home\u0026gt;\u0026lt;/java.home\u0026gt; \u0026lt;compileSource\u0026gt;1.5\u0026lt;/compileSource\u0026gt; \u0026lt;server\u0026gt;jboss4\u0026lt;/server\u0026gt; \u0026lt;server.home\u0026gt;C:Program Filesjboss-eap-4.3\u0026lt;/server.home\u0026gt; \u0026lt;server.port\u0026gt;80\u0026lt;/server.port\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;wso2\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;compileSource\u0026gt;1.5\u0026lt;/compileSource\u0026gt; \u0026lt;server\u0026gt;wso2carbon40\u0026lt;/server\u0026gt; \u0026lt;/properties\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt; \u0026lt;/settings\u0026gt; Now when you build the project using Eclipse, just got to Run As ==\u0026gt; Maven Build … and enter Goals = clean install and Profile = wso2\nThat’s it!\n~~Cheers!\n","description":"","id":33,"section":"posts","tags":null,"title":"Using multiple profiles in Maven + Eclipse","uri":"/2013/03/07/using-multiple-profiles-in-maven-eclipse/"},{"content":"For the last one month, I have been working on an android app for a grocery store.\nI have been using PhoneGap to develop the solution as the client wanted both Android and Iphone version.\nI have tried building the app in native Android but going through the hassle of designing css was just too much for me and plus I did not had time to learn Iphone development.\nThere was a short learning phase for PhoneGap and the results were awesome. However there was one area where I spent hours and ran into several issues. The customer wanted a Feedback section where the user could fill in feedback in a TextArea and hits Submit, which would send an email to customer in the background.\nNow PhoneGap has plugin called WebIntent which will open a Email composer where you have to hit Send. This is not what I wanted as customer would have to hit a SUBMIT button, which would open a Email composer window on Phone and then hit Send again. Also this solution also meant user’s email address would be displayed to Grocery store.\nI wanted to send the feedback in the background anonymously to Grocery store. I decided to use Java email Api and create a dummy email for grocery store which would be used to send feedback to the Grocery store’s main email address.\nI did not find any good tutorial except this one. This is an incomplete tutorial and did not tell you how to create Java classes for Plugin or that you had to make entries in config.xml. So here is the actual tutorial.\nBefore I begin, let me tell you that I am using latest version of Cordova 2.1.0. This is will not work for Cordova 1.9.0(I will explain the issue below).\nStep 1: Add cordova-2.1.0.jar in the project classpath\nStep 2: Add cordova-2.1.0.js in the assets/www/js folder.\nStep 3: create a new Java class called EmailComoposer.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 package com.dinesh.pb; import org.apache.cordova.api.Plugin; import org.apache.cordova.api.PluginResult; import org.apache.cordova.api.PluginResult.Status; import org.json.JSONArray; import org.json.JSONException; import android.annotation.SuppressLint; import android.content.Intent; import android.text.Html; import com.dinesh.pb.utility.Mail; @SuppressLint(\u0026#34;ParserError\u0026#34;) public class EmailComposer extends Plugin { public final String ACTION_SEND_EMAIL = \u0026#34;sendEmail\u0026#34;; @Override public PluginResult execute(String action, JSONArray arg1, String callbackId) { PluginResult result = new PluginResult(Status.INVALID_ACTION); if (action.equals(ACTION_SEND_EMAIL)) { try { String message = arg1.getString(0); this.sendEmailViaGmail(message); result = new PluginResult(Status.OK); } catch (JSONException ex) { result = new PluginResult(Status.JSON_EXCEPTION, ex.getMessage()); } catch (Exception e) { // TODO Auto-generated catch block e.printStackTrace(); } } return result; } private void sendEmailViaGmail(String body) throws Exception{ Mail m = new Mail(\u0026#34;From_email_address@gmail.com\u0026#34;, \u0026#34;your password\u0026#34;); String[] toArr = {\u0026#34;TO_EMAIL_ADDRESS@gmail.com\u0026#34;}; m.set_to(toArr); m.set_from(\u0026#34;FROM_EMAIL_ADDRESS@gmail.com\u0026#34;); m.set_body(body); m.set_subject(\u0026#34;TEST SUBJECT\u0026#34;); boolean sendFlag = m.send(); } } Step 4. copy this Mail.java in package of your choice. My package name is com.dinesh.pb.utility.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 package com.dinesh.pb.utility; import java.util.Date; import java.util.Properties; import javax.activation.CommandMap; import javax.activation.DataHandler; import javax.activation.DataSource; import javax.activation.FileDataSource; import javax.activation.MailcapCommandMap; import javax.mail.BodyPart; import javax.mail.Multipart; import javax.mail.PasswordAuthentication; import javax.mail.Session; import javax.mail.Transport; import javax.mail.internet.InternetAddress; import javax.mail.internet.MimeBodyPart; import javax.mail.internet.MimeMessage; import javax.mail.internet.MimeMultipart; public class Mail extends javax.mail.Authenticator { private String _user; private String _pass; private String[] _to; private String _from; private String _port; private String _sport; private String _host; private String _subject; private String _body; private boolean _auth; private boolean _debuggable; private Multipart _multipart; public Mail() { _host = \u0026#34;smtp.gmail.com\u0026#34;; // default smtp server _port = \u0026#34;465\u0026#34;; // default smtp port _sport = \u0026#34;465\u0026#34;; // default socketfactory port _user = \u0026#34;\u0026#34;; // username _pass = \u0026#34;\u0026#34;; // password _from = \u0026#34;\u0026#34;; // email sent from _subject = \u0026#34;\u0026#34;; // email subject _body = \u0026#34;\u0026#34;; // email body _debuggable = false; // debug mode on or off - default off _auth = true; // smtp authentication - default on _multipart = new MimeMultipart(); // There is something wrong with MailCap, javamail can not find a handler for the multipart/mixed part, so this bit needs to be added. MailcapCommandMap mc = (MailcapCommandMap) CommandMap.getDefaultCommandMap(); mc.addMailcap(\u0026#34;text/html;; x-java-content-handler=com.sun.mail.handlers.text_html\u0026#34;); mc.addMailcap(\u0026#34;text/xml;; x-java-content-handler=com.sun.mail.handlers.text_xml\u0026#34;); mc.addMailcap(\u0026#34;text/plain;; x-java-content-handler=com.sun.mail.handlers.text_plain\u0026#34;); mc.addMailcap(\u0026#34;multipart/*;; x-java-content-handler=com.sun.mail.handlers.multipart_mixed\u0026#34;); mc.addMailcap(\u0026#34;message/rfc822;; x-java-content-handler=com.sun.mail.handlers.message_rfc822\u0026#34;); CommandMap.setDefaultCommandMap(mc); } public Mail(String user, String pass) { this(); _user = user; _pass = pass; } public boolean send() throws Exception { Properties props = _setProperties(); if(!_user.equals(\u0026#34;\u0026#34;) \u0026amp;\u0026amp; !_pass.equals(\u0026#34;\u0026#34;) \u0026amp;\u0026amp; _to.length \u0026gt; 0 \u0026amp;\u0026amp; !_from.equals(\u0026#34;\u0026#34;) \u0026amp;\u0026amp; !_subject.equals(\u0026#34;\u0026#34;) \u0026amp;\u0026amp; !_body.equals(\u0026#34;\u0026#34;)) { Session session = Session.getInstance(props, this); MimeMessage msg = new MimeMessage(session); msg.setFrom(new InternetAddress(_from)); InternetAddress[] addressTo = new InternetAddress[_to.length]; for (int i = 0; i \u0026lt; _to.length; i++) { addressTo[i] = new InternetAddress(_to[i]); } msg.setRecipients(MimeMessage.RecipientType.TO, addressTo); msg.setSubject(_subject); msg.setSentDate(new Date()); // setup message body BodyPart messageBodyPart = new MimeBodyPart(); messageBodyPart.setText(_body); _multipart.addBodyPart(messageBodyPart); // Put parts in message msg.setContent(_multipart); // send email Transport.send(msg); return true; } else { return false; } } public void addAttachment(String filename) throws Exception { BodyPart messageBodyPart = new MimeBodyPart(); DataSource source = new FileDataSource(filename); messageBodyPart.setDataHandler(new DataHandler(source)); messageBodyPart.setFileName(filename); _multipart.addBodyPart(messageBodyPart); } public String[] get_to() { return _to; } public void set_to(String[] _to) { this._to = _to; } public String get_from() { return _from; } public void set_from(String _from) { this._from = _from; } public String get_body() { return _body; } public void set_body(String _body) { this._body = _body; } @Override public PasswordAuthentication getPasswordAuthentication() { return new PasswordAuthentication(_user, _pass); } private Properties _setProperties() { Properties props = new Properties(); props.put(\u0026#34;mail.smtp.host\u0026#34;, _host); if(_debuggable) { props.put(\u0026#34;mail.debug\u0026#34;, \u0026#34;true\u0026#34;); } if(_auth) { props.put(\u0026#34;mail.smtp.auth\u0026#34;, \u0026#34;true\u0026#34;); } props.put(\u0026#34;mail.smtp.port\u0026#34;, _port); props.put(\u0026#34;mail.smtp.socketFactory.port\u0026#34;, _sport); props.put(\u0026#34;mail.smtp.socketFactory.class\u0026#34;, \u0026#34;javax.net.ssl.SSLSocketFactory\u0026#34;); props.put(\u0026#34;mail.smtp.socketFactory.fallback\u0026#34;, \u0026#34;false\u0026#34;); return props; } public String get_subject() { return _subject; } public void set_subject(String _subject) { this._subject = _subject; } // more of the getters and setters ….. } Step 5: Update the config.xml and add the details about the new plugin class EmailComposer.java.\nMine looks like this -\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 \u0026lt;plugin name=\u0026#34;EmailComposer\u0026#34; value=\u0026#34;com.dinesh.pb.EmailComposer\u0026#34;/\u0026gt;. Please update the package name value=\u0026#34;com.dinesh.pb.EmailComposer\u0026#34; with your package path. \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;cordova\u0026gt; \u0026lt;access origin=\u0026#34;http://127.0.0.1*\u0026#34;/\u0026gt; \u0026lt;!-- allow local pages --\u0026gt; \u0026lt;access origin=\u0026#34;.*\u0026#34;/\u0026gt; \u0026lt;log level=\u0026#34;DEBUG\u0026#34;/\u0026gt; \u0026lt;preference name=\u0026#34;useBrowserHistory\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;preference name=\u0026#34;exit-on-suspend\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin name=\u0026#34;App\u0026#34; value=\u0026#34;org.apache.cordova.App\u0026#34;/\u0026gt; \u0026lt;plugin name=\u0026#34;Geolocation\u0026#34; value=\u0026#34;org.apache.cordova.GeoBroker\u0026#34;/\u0026gt; \u0026lt;plugin name=\u0026#34;Device\u0026#34; value=\u0026#34;org.apache.cordova.Device\u0026#34;/\u0026gt; \u0026lt;plugin name=\u0026#34;Accelerometer\u0026#34; value=\u0026#34;org.apache.cordova.AccelListener\u0026#34;/\u0026gt; \u0026lt;plugin name=\u0026#34;Compass\u0026#34; value=\u0026#34;org.apache.cordova.CompassListener\u0026#34;/\u0026gt; \u0026lt;plugin name=\u0026#34;Media\u0026#34; value=\u0026#34;org.apache.cordova.AudioHandler\u0026#34;/\u0026gt; \u0026lt;plugin name=\u0026#34;Camera\u0026#34; value=\u0026#34;org.apache.cordova.CameraLauncher\u0026#34;/\u0026gt; \u0026lt;plugin name=\u0026#34;Contacts\u0026#34; value=\u0026#34;org.apache.cordova.ContactManager\u0026#34;/\u0026gt; \u0026lt;plugin name=\u0026#34;File\u0026#34; value=\u0026#34;org.apache.cordova.FileUtils\u0026#34;/\u0026gt; \u0026lt;plugin name=\u0026#34;NetworkStatus\u0026#34; value=\u0026#34;org.apache.cordova.NetworkManager\u0026#34;/\u0026gt; \u0026lt;plugin name=\u0026#34;Notification\u0026#34; value=\u0026#34;org.apache.cordova.Notification\u0026#34;/\u0026gt; \u0026lt;plugin name=\u0026#34;Storage\u0026#34; value=\u0026#34;org.apache.cordova.Storage\u0026#34;/\u0026gt; \u0026lt;plugin name=\u0026#34;Temperature\u0026#34; value=\u0026#34;org.apache.cordova.TempListener\u0026#34;/\u0026gt; \u0026lt;plugin name=\u0026#34;FileTransfer\u0026#34; value=\u0026#34;org.apache.cordova.FileTransfer\u0026#34;/\u0026gt; \u0026lt;plugin name=\u0026#34;Capture\u0026#34; value=\u0026#34;org.apache.cordova.Capture\u0026#34;/\u0026gt; \u0026lt;plugin name=\u0026#34;Battery\u0026#34; value=\u0026#34;org.apache.cordova.BatteryListener\u0026#34;/\u0026gt; \u0026lt;plugin name=\u0026#34;SplashScreen\u0026#34; value=\u0026#34;org.apache.cordova.SplashScreen\u0026#34;/\u0026gt; \u0026lt;plugin name=\u0026#34;Echo\u0026#34; value=\u0026#34;org.apache.cordova.Echo\u0026#34; /\u0026gt; \u0026lt;plugin name=\u0026#34;EmailComposer\u0026#34; value=\u0026#34;com.dinesh.pb.EmailComposer\u0026#34;/\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/cordova\u0026gt;\u0026lt;/pre\u0026gt; Step 6: Create a new javascript file called email.js\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 var EmailComposer = function(){}; /* cordova.addConstructor(function() { cordova.addPlugin(\u0026#34;emailcomposer\u0026#34;, new EmailComposer()); }); */ EmailComposer.prototype.send = function (message){ console.log(\u0026#34;Calling the send message\u0026#34;); cordova.exec(function(){ alert(\u0026#39;feedback sent\u0026#39;)}, function(){ alert(\u0026#39;feedback was not sent\u0026#39;)}, \u0026#39;EmailComposer\u0026#39;, \u0026#39;sendEmail\u0026#39;, [message]); } function sendFeedback(){ window.EmailComposer.prototype.send(\u0026#34;My message body\u0026#34;); } Now as I mentioned earlier that I am using cordova-2.1.0.js/jar file there are subtle differences between the latest version and older version (cordova-1.9.0). If you are using older version you will need to uncomment the section cordova.addConstructorabove and instead of calling\nwindow.EmailComposer.prototype.send(\u0026ldquo;My message body\u0026rdquo;);\nUse this:\nwindow.plugins.emailComposer.prototype.send(body);\nIf you do not use it then you may get error which would say that window.plugins is not defined. If you run into such issues use firebug and see what variables are defined under “window\u0026quot; variable.\nNotice the method called “feedback()\u0026quot;. I am simply passing the user text as message body by capturing the input from user feedback TextBox. For simplicity I have just pasted a default Email body.\nStep 7: Include the js file in your index.html file\n1 2 3 4 5 6 7 8 9 10 11 12 13 // \u0026lt;!-[CDATA[ \u0026#34;javascript\u0026#34; src=\u0026#34;js/email.js\u0026#34;\u0026gt; // ]]\u0026gt; Step 8: Include cordova js file in index.html // \u0026lt;!-[CDATA[ javascript\u0026#34; src=\u0026#34;js/cordova-2.1.0.js\u0026#34;\u0026gt; // ]]\u0026gt; Step 9: Add three jar files for Java mail api - namely, Activation.jar, Mail.jar and Additional.jar in the libs folder and add it to the classpath. You can these files here.\nCheers!!\nUPDATE: A lot of people commented that they could not find mail.jar,additional.jar and actication.jar so I have uploaded them on 4shared.com. You can download them from the link below.\nActivation.jar\nAdditional.jar\nMail.jar\n","description":"","id":34,"section":"posts","tags":null,"title":"How to send email in PhoneGap (Android) using a gmail account","uri":"/2012/09/23/how-to-send-email-in-phonegap-android-using-a-gmail-account/"},{"content":"So what\u0026rsquo;s new here? Well I was playing around with Phonegap to build a small android and ios app. I was able to build a small weather app using Yahoo weather api but then I came across Sencha Touch 2.\nI wanted to build the same app in Sencha Touch and compare the two platforms for developing mobile apps and as ap part of its get started tutorial I had to drop the Sencha Touch in a web server. Now as it always happens with me the most simplest of things don\u0026rsquo;t work properly for me. I turned on apache server on my mac and added my directory on /etc/apache2/httpd.conf along with and Alias but that did not work out. I constantly ran in forbidden 403 error and tried everything described in various forums but nothing worked and then I came across a post which showed me an alternative way to run a webserver and access my folder without the hassle of apache2 httpd.conf file changes.\nIt\u0026rsquo;s really simple, all you need to do is figure out which folder you want to get access to on web server. In my case I wanted to share /Users/dinesharora/Desktop/Mydocument/softwares/sencha-touch-2\nso here are the steps:\nOpen the terminal\ncd /Users/dinesharora/Desktop/Mydocument/softwares/sencha-touch-2\ntype python -m SimpleHTTPServer\nHit enter\nYou will see a message - Serving HTTP on 0.0.0.0 port 8000 Now if for some reason you are a stickler and like the old-fashioned 8080 port then just type 1 python -m SimpleHTTPServer 8080 That\u0026rsquo;s it. Now access your folder via http://localhost:8000/. If you want to get access to this over another machine then just type http://localhost:8080, so for example in my case it would be http://dinesharora.local:8080\nNow you know how to fly a plane, but do you know how to do a safe landing?? Just hit control +c to shut down the server. Dumb!!\nCheers!!\n** **\n","description":"","id":35,"section":"posts","tags":null,"title":"How To Share Any Folder On Mac Via Built-in Web Server","uri":"/2012/07/13/share-any-folder-on-mac-via-built-in-web-server/"},{"content":"Long long time ago in a far far away land….. I am just kidding. So I needed a gem to do file uploads(in my case images but you can upload anything) and I was looking at various options. Paperclip is a popular option but there is a new kid on the block (so i read in various forums)… Carrierwave.\nNow I have not used Paperclip but what I read was that Carrierwave is more flexible and powerful than Paperclip so if are interested then keep reading. Now let me tell you that you may need to do some additional settings, I will not get into details because the wiki page of Carrierwave is pretty intensive. The purpose of writing this post is to highlight a couple of issue that I ran into and some settings which were not explained.\nStep 1: Install the Carrierwave gem\ngem install carrierwave** Step 2: Update the gem file\ngem carrierwave Step 3: Now you need a uploader. This is the file which has all the settings like which folder the image will be saved, setting the image quality, caching etc. I wanted to call my uploader class as ImageUploader\nrails generate uploader ImageUploader Step 4: Install fog gem\ngem install fog Step 5: Update gem file\ngem \u0026#39;fog\u0026#39;, \u0026#39;\u0026#39;~\u0026gt; 1.3.1\u0026#39; bundle install Step 6: Choose the storage type\n1 2 3 4 5 ImageUploader \u0026lt; CarrierWave::Uploader::Base storage :fog end Step 7: Create model. Mine was called Photo so I create photo.rb. Notice the line number 10.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Photo \u0026lt; ActiveRecord::Base #Attributes or fileds attr_accessible :image,:pic_name,:description,:albums_id #associations belongs_to :albums #carrier wave mount_uploader :image,**ImageUploader** #Validations validates :description,:pic_name,:albums_id, :presence=\u0026gt;true validates_uniqueness_of :pic_name end Step 7: How to upload file and show uploaded file in the html page\nUpload page:\n1 2 3 4 5 6 7 \u0026lt;%= form_for @user, :html =\u0026gt; {:multipart =\u0026gt; true} do |f| \u0026gt; \u0026lt;p\u0026gt; \u0026lt;label\u0026gt;My Avatar\u0026lt;/label\u0026gt; \u0026lt;%= f.file_field :avatar \u0026gt; \u0026lt;%= f.hidden_field :avatar_cache \u0026gt; \u0026lt;/p\u0026gt; \u0026lt;% end \u0026gt; View uploaded image\n\u0026lt;%= form_for @user, :html =\u0026gt; {:multipart =\u0026gt; true} do |f| \u0026gt; \u0026lt;p\u0026gt; \u0026lt;label\u0026gt;My Avatar\u0026lt;/label\u0026gt; \u0026lt;%= image_tag(@user.avatar_url) if @user.avatar? \u0026gt; \u0026lt;%= f.file_field :avatar \u0026gt; \u0026lt;%= f.hidden_field :avatar_cache \u0026gt; \u0026lt;/p\u0026gt; \u0026lt;% end \u0026gt; Step 8: Now comes the most important part. Setting up fog. Now if you follow the documentation on Carrierwave then you will run into issue(I will explain the issue and fix below). The wiki page said create a file **fog.rb **in the **lib/carrierwave/storage/fog.rb **and that\u0026rsquo;s what I did. I created the file with the contents below.\n1 2 3 4 5 6 7 8 9 10 11 12 CarrierWave.configure do |config| config.fog_credentials = { :provider =\u0026gt; \u0026#39;AWS\u0026#39;, # required :aws_access_key_id =\u0026gt; \u0026#39;xxx\u0026#39;, # required :aws_secret_access_key =\u0026gt; \u0026#39;yyy\u0026#39;, # required :region =\u0026gt; \u0026#39;eu-west-1\u0026#39; # optional, defaults to \u0026#39;us-east-1\u0026#39; } config.fog_directory = \u0026#39;name_of_directory\u0026#39; # required config.fog_host = \u0026#39;https://assets.example.com\u0026#39; # optional, defaults to nil config.fog_public = false # optional, defaults to true config.fog_attributes = {\u0026#39;Cache-Control\u0026#39;=\u0026gt;\u0026#39;max-age=315576000\u0026#39;} # optional, defaults to {} end Now before you start you need to have a S3 account on Amazon S3. So get your Amazon access key and secret access key. For example mine was …. hehehe no I am not going to share my access keys with you :-). Anyway if you forgot to note down your access key and incase you are wondering where I can find that and are guessing that it will be on S3 Dashboard then you are mistaken just like me. You can find that on your account settings –\u0026gt; Security credentials.\nSo after you have noted down your key and access key. Go ahead create a bucket on S3. A bucket is nothing but a directory. It\u0026rsquo;s just a fancy shimancy name for directory that Amazon came up with. You can further create sub directories.\nNow coming back to the meaty part and **fog.rb **file. I updated the below fields in the fog.rb\n1 2 :aws_access_key_id =\u0026gt; \u0026#39;xxx\u0026#39;, # required :aws_secret_access_key =\u0026gt; \u0026#39;yyy\u0026#39;, # required I commented out the below lines as they are optional\n1 2 #:region=\u0026gt; eu-west-1 # optional, defaults to us-east-1 I was not sure what was my region so if you are not sure as well then go ahead and comment it.\n1 2 3 4 #config.fog_host = https://s3.amazonaws.com\u0026#39; # optional, defaults to nil #config.fog_public = true # optional, defaults to true If you leave\nconfig.fog_host to https://s3.amazonaws.com\nthen I ran into issues which said\nLoadError (Expected /Users/dinesharora/Desktop/Mydocument/ruby-proj/album/app/uploaders/image_uploader.rb to define ImageUploader): So I commented that field. The next part that I was not sure about was how to tell fog which folder or directory I want to upload my files. I had created a bucket(directory) called **myalbums **and had created a sub folder called devlopment.\nSo I updated\nconfig.fog_directory = myalbums/development which did not work. The right way to do is\nconfig.fog_directory = myalbums and also in **ImageUploader **update the line\ndef store_dir development/uploads/#{model.class.to\\_s.underscore}/#{mounted\\_as}/#{model.id} end That\u0026rsquo;s it. Now just start the server and start uploading, that\u0026rsquo;s what the forums said but as it always happens with me(nothing works for me the first time) I ran into error(as I mentioned earlier that you will if you create the fog.rb in lib/carrierwave/storage/ folder) which said\n1 2 3 4 5 6 7 8 9 10 11 12 **ActionController::RoutingError (uninitialized constant CarrierWave::Storage::Fog):** **app/uploaders/image_uploader.rb:11:in \\`\u0026lt;class:ImageUploader\u0026gt;\u0026#39;** **app/uploaders/image_uploader.rb:3:in \\`\u0026lt;top (required)\u0026gt;\u0026#39;** **app/models/photo.rb:10:in \\`\u0026lt;class:Photo\u0026gt;\u0026#39;** **app/models/photo.rb:1:in \\`\u0026lt;top (required)\u0026gt;\u0026#39;** **app/controllers/photo_controller.rb:1:in \\`\u0026lt;top (required)\u0026gt;\u0026#39;** To get rid of this error, just copy the file in **config/initializers **and now I could finally say – That\u0026rsquo;s it!!!! 🙂\n[1]: http://javahabit.com/wp-content/uploads/2012/06/screen-shot-2012-06-03-at-12-26-01-am1.png ","description":"","id":36,"section":"posts","tags":null,"title":"Saving files in Amazon S3 using Carrierwave and Fog Gem","uri":"/2012/06/03/saving-files-in-amazon-s3-using-carrierwave-and-fog-gem/"},{"content":"I struggled a lot doing this on my mac. I prepared steps and notes while I was upgrading. here are the steps for mac osx. This works for Mac OSX 10.6+\n============ Section 1 =================\nInstall and update Ruby 1.9 on MAC OSX Snow leopard 10.6.5\nInstall RVM\nInstallation instruction: http://rvm.beginrescueend.com/rvm/install/ – In Treminal Run the following command:\nbash \u0026lt; \u0026lt;( curl http://rvm.beginrescueend.com/releases/ … all-latest )\n– type in terminal: version=$(curl http://rvm.beginrescueend.com/releases/ … sion.txt);\n– type in terminal:\nmkdir -p ~/.rvm/src/ \u0026amp;\u0026amp; cd ~/.rvm/src/ \u0026amp;\u0026amp; curl -O http://rvm.beginrescueend.com/releases/ … on}.tar.gz | tar zxf – \u0026amp;\u0026amp; cd rvm-${version} \u0026amp;\u0026amp; ./install\n– The first time you install RVM, you must put the following line into your ~/.bash_profile at the very end, after all path loads etc:\n(If you do not have .bash_profile then open terminal.\nStart up Terminal\n• Type “cd ~/” to go to your home folder\n• Type “touch .bash_profile” to create your new file.\n• Edit .bash_profile with your favorite editor (or you can just type “open -e .bash_profile” to open it in TextEdit.\n• Type “. .bashrc” to reload .bashrc and update any functions you add.\n)\n– Update the .bash_profile and add this text.\n[[ -s “$HOME/.rvm/scripts/rvm” ]] \u0026amp;\u0026amp; . “$HOME/.rvm/scripts/rvm” # This loads RVM into a shell session.\n– Close the terminal and open a new terminal.\n– Check if rvm is installed correctly by typing\ntype rvm | head -1\nThis should show result : “rvm is a function ”\n– type : source ~/.rvm/scripts/rvm\n– type: rvm notes\n–\n=========== Section 2: After you have done section 1 above ======\nII Upgrade to ruby 1.9\n– Make sure that you installed rvm\nInstruction URL- http://asciicasts.com/episodes/200-rails-3-beta-and-rvm\n– type: rvm install 1.9.2\n– Check which version of ruby is installed so far by typing “rvm list”.\n– The new version of ruby will be active only until the terminal is open. To make ruby 1.9.2 as default version. Type: rvm 1.9.2 –default\n– If we want to return to previous version of the system. Then type: rvm system –default\nIII INSTALL RAILS 3\n– Type: gem install rails\nIV INSTALL FRESH COPY OF MYSQL\n– INSTRUCTION URL: http://weblog.rubyonrails.org/2009/8/30 … ow-leopard\n– First Stop the mysql server if it is running :\nsudo /opt/local/share/mysql5/mysql/mysql.server stop\n– Now download a fresh copy from this URL:\nhttp://weblog.rubyonrails.org/2009/8/30 … ow-leopard\n– Next Install the mysql.pkg → Next install MySQLStartupItem.pkg -→ Install MySQL.prefPane\n– The Mac OS X PKG of MySQL installs itself into\n`/usr/local/mysql-VERSION’ and also installs a symbolic link,\n`/usr/local/mysql’, that points to the new location. If a directory\nnamed `/usr/local/mysql’ exists, it is renamed to\n`/usr/local/mysql.bak’ first. Additionally, the installer creates the\ngrant tables in the `mysql’ database by executing `mysql_install_db’.\n– Start the MySql server from the System Prefernce pane and make sure that it runs.\n– Go to /usr/local/mysql/bin and type: ./mysql, This should start start the MYSQL prompt and you can execute the SQl statements.\n– Let us now secure the database by giving it a user id and password.\nIn the same package type: ./mysqladmin –u root password ISSUES:\nAccess Denied for local host after you have set root and password then you need to reset the password..\nStop the Server from preference pane. From /usr/local/mysql/bin folder type the following the terminal:\nsudo ./mysqld_safe — –skip-grant-tables . This will start the server. Type : ./mysql -u root mysql type: UPDATE user SET Password=PASSWORD(‘admin’) where USER=’root’; — This will set the password as admin. Restart the server from prefernce pane. Hope this helps. I used the exact same steps to upgrade to Rails 3.0.3 and ruby 1.9.2\n—Cheers!!!\nGo to forum Go to topic Go to post 14 dinesh19aug ","description":"","id":37,"section":"posts","tags":null,"title":"Installing Rails on Mac OSX","uri":"/2012/05/30/installing-rails-on-mac-osx/"},{"content":"Yes, there are still a few lost soul who still have a Hotmail account and I am one of them :-).\nI have used Iphone in the past and use an android phone now, however I always complained that I was not able to set up an IMAP account for Hotmail. I always had a POP3 account 🙁\nWhat does IMAP and POP3 mean? – For beginner who do not understand what is IMAP and POP3, here’s a small description.\na) POP3 – is a one way email checking. When you setup account on your iPhone, android or Microsoft outlook or any other email client and you download an email on your phone or on your desktop, it just downloads a copy of that email. So when you hit delete or read an email on your phone or desktop, it does not affect the email in the Hotmail account. Now most of us use Iphone o android phone these days to check emails. Now when you delete the email on phone, you still need to login on your Hotmail account to really delete email. As result when I login to Hotmail account after a month, there are hundreds of emails which I deleted on my phone and I have to go through each email to make sure that I do not delete an important email.\nb) IMAP – is a two-way email checking. When you read or delete and email on phone or any other email client such as OUTLOOK, the email is updated in your account as well. For example if you delete an email on your phone, it will be deleted from your account as well.\nSo here’s a run down of the process.\nIPHONE SETUP:\nGo to Settings – Mail, Contact, Calendars Click on Add Account… Choose Microsoft Exchange Fill in the fields shown (Leave domain blank and your login should be your email address) Click next and it will ask for server. Use m.hotmail.com Choose if you want your email, contacts or calendar synced. ANDROID PHONE SETUP:\nOpen the Mail app.\nHit the menu button \u0026gt; Add account\nEnter your hotmail e-mail address and password.\nPress Manual setup (don’t press Next!)\nFor account, select Exchange.\nOn the Server settings page, clear out the DomainUsername field and enter your hotmail address.\nChange the Server to m.hotmail.com (without the quotes).\nKeep the checkboxes the way they are (Use secure connection enabled, but don’t accept all SSL certificates)\nPress Next.\nOnce the server settings are confirmed, you’ll be asked for how far back you’d like to sync your e-mail, contacts and calendars.\nCheers!!!\n","description":"","id":38,"section":"posts","tags":null,"title":"Setting up IMAP settings for hotmail account on Iphone and android","uri":"/2012/05/29/setting-up-imap-settings-for-hotmail-account-on-iphone-and-android/"},{"content":"CAUTION: Please excuse the diction/grammar/spelling. It’s 3 AM and I am in a hurry to sleep as I need to drop my friends to airport in exactly 4 hrs.\nSo I was trying to set up this new application for my wife. I was using galleria plugin to show a slide like image. Everything was working fine in development so I decided to see how it would look like in production environment if it was deployed in a cloud or virtual server. So I ended up choosing engineyard because it gives you 500 free hours and you do not need to have dns name. Once the application is deployed on the server, you can view the application on temporary url.\nInstalling a rails app on engineyard is pretty easy, however tunneling (ssh) on to the server was a nightmare. I will cover the ssh experience in some other post. The main issue was my galleria plugin css, images and javascript was not showing correctly. After spending 2 days and mailing the engineyard (They pretty responsive and quick!!) I realized that there was an issue with application configuration. So I tried to run the application on my mac in production mode and found that galleria javascripts and css files were not loaded. The engineyard support told me that they were using passenger and Nginx. So I decided to install the same on my local and experiment.\nYou can install passenger with Nginx or apache. I used apache version initially but had some issues so decided to use nginx instead.\nOn an interesting note While I was still struggling to load galleria assets using passenger, I searched a lot site documentation, rails sites, forums etc., but none told me how to start and stop Nginx … call me dumb but that is something I did not find on any of the sites until I decided to go through the whole Nginx documentation and there it was… buried deep half way through the documentation :-). It should have been there on there installation page.\nSo this post is in two parts, the first part will walk you through passenger and Nginx installation and the second part will let you know the configuration changes in your rails app so that assets are loaded properly in production mode.\nPART 1: PASSENGER AND NGINX installation\nInstall passenger: Run this in your command line gem install passenger Install the Nginx: Run this in your command line passenger-install-nginx-module If you see permission errors which says that you do not have permission to install then try\nsudo passenger-install-nginx-module If you still get error which says\nCould not find RubyGem passenger (\u0026gt;= 0) (Gem::LoadError),\nthen you probably use rvm to maintain your ruby rails version. So in this case try\nrvmsudo passenger-install-nginx-module Now when the installation starts, it will ask you some basic question like should I install some file plugins or location of installation etc., just keep saying yes or hit enter to continue. The whole process will probably take 3-4 minutes to complete.\nUpdate the nginx configuration file By default nginx will be installed in /opt/nginx folder on your mac or linux system. I don’t know what is the default location for windows. On a lighter note do people actually use windows for RAILS development??? Seriously?? No offense but I have only met people who use windows to try out rails sample apps .\nOk I am done with bashing Windows users 🙂 So to update the configuration file go to nginx.conf file under\n/opt/nginx/conf and update the code under server tag. You can find more details about nginx configuration here.\nserver { **listen 80;** **server_name localhost;** **root /Users/dinesharora/Desktop/Mydocument/ruby-proj/album;** **passenger_enabled on;** **passenger\\_base\\_uri /Users/xxxxx/Desktop/Mydocument/ruby-proj/album;** After saving the file. Stop the Nginx server\nStop nginx by going into /opt/nginx/sbin. Then run this command\nsudo ./nginx -s stop To start just run\n./ngnix Start your passenger or application. Go to your rails app folder and run this command in the terminal\npassenger start (To stop ctrl+c) Now by default passenger should start in production mode, but mine did not. It started in development mode. The documentation said that it will start in production mode by default but id did not. After racking my brains and going through the whole documentation, I did not find anything. Guess what ……. the documentation is outdated on the site. I almost gave up on Rails development and was thinking about going back to Java/Spring/Grails or GWT, but decided to stick a little longer. Anyway too much blabbering about what I did and whined …. here’s how to check if your passenger is running in production or development mode.\nWhen you run you passenger start, you will in 3rd or fourth line something like this\nLog file: /Users/dinesharora/Desktop/Mydocument/ruby-proj/album/log/passenger.3000.log Environment: development Accessible via: http://0.0.0.0:3000/ If it is running in development mode, the you need to start your application using this command.\npassenger start -e production It goes without saying that if you run into permission issues, run it using sudo or rvmsudo\nSo that\u0026rsquo;s it. Your app is running and can be accessed via http://0.0.0.0:3000/. I mapped 0.0.0.0 to localhost :-). Anyway I was happy that my installation was successful(I struggled for 4-5 days), without any solutions.\nPART 2: ASSETS CONFIGURATION\nWell my happiness was short lived because my galleria plugin was not working. I initially thought it was an issue with galleria plugin so I switched it with other jquery image slide show plugin, but each had same issue, they all worked fine in development but were not loaded in production mode. I kept seeing this error in the production logs Routing error [get] /assets/javascripts/galleria/xxxx.js not found 404 error.\nEvery site said that Just set 1 config.assets.compile = true and it will start showing up. Well I believed that statement for 4 more days to no avail. I tried playing around with application.js (Sprockets gem built in Rails 3.x) bit it did not work. I included the galleria folder as well in the application.js but still no images.\nSo I had placed my galleria plugin /app/assets/javascripts/galleria and I had to access\njs file galleria/plugins/*.css files etc galleria/plugins/images etc. I tried placing them in app/assets, lib/assets, vendor/assets but nothing will work. Here are steps if you have the same issue.\nOpen production.rb and make sure you have added or uncommented the following\nCode is not reloaded between requests config.cache_classes = true Full error reports are disabled and caching is turned on config.consider\\_all\\_requests_local = false config.action\\_controller.perform\\_caching = true Disable Rails\u0026amp;#8217;s static asset server (Apache or nginx will already do this) config.serve\\_static\\_assets = false Compress JavaScripts and CSS config.assets.compress = true **\\# Don\u0026amp;#8217;t fallback to assets pipeline if a precompiled asset is missed** **config.assets.compile = true** **\\# Generate digests for assets URLs** **config.assets.digest = true** **config.i18n.fallbacks = true** **\\# Send deprecation notices to registered listeners** **config.active_support.deprecation = :notify** \\# config.assets.initialize\\_on\\_precompile = false config.assets.precompile += [“*.js”, “*.css”] —— This HAS TO BE ADDED and was the key. Unless you add this line galleria images or any other images which are sub folders in assets or controller specific or personal folder under app, vendor lib will not loaded.\nAfter you have made the above changes in production.rb file, Rails needs to compile js and css and put them in\npublic/assets folder. Now in development environment Rails does it for you but when you are in production, you need to generate assets. So while you are in you rails application folder run this command\nrake assets:precompile OR bundle exec rake\nassets:precompile This will attach fingerprint to all the images, css and js files and put them in public/assets folder. Read Rails documentation.\nNow start your application in production mode using\npassenger start -e production Open the application url.\nVoila!!! All the images show up.\nCheers\n","description":"","id":39,"section":"posts","tags":null,"title":"Engineyard, Rails 3.x, NGINX, PASSENGER ASSETS NOT DISPLAYED","uri":"/2012/01/28/engineyard-rails-3-x-nginx-passenger-assets-not-displayed/"}]