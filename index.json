[
{
	"uri": "/showcase/hugo/hugo-theme-zzo/",
	"title": "Hugo Zzo Theme",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "Make a blog with hugo zzo theme!",
	"content": ""
},
{
	"uri": "/showcase/hugo/hugo-theme-zdoc/",
	"title": "Hugo zDoc Theme",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "Make a documentation with hugo zdoc theme!",
	"content": ""
},
{
	"uri": "/",
	"title": "",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories/machine-learning/",
	"title": "Machine learning",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/posts/",
	"title": "Posts",
	"tags": ["index"],
	"categories": [],
	"series": [],
	"description": "Post page",
	"content": ""
},
{
	"uri": "/2020/01/27/logistics-regression-using-python/",
	"title": "Sick and tired of doing logistics regression the old way? read this",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "Machine learning tutorial using Logistics regression. This post in the machine learning series will walk you through the process of solving binary classification problems using python.",
	"content": "So far in the series we have learned about forms on regression models. Each of those models was used to solve a target variable that was a linear number.\nNow we enter a territory where target variables might not be that straight forward. The target variables would be in the form binary, category, etc. Basically anything other than a number. Ex - Cat vs Dog, Yes or No, Reg, Green or Blue.\nThis form of machine learning is called Classification. One of the first algorithms in this series is called Logistic Regression\nGoal: We are provided a set of data that contains, Gender, Age, Salary \u0026amp; Purchased. The goal is to predict whether a person will make a purchase given the parameters - Age and Salary.\nData Exploration 1 2 3  import numpy as np\rimport pandas as pd\rimport matplotlib.pyplot as plt   1 2  #Load the file\r dataset = pd.read_csv(\u0026#34;Social_Network_Ads.csv\u0026#34;)\r  1 2  #View the first 5 rows\r dataset.head()\r  \r\r.dataframe tbody tr th:only-of-type {\rvertical-align: middle;\r}\r.dataframe tbody tr th {\rvertical-align: top;\r}\r.dataframe thead th {\rtext-align: right;\r}\r\r\r\rUser ID\rGender\rAge\rEstimatedSalary\rPurchased\r\r\r\r\r0\r15624510\rMale\r19\r19000\r0\r\r\r1\r15810944\rMale\r35\r20000\r0\r\r\r2\r15668575\rFemale\r26\r43000\r0\r\r\r3\r15603246\rFemale\r27\r57000\r0\r\r\r4\r15804002\rMale\r19\r76000\r0\r\r\r\r\r\r1 2 3 4  male= dataset[dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Male\u0026#39;][\u0026#39;Gender\u0026#39;].size\rfemales = dataset[dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Female\u0026#39;][\u0026#39;Gender\u0026#39;].size\r  1 2 3 4 5 6  #Plot male vs female?\r gender = [\u0026#39;Male\u0026#39;, \u0026#39;Female\u0026#39;]\ry_pos = np.arange(2)\rgender_count = [male, females]\rx_pos = [i for i, _ in enumerate(gender)] # 0,1\r   1 2 3 4 5 6 7 8 9  plt.bar(x_pos, gender_count, color=\u0026#39;green\u0026#39;)\rplt.xlabel(\u0026#34;Gender\u0026#34;)\rplt.ylabel(\u0026#34;Count\u0026#34;)\rplt.title(\u0026#34;Male Vs Female\u0026#34;)\rplt.xticks(x_pos, gender) ##==\u0026gt; ([0,1], [Male, Female])\r plt.show()\r  1 2 3 4 5  #How many Men vs Female bought/Not Bought\r men_purchase = dataset[(dataset[\u0026#39;Purchased\u0026#39;]==1) \u0026amp; (dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Male\u0026#39;)][\u0026#39;Gender\u0026#39;].size\rmen_no_purchase = dataset[(dataset[\u0026#39;Purchased\u0026#39;]==0) \u0026amp; (dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Male\u0026#39;)][\u0026#39;Gender\u0026#39;].size\rfemale_purchase = dataset[(dataset[\u0026#39;Purchased\u0026#39;]==1) \u0026amp; (dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Female\u0026#39;)][\u0026#39;Gender\u0026#39;].size\rfemale_no_purchase = dataset[(dataset[\u0026#39;Purchased\u0026#39;]==0) \u0026amp; (dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Female\u0026#39;)][\u0026#39;Gender\u0026#39;].size\r  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  x_label=[\u0026#39;Yes\u0026#39;, \u0026#39;No\u0026#39;]\rx_pos = np.arange(len(x_label))\rwidth = 0.35\rpeople_purchase = [men_purchase, men_no_purchase]\rpeople_no_purchase=[female_purchase,female_no_purchase]\r#All people\r fig, ax = plt.subplots()\rrects1 = ax.bar(x_pos - width/2, people_purchase, width, label=\u0026#39;Men\u0026#39;)\rrects2 = ax.bar(x_pos + width/2, people_no_purchase, width, label=\u0026#39;Women\u0026#39;)\rax.set_ylabel(\u0026#39;Count\u0026#39;)\rax.set_title(\u0026#39;Men and Women vs Purchase\u0026#39;)\rax.set_xticks(x_pos)\rax.set_xticklabels(x_label)\rax.legend()\rdef autolabel(rects):\r\u0026#34;\u0026#34;\u0026#34;Attach a text label above each bar in *rects*, displaying its height.\u0026#34;\u0026#34;\u0026#34;\rfor rect in rects:\rheight = rect.get_height()\rax.annotate(\u0026#39;{}\u0026#39;.format(height),\rxy=(rect.get_x() + rect.get_width() / 2, height),\rxytext=(0, 3), # 3 points vertical offset\r textcoords=\u0026#34;offset points\u0026#34;,\rha=\u0026#39;center\u0026#39;, va=\u0026#39;bottom\u0026#39;)\rautolabel(rects1)\rautolabel(rects2)\rfig.tight_layout()\rplt.show()\r  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # What age range purchases more\r men_purchased=dataset[(dataset[\u0026#39;Purchased\u0026#39;]==1)\u0026amp; (dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Male\u0026#39;) ][\u0026#39;Age\u0026#39;]\rfemale_purchased=dataset[(dataset[\u0026#39;Purchased\u0026#39;]==1)\u0026amp; (dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Female\u0026#39;) ][\u0026#39;Age\u0026#39;]\rn_bins = 6\rfig, axs = plt.subplots(2,1, sharey=True)\r# We can set the number of bins with the `bins` kwarg\r #plt.title(\u0026#39;Men Vs women Salary Range Purchase\u0026#39;)\r axs[0].hist(men_purchased, bins=n_bins,orientation =\u0026#39;vertical\u0026#39;,cumulative=True )\raxs[0].set_ylabel(\u0026#39;Men Purchases\u0026#39;)\raxs[1].hist(female_purchased, bins=n_bins,orientation =\u0026#39;vertical\u0026#39;,cumulative=True)\raxs[1].set_ylabel(\u0026#39;Female Purchases\u0026#39;)\raxs[1].set_xlabel(\u0026#39;Age Range\u0026#39;)\r#fig.tight_layout()\r plt.show()\r  For people who bought, it appears that men and women\u0026rsquo;s shopping habit is quite different. For both men and women, they make purchases gradually until age 40. After age 40, both men and women tend to purchase more. After age 50, men purchase habits drop but women continue the trend.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # What salary range purchases more\r men_purchased=dataset[(dataset[\u0026#39;Purchased\u0026#39;]==1)\u0026amp; (dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Male\u0026#39;) ][\u0026#39;EstimatedSalary\u0026#39;]\rfemale_purchased=dataset[(dataset[\u0026#39;Purchased\u0026#39;]==1)\u0026amp; (dataset[\u0026#39;Gender\u0026#39;]==\u0026#39;Female\u0026#39;) ][\u0026#39;EstimatedSalary\u0026#39;]\rn_bins = 12\rfig, axs = plt.subplots(2,1, sharey=True)\r# We can set the number of bins with the `bins` kwarg\r #plt.title(\u0026#39;Men Vs women Salary Range Purchase\u0026#39;)\r axs[0].hist(men_purchased, bins=n_bins,orientation =\u0026#39;vertical\u0026#39; )\raxs[0].set_ylabel(\u0026#39;Men Purchases\u0026#39;)\raxs[1].hist(female_purchased, bins=n_bins,orientation =\u0026#39;vertical\u0026#39;)\raxs[1].set_ylabel(\u0026#39;Female Purchases\u0026#39;)\raxs[1].set_xlabel(\u0026#39;Salary Range\u0026#39;)\r#fig.tight_layout()\r plt.show()\r  Salary Range purchases are more interesting. Men\u0026rsquo;s and women\u0026rsquo;s purchases keep dropping from 19000 - 50000. Women\u0026rsquo;s purchases continue to increase from 75000 and upwards. Men\u0026rsquo;s purchases remain pretty stale beyond 70000 and upwards.\nSet up Training and Test Data 1 2 3 4  # Set up training and test data\r x=dataset.iloc[:,1:4].values\ry=dataset.iloc[:,4:5].values\rx[1:5]\r  1 2 3 4 5  array([[\u0026#39;Male\u0026#39;, 35, 20000],\r[\u0026#39;Female\u0026#39;, 26, 43000],\r[\u0026#39;Female\u0026#39;, 27, 57000],\r[\u0026#39;Male\u0026#39;, 19, 76000]], dtype=object)\r  The dataset has a categorical field sex = {Male, Female}. Before we proceed to train the model, let\u0026rsquo;s encode the dataset.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  #Adding the logistic regression\r from sklearn.preprocessing import OneHotEncoder, LabelEncoder\rfrom sklearn.compose import ColumnTransformer\rtransformer = ColumnTransformer(\rtransformers=[\r(\u0026#34;Gender\u0026#34;, # Just a name\r OneHotEncoder(categories=\u0026#39;auto\u0026#39;), # The transformer class\r [0] # The column(s) to be applied on.\r )\r], remainder=\u0026#39;passthrough\u0026#39;\r)\rx= transformer.fit_transform(x)\rx\r  1 2 3 4 5 6 7  array([[0.0, 1.0, 19, 19000],\r[0.0, 1.0, 35, 20000],\r[1.0, 0.0, 26, 43000],\r...,\r[1.0, 0.0, 50, 20000],\r[0.0, 1.0, 36, 33000],\r[1.0, 0.0, 49, 36000]], dtype=object)\r  Now you can see that Male has been set to 0,1 and Female as 1,0.\nNext, we split the data in tp train and test data. Here we are splitting into 75:25 ratio. The random_state is set to 10, which means that every 10th row will be set to train and test.\n1 2 3  #Split into training and test data\r from sklearn.model_selection import train_test_split\rX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=10)\r  Next, we will standardize the value across the dataset. Standardized scaling is an important step here because as you will see the age range is between 1-100, while salary is in the 1000\u0026rsquo;s and sex is either 0 or 1.\n1 2  from sklearn.linear_model import LogisticRegression\rfrom sklearn.preprocessing import StandardScaler\r  1 2 3 4  sc = StandardScaler()\rX_train = sc.fit_transform(X_train)\rX_test = sc.transform(X_test)\r  1  X_train\r  1 2 3 4 5 6 7  array([[-1.06191317, 1.06191317, -0.93894518, 0.26049952],\r[ 0.94169658, -0.94169658, -0.93894518, 0.43327002],\r[ 0.94169658, -0.94169658, 0.3177076 , 0.05893394],\r...,\r[-1.06191317, 1.06191317, -0.84227958, 0.2892946 ],\r[ 0.94169658, -0.94169658, 0.1243764 , -0.25781198],\r[ 0.94169658, -0.94169658, 0.4143732 , 1.09555693]])\r  Now you can see that each column has been standardized and scaled. Next, we need to define our regression class.\n1 2 3  lr = LogisticRegression(random_state=3, solver = \u0026#39;lbfgs\u0026#39;,\\\rmulti_class=\u0026#39;auto\u0026#39;).fit(X_train, y_train.ravel())\r  1 2  y_pred = lr.predict(X_test)\r  After training our Logistics Regression, we tested it against the test data to see what are values predicted for untrained data from the test.\nNext, we need to see our accuracy and look at the Confusion matrix\n1 2 3  from sklearn.metrics import accuracy_score, confusion_matrix\rprint(\u0026#39;Accuracy: \\n\u0026#39; , accuracy_score(y_test,y_pred))\rprint(\u0026#39;Confusion Matrix:\\n\u0026#39; ,confusion_matrix(y_test,y_pred))\r   Accuracy:\r0.9\rConfusion Matrix:\r[[64 5]\r[ 5 26]]m\rAnd with this, we can see that our accuracy is 91% and 10 items (5 False Positive and 5 False Negative) were incorrect predictions\n"
},
{
	"uri": "/categories/tech-notes/",
	"title": "Tech Notes",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/showcase/hugo/",
	"title": "Hugo",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "Hugo theme collection",
	"content": ""
},
{
	"uri": "/showcase/",
	"title": "Showcase overview",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "My portfolio, repos, works overview page",
	"content": ""
},
{
	"uri": "/archive/",
	"title": "Archive",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "Archive Page",
	"content": "archive page\n"
},
{
	"uri": "/2019/03/02/decision-tree-using-python/",
	"title": "Part 7 Decision tree regression or classification using python",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "Machine learning tutorial using decision tree regression. This post in the machine learning series will walk you through the process of implementing decision tee regression using python.",
	"content": "In the previous post, we learnt about Support vector regression. In this post, we will see a new way of deciphering information using a simple format of traversing conditions.\nBusiness Goal: Can you spot the king? The people of Falkland are scared. Their king disguises as a common man and roams among them to gain knowledge about his kingdom and see if his policies are working in his kingdom. When the king is disguised, the common people don\u0026rsquo;t recognize him. If they accidentally mistreat the king when he is disguised, they get punished. Can you help the people of Falkland spot the king?\nHow to get dataset?  Decision Tree dataset Decision tree notebook  What is a \u0026ldquo;Decision Tree\u0026rdquo;'\u0026quot;?  A Decision tree builds regression or classification models in the form of tree structure. It is a set of \u0026lsquo;yes\u0026rsquo; or \u0026lsquo;no\u0026rsquo; flow, which cascades downward like an upside down tree. For example, given a set of independent variables or features about a person, can we find if the person is healthy.\n Parts of decision Tree  Each decision point is called a Node. Ex - Age \u0026lt; 30 Each connector is called an Edge. Each node which does not have any subnode is called a Leaf. Ex - Fit or Unfit!.  How is the tree built? To build a tree, we need to start with an Independent Feature as a root node. The possible attributes or unique values of that feature form the edges. Once the first level of the tree is completed, attach another feature node at the end of each node and traverse deeper. Once you have exhausted all the features, you will arrive at the dependent value or result.\nCan we just start with any random feature as the root node? This is a million $$$ question here. This is the meat of the whole algorithm. Let\u0026rsquo;s look at our business problem about the problem that people of Falkland are facing. We need to come up with a solution to spot the king when he is disguised to save the common man from mistreating him accidentally and hence punished in return. Here\u0026rsquo;s the data that we have collected about people leaving the castle.\n Ok! So we have the data, but how do we find out which feature will be the root node?\n Going back to our previous post on Backward Elimination, we can gather that the root node should be a feature which is the most important feature in making the decision. To find the most important feature, we will align each independent feature with dependent feature (Is_King).\nIf we look at the above mapping, we will see that Gold_Tooth feature is right most of the time in predicting the king, followed by the castle as it has the least number of false positive.\n Well, that\u0026rsquo;s good to know, but I noticed that you did talk about the last two features - Greedy and Slow.\n Yes, the distinction between the two is difficult to figure out. Both Greedy and Slow features have an equal number of false positives. To understand, which feature is more important than the other, we need to understand Data Entropy_.\nWhat is Data Entropy? Entropy means how many times information changed that we got a positive result. Imagine if the king never left the castle, which means that all the information that we collected will show Is_King as 0. In our case, the entropy is 1 because anybody could be the king. If we just had Castle as the feature, predicting the king would be difficult without another piece of information.\n So in simple terms Entropy is how many pieces of the data point(Independent feature) is required, to guess the Dependent variable - Is_King__\n To further explain. Let\u0026rsquo;s say that instead of starting with Gold_tooth as the root node, we start with the castle. We will see that we are able to find the king only 3/10 times. On top of that, the left side gives very poor results. Just 1/5 or 20%.\nThere is another problem with the above tree. It is too overcomplicated and is overfitted. If we get new data the accuracy of our model could fall drastically.\nGoing back to our learning in the earlier post, the simpler model should be preferred over the complicated model to avoid overfitting.\nHow to avoid overfitting in decision Tree? Just remember the 3 golden rules to avoid overfitting:\n  Use a smaller number of data points to build the tree. Ex - 10% of data points is a good place to build a generic model.\n  Do not go overboard with the depth of the tree. A tree depth should only be increased if there is a significant improvement in the prediction.\n  Stop, if the number of data points at the split is less than 5%.\n  Here\u0026rsquo;s a refined version of the tree.\nWould this model work on non-categorical or continuous values? Absolultely!! The splitting rules would still apply as I mentioned above.\nSo each Split is a leaf node above. Imagine if we wanted to find the dependent variable Y whose independent partners X1 and X2 are 10 and 150, then it would land in the first node as 300.5.\n I get why it landed in first leaf node position but where did we get value 300.5?\nThe value 300.5 is the average of all the data points in that box.\n  Pay attention and read the previous 2 lines again. The last two lines will help you understand why we need to divide it into different leaves and nodes. If you do not have splits, then the only option is to take the average of the ALL the data points!! The accuracy would be nowhere close to your expectation and would be same all values of X1 and X2.\n Python Implementation We are going to take a standard dataset called IRIS Dataset\n “The Iris flower dataset or Fisher’s Iris dataset is a multivariate dataset introduced by the British statistician and biologist Ronald Fisher in his 1936 paper ‘The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis’.” — Wikipedia\n In layman terms, it is a set of data points about IRIS flower where we have the information about the length and the width of sepals and petals about 3 varieties.\nStep 1: Get the common imports\n1 2 3 4 5 6  # Importing the libraries\r import numpy as np\rimport matplotlib.pyplot as plt\rimport pandas as pd\rfrom sklearn.tree import DecisionTreeClassifier\rdataset = pd.read_csv(\u0026#34;iris.csv\u0026#34;)\r  Step 2: Identify the missing data\n1  dataset.isnull().any()\r  sepal-length False\rsepal-width False\rpetal-length False\rpetal-width False\rspecies False\rdtype: bool\r Step 3: Describe the data and identify the data types\n1 2  dataset.describe()\r  \r.dataframe tbody tr th:only-of-type {\rvertical-align: middle;\r}\r.dataframe tbody tr th {\rvertical-align: top;\r}\r.dataframe thead th {\rtext-align: right;\r}\r \n\r\rsepal-length\rsepal-width\rpetal-length\rpetal-width\r\r\r\r\rcount\r150.000000\r150.000000\r150.000000\r150.000000\r\r\rmean\r5.843333\r3.054000\r3.758667\r1.198667\r\r\rstd\r0.828066\r0.433594\r1.764420\r0.763161\r\r\rmin\r4.300000\r2.000000\r1.000000\r0.100000\r\r\r25%\r5.100000\r2.800000\r1.600000\r0.300000\r\r\r50%\r5.800000\r3.000000\r4.350000\r1.300000\r\r\r75%\r6.400000\r3.300000\r5.100000\r1.800000\r\r\rmax\r7.900000\r4.400000\r6.900000\r2.500000\r\r\r\r\r1  dataset.dtypes\r  sepal-length float64\rsepal-width float64\rpetal-length float64\rpetal-width float64\rspecies object\rdtype: object\r Step 4: Load the Iris data and create the X and Y variables\n1 2 3  X= dataset.iloc[0:, 0:4].values\rY = dataset.iloc[:,4]\r  Step 5: Plot the data\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  ##Get the dataset for each of the three species\r setosa=dataset[dataset[\u0026#39;species\u0026#39;]==\u0026#39;Iris-setosa\u0026#39;]\rversicolor =dataset[dataset[\u0026#39;species\u0026#39;]==\u0026#39;Iris-versicolor\u0026#39;]\rvirginica =dataset[dataset[\u0026#39;species\u0026#39;]==\u0026#39;Iris-virginica\u0026#39;]\r#Create an empty figure with two windows pf size 21 by 10\r plt.figure()\rfig,ax=plt.subplots(1,2,figsize=(21, 10))\r#Plot each species using Sepal length and width on x-y axis\r setosa.plot(x=\u0026#34;sepal-length\u0026#34;, y=\u0026#34;sepal-width\u0026#34;, kind=\u0026#34;scatter\u0026#34;,ax=ax[0],label=\u0026#39;setosa\u0026#39;,color=\u0026#39;r\u0026#39;)\rversicolor.plot(x=\u0026#34;sepal-length\u0026#34;,y=\u0026#34;sepal-width\u0026#34;,kind=\u0026#34;scatter\u0026#34;,ax=ax[0],label=\u0026#39;versicolor\u0026#39;,color=\u0026#39;b\u0026#39;)\rvirginica.plot(x=\u0026#34;sepal-length\u0026#34;, y=\u0026#34;sepal-width\u0026#34;, kind=\u0026#34;scatter\u0026#34;, ax=ax[0], label=\u0026#39;virginica\u0026#39;, color=\u0026#39;g\u0026#39;)\r#Plot each species using Petal length and width on x-y axis\r setosa.plot(x=\u0026#34;petal-length\u0026#34;, y=\u0026#34;petal-width\u0026#34;, kind=\u0026#34;scatter\u0026#34;,ax=ax[1],label=\u0026#39;setosa\u0026#39;,color=\u0026#39;r\u0026#39;)\rversicolor.plot(x=\u0026#34;petal-length\u0026#34;,y=\u0026#34;petal-width\u0026#34;,kind=\u0026#34;scatter\u0026#34;,ax=ax[1],label=\u0026#39;versicolor\u0026#39;,color=\u0026#39;b\u0026#39;)\rvirginica.plot(x=\u0026#34;petal-length\u0026#34;, y=\u0026#34;petal-width\u0026#34;, kind=\u0026#34;scatter\u0026#34;, ax=ax[1], label=\u0026#39;virginica\u0026#39;, color=\u0026#39;g\u0026#39;)\r#Give Each figure its names\r ax[0].set(title=\u0026#39;Sepal comparasion \u0026#39;, ylabel=\u0026#39;sepal-width\u0026#39;)\rax[1].set(title=\u0026#39;Petal Comparasion\u0026#39;, ylabel=\u0026#39;petal-width\u0026#39;)\rax[0].legend()\rax[1].legend()\r#Show the plot\r plt.show()\r  \u0026lt;Figure size 432x288 with 0 Axes\u0026gt;\r Step 6: Encode the value of Flower types\nThe values of dependent the variable needs to be encoded to numbers as they are categorical values\n1 2 3 4  from sklearn.preprocessing import LabelEncoder\rlabelEncoder_y = LabelEncoder()\rY = labelEncoder_y.fit_transform(Y)\r  Step 7: Split the data in training and test set\n1 2  from sklearn.model_selection import train_test_split\rx_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=0)\r  Step 8: Train the Decision Tree model\n1 2 3  from sklearn.tree import DecisionTreeRegressor\rregressor = DecisionTreeRegressor(random_state=0)\rregressor.fit(x_train, y_train)\r  DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\rmax_leaf_nodes=None, min_impurity_decrease=0.0,\rmin_impurity_split=None, min_samples_leaf=1,\rmin_samples_split=2, min_weight_fraction_leaf=0.0,\rpresort=False, random_state=0, splitter='best')\r Step 9: Predict and score the model\n1 2 3  y_predict=regressor.predict(x_test)\rprint(regressor.score(x_test,y_test))\r  1.0\r  Wow! Did we just predict that our model is correct 100% of the time?\nThe reason the accuracy is showing 100% is that our model is too complex as we did not define the maximum depth of tree and hence we broke a cardinal rule. Let\u0026rsquo;s take a look at the created tree.\n 1 2 3 4 5 6 7 8 9 10  from sklearn.externals.six import StringIO\rfrom IPython.display import Image\rfrom sklearn.tree import export_graphviz\rimport pydotplus\rfrom sklearn import tree\rdot_data = StringIO() tree.export_graphviz(regressor, out_file=dot_data)\rgraph = pydotplus.graph_from_dot_data(dot_data.getvalue()) Image(graph.create_png())\r  As you can see, that since we did not provide a maximum depth of the tree, it created a complex tree of 6 layers and hence for our model we are getting 100% accuracy. This means that the model is an overfitted model.\nLet\u0026rsquo;s fix this by creating a simpler model.\n1 2 3 4 5 6 7  #Creating a model that is only 2 layers deep by setting max_depth=3\r regressor = DecisionTreeRegressor(random_state=0,criterion=\u0026#39;mse\u0026#39;, splitter=\u0026#39;best\u0026#39;, max_depth=3, min_samples_split=3, min_samples_leaf=2 )\rregressor.fit(x_train, y_train)\ry_predict=regressor.predict(x_test)\rprint(regressor.score(x_test,y_test))\r  0.9739827477382705\r  As you can see that the model is not an overfit anymore and still gives us pretty good accuracy of 97.4%.\nLooking at the decision tree now.\n 1 2 3 4 5 6 7 8 9 10 11 12  from sklearn.externals.six import StringIO\rfrom IPython.display import Image\rfrom sklearn.tree import export_graphviz\rimport pydotplus\rfrom sklearn import tree\rdot_data = StringIO() tree.export_graphviz(regressor, out_file=dot_data)\rgraph = pydotplus.graph_from_dot_data(dot_data.getvalue()) Image(graph.create_png())\r![tree_fix.PNG](/images/decision/tree_fix.PNG)\r  So keep climbing the tree of success with this DecisionTree regression model. In the next series, we will see how to use a kind of decision tree called Random forest regression.\n"
},
{
	"uri": "/about/",
	"title": "About",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "A Morsel Of Code - One Byte At A Time",
	"content": "This website is collection of random technical topics. Most of these are issues that I come across at my work and this place serve as future reference for the solutions.\n"
},
{
	"uri": "/2019/02/10/part-6-ml-svr/",
	"title": "Part 6 Support Vector Regression",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "Machine learning tutorial using Support vector regression. This post in the machine learning series will walk you through the process of implementing Support vector Regression.",
	"content": "Business Goal: As an owner of MuShu Bike Rental CO. in New York. I want to know how many bicycles will be rented on any given day based on daily temperature, humidity and wind speed. Can you help MuShu Bike Rental CO. to predict the number of daily rentals?\nHow to get the dataset?  Startup Dataset Support vector Regression notebook  Let\u0026rsquo;s solve this problem using SVR - Support Vector Regression.\nBefore we begin, let\u0026rsquo;s see the key terms that will be used.\nKey terms  Kernel   A fancy word for the function used to map a lower dimension data into higher dimension data.\n  Hyper Plane   This is a line that helps us predict the target values.\n  Boundary Line   There are two boundary lines which separate the classes. The support vectors can be on the boundary line or outside the boundary line.\n  Support Vectors   Support vectors are the data points which are closest to the boundary line.\n What is a SVR model? In Simple/multiple regression we try to minimize the errors while in SVR, we try to fit the error within a threshold.\n Blue Line: Hyper Plane | Red Line: Boundary lines\n Looking at the above figure, our goal is to have the data points inside the boundary lines and hyperplane with the maximum number of data points.\nWhat is \u0026ldquo;Boundary again? The red lines that you see in the diagram above are called boundary lines. These lines are at equidistant from a hyper plane (Blue line). So basically, if one boundary line is at distance \u0026ldquo;e\u0026rdquo; distance from a hyper plane the other would be at distance of \u0026quot;-e\u0026rdquo;.\nIn mathematical equation.\nIf the hyper plane line is a straight line going through Y-AXIS and represented as\n mX + C =0\n Then the equation of boundary lines can be represented as\n mX + C = e\nmx +C = -e\n The final equation of SVR can be represented as\n e≤ y-mx-c ≤+e\n  To summarize: The goal so far is to find the distance value e which is equidistant from hyper plane line with the maximum data points OR that they are inside the Boundary line.\n Exploring the dataset 1 2 3 4 5 6 7  import numpy as np\rimport pandas as pd\rimport matplotlib.pyplot as plt\r##Import the datset\r dataset = pd.read_csv(\u0026#39;BikeRental/bike_rental_train.csv\u0026#39;)\r  1  dataset.head()\r  \r.dataframe tbody tr th:only-of-type {\rvertical-align: middle;\r}\r.dataframe tbody tr th {\rvertical-align: top;\r}\r.dataframe thead th {\rtext-align: right;\r}\r \n\r\rtemp\rhumidity\rwindspeed\rbike_rent_count\r\r\r\r\r0\r9.02\r80\r0.0000\r40\r\r\r1\r9.02\r80\r0.0000\r32\r\r\r2\r9.84\r75\r0.0000\r13\r\r\r3\r9.84\r75\r0.0000\r1\r\r\r4\r9.84\r75\r6.0032\r1\r\r\r\r\r1  dataset.describe().T\r  \r.dataframe tbody tr th:only-of-type {\rvertical-align: middle;\r}\r.dataframe tbody tr th {\rvertical-align: top;\r}\r.dataframe thead th {\rtext-align: right;\r}\r \n\r\rcount\rmean\rstd\rmin\r25%\r50%\r75%\rmax\r\r\r\r\rtemp\r9801.0\r20.230348\r7.791740\r0.82\r13.9400\r20.500\r26.2400\r41.0000\r\r\rhumidity\r9801.0\r61.903989\r19.293371\r0.00\r47.0000\r62.000\r78.0000\r100.0000\r\r\rwindspeed\r9801.0\r12.836534\r8.177168\r0.00\r7.0015\r12.998\r16.9979\r56.9969\r\r\rbike_rent_count\r9801.0\r191.334864\r181.048534\r1.00\r42.0000\r145.000\r283.0000\r977.0000\r\r\r\r\r1  dataset.columns\r  Index(['temp', 'humidity', 'windspeed', 'bike_rent_count'], dtype='object')\r 1 2  plt.scatter( dataset.temp, dataset.bike_rent_count, c=\u0026#39;green\u0026#39;);\r  1 2  plt.scatter( dataset.humidity,dataset.bike_rent_count);\r  1  plt.scatter( dataset.windspeed, dataset.bike_rent_count);\r   Summary\nBased on data description and histogram plot.\n  Temp Range = 0 to 41 Humidity Range = 0 to 100 Windspeed = 0 to 57  1  dataset.corr(method=\u0026#39;pearson\u0026#39;, min_periods=1)\r  \r.dataframe tbody tr th:only-of-type {\rvertical-align: middle;\r}\r.dataframe tbody tr th {\rvertical-align: top;\r}\r.dataframe thead th {\rtext-align: right;\r}\r \n\r\rtemp\rhumidity\rwindspeed\rbike_rent_count\r\r\r\r\rtemp\r1.000000\r-0.060524\r-0.020792\r0.393114\r\r\rhumidity\r-0.060524\r1.000000\r-0.317602\r-0.312835\r\r\rwindspeed\r-0.020792\r-0.317602\r1.000000\r0.096836\r\r\rbike_rent_count\r0.393114\r-0.312835\r0.096836\r1.000000\r\r\r\r\r Summary\n  Looking at the correlation matrix, we see that there is a positive relationship between temperature and bike_rent_count Humidity has a negative effect on bike_rent_count. Higher the humidity, lower the number of rentals Windspeed has little effect on bike_rent_count.\nLooking at the correlation matrix, it confirms the visuals that bike count rental has a weak correlation with all of the 3 variables.  What does a weak correlation mean?\nIt means that the equation of the model that we are going to plot is probably not going to give very accurate results. However, the goal of this post is to show you how to implement SVR.\nSo Let\u0026rsquo;s bring out our template from our first post on data pre-processing.\n Step 1: Let\u0026rsquo;s break the data into Dependent and Independent variable\n 1 2 3 4  ### Break up in dependent and Independent variables\r X = dataset.iloc[:, 0:3].values\ry = dataset.iloc[:, 3].values\r   Step 2 : Break the data into train and test set\n 1 2 3 4  # Splitting the dataset into the Training set and Test set\r from sklearn.model_selection import train_test_split\rX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\r   Step 3: Feature scaling. This step is required here beacause SVR library does not do feature scaling.\n 1 2 3 4 5 6 7  # Feature Scaling\r from sklearn.preprocessing import StandardScaler\rsc_X = StandardScaler()\rX_train = sc_X.fit_transform(X_train)\rX_test = sc_X.transform(X_test)\r#sc_y = StandardScaler()\r #y_train = sc_y.fit_transform(y_train)\r    Step 4: Create a Regressor and fit the model\n 1 2 3 4 5 6 7  # Fitting the SVR Model to the dataset\r from sklearn.svm import SVR\r# Create your regressor here\r regressor = SVR(kernel=\u0026#39;linear\u0026#39;)\rregressor.fit(X_train,y_train)\r  SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\rgamma='auto_deprecated', kernel='linear', max_iter=-1, shrinking=True,\rtol=0.001, verbose=False)\r In the above code, we are using the SVR class for fitting the model.\n SVR(\n[\u0026ldquo;kernel='rbf\u0026rsquo;\u0026quot;, \u0026lsquo;degree=3\u0026rsquo;, \u0026ldquo;gamma='auto_deprecated\u0026rsquo;\u0026quot;, \u0026lsquo;coef0=0.0\u0026rsquo;, \u0026lsquo;tol=0.001\u0026rsquo;, \u0026lsquo;C=1.0\u0026rsquo;, \u0026lsquo;epsilon=0.1\u0026rsquo;, \u0026lsquo;shrinking=True\u0026rsquo;, \u0026lsquo;cache_size=200\u0026rsquo;, \u0026lsquo;verbose=False\u0026rsquo;, \u0026lsquo;max_iter=-1\u0026rsquo;],\n)\n The SVR model that we are using provides 4 types of Kernel - rbf, linear, poly, sigmoid. In our case, we are using linear since data appears to be linear based on visualizations. Another interesting attribute is verbose, which when set to true will show you the default values used of other attributes.\n Step 5: Predict the bike count based on test data\n 1 2  # Predicting a new result\r y_pred = regressor.predict(X_test)\r   Step 6: Check the model effeciency\n 1 2  print(\u0026#39;Train Score: \u0026#39;, regressor.score(X_train, y_train))\rprint(\u0026#39;Test Score: \u0026#39;, regressor.score(X_test, y_test))\r  Train Score: 0.19926232721567205\rTest Score: 0.2082800818663224\r As mentioned earlier, since the correlation is weak, we can see that our model is extremely weak. One thing to note here is that I downloaded this random dataset from some website. So when I was working on SVR, I was not sure if the data is true or not.\nLet\u0026rsquo;s try the tweaking SVR model a little to see if we can do better.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # Create your regressor here\r regressor = (SVR(kernel=\u0026#39;poly\u0026#39;,\rshrinking=True,\rdegree=7,\rgamma=\u0026#39;scale\u0026#39;,\repsilon = 0.01,\rcoef0 =1.60\r))\rregressor.fit(X_train,y_train)\r# Predicting a new result\r y_pred = regressor.predict(X_test)\rprint(\u0026#39;Train Score: \u0026#39;, regressor.score(X_train, y_train))\rprint(\u0026#39;Test Score: \u0026#39;, regressor.score(X_test, y_test))\r  Train Score: 0.25167703525198526\rTest Score: 0.2484248213345378\r So after playing around with different option and values, you will see that if you use poly or polynomial kernel, I was able to push the model prediction to 25.xx%.\nSo that\u0026rsquo;s it for this series. Try a different dataset, probably get one from the Multiple Linear regression about 50_Startups and predict using linear kernel.\nIn the next series, we will learn about our first ever classification model - Decision Trees. Till then happy Happy hyper-planing\n"
},
{
	"uri": "/2019/02/10/part-5-ml-mltr-backward-elimination/",
	"title": "Part 5 Machine Learning Backward Elimination",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "Machine learning tutorial using multiple linear regression. This post in the machine learning series will walk you through the process of automatic backward elimination and show you to improve your multiple regression model and teach you an important concept that simple is always better.",
	"content": "In the previous post, we learnt about multiple linear regression. The problem with the last approach was that we used all the features without considering that some of the features may not be impacting or playing any role in the outcome. we also talked about 5 ways of reducing the noisy feature. Backward elimination is one of them.\nHow to get the dataset?  Startup Dataset Multiple Regression notebook  What is Backward Elimination? Backward elimination is a process to remove features that have little effect on the dependent variable.\nWhat could possibly be wrong with leaving the features if they are not impacting or have little impact? New England Patriots won the Superbowl on Feb 3, 2019. The team won because it had a better team, better skills and a good coach. If I say, the team also won because Patriots fans are great at cheering and that when Patriots play fans supporting the opposition is more tamed, then I would be wrong. If I say that all players in the team wore a white jersey and they won. They also won because they played it on Sunday and T. Brady thinks that it\u0026rsquo;s his luckiest day. You would call Baloney to all the facts that I just mentioned. It may have helped - may be slightly but too insignificant to make a real difference. The features in a data set are exactly that - Baloney. They only add noise in the actual model and many small non-significant data may actually provide us a model which is way off the margin. The simpler the model, the better the result.\nHow do we implement Backward elimination? In backward elimination, you take all the variables and create the algorithm. Select a significance level, then consider the predictor with Highest P-value and if P-Value \u0026gt; Significance level then eliminate the variable from the equation, else keep it.\nHow do we implement it in python? In the previous post, we were trying to figure out if a company is profitable or not by looking at 4 independent variables - R\u0026amp;D Spent, Administration cost, Market spending \u0026amp; State. We created a model with all the features. So let\u0026rsquo;s pick up from where we left off. Here\u0026rsquo;s how our dataset looks like\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  import numpy as np\rimport matplotlib.pyplot as plt\rimport pandas as pd\r#Read the dataset\r dataset = pd.read_csv(\u0026#34;50_Startups.csv\u0026#34;)\r#Divide the dataset in dependent and Independent variables\r X= dataset.iloc[:, :-1].values\ry = dataset.iloc[:, -1].values\r#Taking care of Categorical values.\r from sklearn.preprocessing import OneHotEncoder, LabelEncoder\rlabel_encoder = LabelEncoder();\rX[:,3]=label_encoder.fit_transform(X[:, 3])\roneHotEncoder = OneHotEncoder(categorical_features=[3])\rX= oneHotEncoder.fit_transform(X).toarray()\r#getting out of dummy variable trap\r X = X[:,1:] # Select all the rows and all the columns starting fom index 1 onwards.\r #Create training and test set\r from sklearn.model_selection import train_test_split\rX_train, X_test, y_train, y_test = train_test_split(X, y,\rtest_size = 0.20,\rtrain_size=0.80,\rrandom_state=0)\r#Check for missing data\r null_columns=dataset.columns[dataset.isnull().any()]\rt = dataset[null_columns].isnull().sum()\r#Training the model\r from sklearn.linear_model import LinearRegression\rregressor = LinearRegression()\rregressor.fit(X_train, y_train)\r# Predicting the results of the training set\r y_pred = regressor.predict(X_test) print(regressor.coef_)\rprint(regressor.intercept_)\rprint(\u0026#39;Train Score: \u0026#39;, regressor.score(X_train, y_train))\rprint(\u0026#39;Test Score: \u0026#39;, regressor.score(X_test, y_test))\r  [-9.59284160e+02 6.99369053e+02 7.73467193e-01 3.28845975e-02\r3.66100259e-02]\r42554.16761772438\rTrain Score: 0.9501847627493607\rTest Score: 0.9347068473282446\r Take note of Train Score and Test Score\n Train Score: 0.9501847627493607\n  Test Score: 0.9347068473282446\n The difference between them is 0.01547791542 or 1.548%\nSo far we used all the features. Now to use backward elimination we will use an entirely new package and class. However, before we begin, we need to decide on a significance level. In this case, let\u0026rsquo;s chose a level equal o 0.05.\n1 2 3 4  import statsmodels.formula.api as smf\r#Appending ones for constants\r X = np.append(arr=np.ones((50,1)).astype(int), values=X, axis=1)\r  Why did we append 1\u0026rsquo;s in the existing dataset?  Y = b0X0 + b1X1+ b2X2 + b3X3 + b4X4 + b5X5 + C\n In the above equation, if you notice that every Xn has a multiplier bn but not the constant C. Actually if you have a X6 and set it to 1 that solves the problem. The question is why do we need a 1 multiplier for the constant. The answer lies in the library and the class that we use. The package statsmodel only considers a multiplier if it has a feature value. If there is no feature value then it would not get picked up while creating the model. So the C would be dropped. Hence we need to create a feature with value = 1.\n1 2 3 4  ##Creating a model with all varibales\r x_opt = X[:,[0,1,2,3,4,5]]\rregressor_OLS = smf.OLS(endog=y, exog=x_opt).fit()\rprint(regressor_OLS.summary())\r   OLS Regression Results ==============================================================================\rDep. Variable: y R-squared: 0.951\rModel: OLS Adj. R-squared: 0.945\rMethod: Least Squares F-statistic: 169.9\rDate: Sun, 10 Feb 2019 Prob (F-statistic): 1.34e-27\rTime: 22:42:26 Log-Likelihood: -525.38\rNo. Observations: 50 AIC: 1063.\rDf Residuals: 44 BIC: 1074.\rDf Model: 5 Covariance Type: nonrobust ==============================================================================\rcoef std err t P\u0026gt;|t| [0.025 0.975]\r------------------------------------------------------------------------------\rconst 5.013e+04 6884.820 7.281 0.000 3.62e+04 6.4e+04\rx1 198.7888 3371.007 0.059 0.953 -6595.030 6992.607\rx2 -41.8870 3256.039 -0.013 0.990 -6604.003 6520.229\rx3 0.8060 0.046 17.369 0.000 0.712 0.900\rx4 -0.0270 0.052 -0.517 0.608 -0.132 0.078\rx5 0.0270 0.017 1.574 0.123 -0.008 0.062\r==============================================================================\rOmnibus: 14.782 Durbin-Watson: 1.283\rProb(Omnibus): 0.001 Jarque-Bera (JB): 21.266\rSkew: -0.948 Prob(JB): 2.41e-05\rKurtosis: 5.572 Cond. No. 1.45e+06\r==============================================================================\r Based on the process, we now have to find the feature with the highest P-value and if it greater than ould SL then we will drop it. In this case\n x2 has the highest P-value = 0.990 \u0026gt; 0.05.\n So will drop the feature x2 which corresponds to the State dummy variable\nWe will continue and re-run the model with just 5 feature\n1 2 3 4  ## Removing index 2 as P\u0026gt;0.05 and is the highest P\r x_opt = X[:,[0,1,3,4,5]]\rregressor_OLS = smf.OLS(endog=y, exog=x_opt).fit()\rprint(regressor_OLS.summary())\r   OLS Regression Results ==============================================================================\rDep. Variable: y R-squared: 0.951\rModel: OLS Adj. R-squared: 0.946\rMethod: Least Squares F-statistic: 217.2\rDate: Sun, 10 Feb 2019 Prob (F-statistic): 8.49e-29\rTime: 22:52:32 Log-Likelihood: -525.38\rNo. Observations: 50 AIC: 1061.\rDf Residuals: 45 BIC: 1070.\rDf Model: 4 Covariance Type: nonrobust ==============================================================================\rcoef std err t P\u0026gt;|t| [0.025 0.975]\r------------------------------------------------------------------------------\rconst 5.011e+04 6647.870 7.537 0.000 3.67e+04 6.35e+04\rx1 220.1585 2900.536 0.076 0.940 -5621.821 6062.138\rx2 0.8060 0.046 17.606 0.000 0.714 0.898\rx3 -0.0270 0.052 -0.523 0.604 -0.131 0.077\rx4 0.0270 0.017 1.592 0.118 -0.007 0.061\r==============================================================================\rOmnibus: 14.758 Durbin-Watson: 1.282\rProb(Omnibus): 0.001 Jarque-Bera (JB): 21.172\rSkew: -0.948 Prob(JB): 2.53e-05\rKurtosis: 5.563 Cond. No. 1.40e+06\r==============================================================================\r Once again in the above output\n x1 has the highest P-value = 0.940 \u0026gt; 0.05\n So we will drop X1, which in this case represents the second dummy variable for the State.\nSo we will continue until we don\u0026rsquo;t have variable that is greater than our significance level\n1 2 3 4 5 6  ## Removing index 1 as P\u0026gt;0.05 and is the highest P\r x_opt = X[:,[0,3,4,5]]\rregressor_OLS = smf.OLS(endog=y, exog=x_opt).fit()\rprint(regressor_OLS.summary())\r   OLS Regression Results ==============================================================================\rDep. Variable: y R-squared: 0.951\rModel: OLS Adj. R-squared: 0.948\rMethod: Least Squares F-statistic: 296.0\rDate: Sun, 10 Feb 2019 Prob (F-statistic): 4.53e-30\rTime: 22:59:29 Log-Likelihood: -525.39\rNo. Observations: 50 AIC: 1059.\rDf Residuals: 46 BIC: 1066.\rDf Model: 3 Covariance Type: nonrobust ==============================================================================\rcoef std err t P\u0026gt;|t| [0.025 0.975]\r------------------------------------------------------------------------------\rconst 5.012e+04 6572.353 7.626 0.000 3.69e+04 6.34e+04\rx1 0.8057 0.045 17.846 0.000 0.715 0.897\rx2 -0.0268 0.051 -0.526 0.602 -0.130 0.076\rx3 0.0272 0.016 1.655 0.105 -0.006 0.060\r==============================================================================\rOmnibus: 14.838 Durbin-Watson: 1.282\rProb(Omnibus): 0.001 Jarque-Bera (JB): 21.442\rSkew: -0.949 Prob(JB): 2.21e-05\rKurtosis: 5.586 Cond. No. 1.40e+06\r==============================================================================\r 1 2 3 4 5 6  ## Removing index 1 as P\u0026gt;0.05 and is the highest P\r x_opt = X[:,[0,3,5]]\rregressor_OLS = smf.OLS(endog=y, exog=x_opt).fit()\rprint(regressor_OLS.summary())\r   OLS Regression Results ==============================================================================\rDep. Variable: y R-squared: 0.950\rModel: OLS Adj. R-squared: 0.948\rMethod: Least Squares F-statistic: 450.8\rDate: Sun, 10 Feb 2019 Prob (F-statistic): 2.16e-31\rTime: 22:59:39 Log-Likelihood: -525.54\rNo. Observations: 50 AIC: 1057.\rDf Residuals: 47 BIC: 1063.\rDf Model: 2 Covariance Type: nonrobust ==============================================================================\rcoef std err t P\u0026gt;|t| [0.025 0.975]\r------------------------------------------------------------------------------\rconst 4.698e+04 2689.933 17.464 0.000 4.16e+04 5.24e+04\rx1 0.7966 0.041 19.266 0.000 0.713 0.880\rx2 0.0299 0.016 1.927 0.060 -0.001 0.061\r==============================================================================\rOmnibus: 14.677 Durbin-Watson: 1.257\rProb(Omnibus): 0.001 Jarque-Bera (JB): 21.161\rSkew: -0.939 Prob(JB): 2.54e-05\rKurtosis: 5.575 Cond. No. 5.32e+05\r==============================================================================\r 1 2 3 4  ## Removing index 1 as P\u0026gt;0.05 and is the highest P\r x_opt = X[:,[0,3]]\rregressor_OLS = smf.OLS(endog=y, exog=x_opt).fit()\rprint(regressor_OLS.summary())\r   OLS Regression Results ==============================================================================\rDep. Variable: y R-squared: 0.947\rModel: OLS Adj. R-squared: 0.945\rMethod: Least Squares F-statistic: 849.8\rDate: Sun, 10 Feb 2019 Prob (F-statistic): 3.50e-32\rTime: 22:59:43 Log-Likelihood: -527.44\rNo. Observations: 50 AIC: 1059.\rDf Residuals: 48 BIC: 1063.\rDf Model: 1 Covariance Type: nonrobust ==============================================================================\rcoef std err t P\u0026gt;|t| [0.025 0.975]\r------------------------------------------------------------------------------\rconst 4.903e+04 2537.897 19.320 0.000 4.39e+04 5.41e+04\rx1 0.8543 0.029 29.151 0.000 0.795 0.913\r==============================================================================\rOmnibus: 13.727 Durbin-Watson: 1.116\rProb(Omnibus): 0.001 Jarque-Bera (JB): 18.536\rSkew: -0.911 Prob(JB): 9.44e-05\rKurtosis: 5.361 Cond. No. 1.65e+05\r==============================================================================\r So in the end, we find that only the C constant and the R\u0026amp;D Spending are really the important or most significant feature to find out if we should invest in the new business venture.\nHow do I believe you that by just keeping R\u0026amp;D feature, will improve our model accuracy? Let\u0026rsquo;s recalculate our model using the Linear Regression library and find the difference between accuracy score\n1 2 3 4 5 6 7 8 9 10 11  import numpy as np\rimport matplotlib.pyplot as plt\rimport pandas as pd\r#Read the dataset\r dataset = pd.read_csv(\u0026#34;50_Startups.csv\u0026#34;)\r#Divide the dataset in dependent and Independent variables\r X= dataset.iloc[:, 0].values ##Get the R\u0026amp;D score only\r y = dataset.iloc[:, -1].values\r  1 2 3 4 5 6 7  #Create training and test set\r from sklearn.model_selection import train_test_split\rX_train, X_test, y_train, y_test = train_test_split(X, y,\rtest_size = 0.20,\rtrain_size=0.80,\rrandom_state=0)\r  1 2 3 4 5 6 7 8 9 10 11 12 13 14  #Training the model\r from sklearn.linear_model import LinearRegression\rregressor = LinearRegression()\rregressor.fit(np.array(X_train).reshape(-1,1), y_train)\r# Predicting the results of the training set\r y_pred = regressor.predict(np.array(X_test).reshape(-1,1))\rprint(regressor.coef_)\rprint(regressor.intercept_)\rprint(\u0026#39;Train Score: \u0026#39;, regressor.score(np.array(X_train).reshape(-1,1), y_train))\rprint(\u0026#39;Test Score: \u0026#39;, regressor.score(np.array(X_test).reshape(-1,1), y_test))\r  [0.8516228]\r48416.297661385026\rTrain Score: 0.9449589778363044\rTest Score: 0.9464587607787219\r Let\u0026rsquo;s look at the Train score and Test Score with all the feature and with just R\u0026amp;D spending.\n With all Features\nTrain Score: 0.9501847627493607 \u0026amp; Test Score: 0.9347068473282446\n  Difference = 0.01547791542 or 1.548%\n  With just R\u0026amp;D spending feature\nTrain Score: 0.9449589778363044 \u0026amp; Test Score: 0.9464587607787219\n  Difference = 0.0014997829424 or 0.150%\n Also the if you see that the test score has improved when from 93.6% to 94.6%.\nHopefully, you enjoyed this series. In the next series, we will look at slightly more interesting topic called SVMs or Support Vector Regression.\n"
},
{
	"uri": "/2019/02/02/part-4-ml-multiple-linear-regression/",
	"title": "Part 4 Machine Learning Multiple Regression",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "Machine learning tutorial using multiple linear regression. This post in the machine learning series will walk you through the basics of exploring the data set and predicting the result using multiple linear regression.",
	"content": "In the previous post, we learnt about a P-Value, a prerequisite for learning Multiple Linear Regression.\nBusiness Problem: In this series, we will take a look at a dataset of 50 startup companies.\nA venture capitalist has hired you as a data scientist and wants you to help him select which type of company he should invest so that he can make the most profit. You need to review spending on R\u0026amp;D, Admin cost, marketing cost and location to make the decision\nHow to get the dataset?  Startup Dataset Multiple Regression notebook  What is Multiple Linear Regression? In the second post on linear regression, our equation was simple and straight-forward\n Y = mX + C\n where Y was the dependent variable, X was the dependent variable and c was the Y-intercept when X = 0. The reason the equation was simple because the Y was dependent on one variable only. If there were multiple variables affecting the value of Y, then what should it be called? - :-). You know the answer to that question.\n Multiple Linear Regression!!!\n The equation would also be something as simple as that\n Y = b0X0 + b1X1+b2X2+ \u0026hellip;. + C\n Steps to solve the problem?  Step 1: Data pre-processing and analysis  Take a closer look at dataset. You will notice that all the Independent Variables, except State, is numerical. The variable State is either California or New York. From our first post, you would know that this type of data is called categorical data. We should always convert categorical data into numerical data to avoid bias and find if there is collinearity between Profit and State. Collinearity is just a fancy way of asking - \u0026ldquo;Is there some relation between Profit and State?.\nWhen you convert a categorical data to numeric data, the new column is called Dummy Variable. So as we learned from our first post, we should convert it to a sparse matrix.\nQuestion\n *Do you need two columns to represent New York and California states?\nThe answer is No.\n It is easy to derive from the above screenshot that if New York is 1 then California by default would be 0 and vice-versa. So this actually works like a switch which can have only 2 states 0 or 1.\n Important tip: You should never use all of your dummy variables in your Regression column. They should always be 1 less than the number of values.\n If we drop one dummy variable then are we not making this a biased equation\nWithout dropping column my equation would look like this\n Y = b0X0 + b1X1+ b2X2 + b3X3 + b4X4 + b5X5 + C\n After Dropping one dummy variable\n  Y = b0X0 + b1X1+ b2X2 + b3X3 + b4X4 + C\n  If we dropped the variable then it may appear that when California is the state then the value of b4X4 will be 0, hence we lose one variable. In reality, the regression algorithm marks that the first dummy variable which is represented by 0 is set as default. So, the regression equation will never be biased. The regression equation is going to use constant C to adjust the value of California.\nBut what is wrong with using all the dummy variable?\nWhen you use both the values, your equation would be something\n Y = b0X0 + b1X1+ b2X2 + b3X3 + b4X4 + b5X5 + C\n If we do this then we will introduce multi-collinearity, where the algorithm will not be able to able to distinguish the effect on Price. This is because D2 is always equal to 1 - D1. The algorithm will then try to predict the effect of D2 over D1 and would think that there is a relation between Independent variable as well.\n Step 2: Understanding all possible methods to build a model using Multiple Linear Regression models  There are 5 methods to build a model\n- All in one\n- Backward Elimination\n- Forward Selection\n- Bi-Directional Elimination\n- Score comparison\n All In: All in means that you use all the variables when you know for sure that all the independent variables have a definite effect on the dependent variable. An example is that if doctors told you for sure that to live past 80 yrs of age, you should eat good food and exercise daily. In other words, you have domain expert telling you that all the variables directly affect the dependent variable.\n  Backward elimination: In backward elimination, you take all the variables and create the algorithm. Select a significance level, then consider the predictor with Highest P-value and if P-Value \u0026gt; Significance level then eliminate the variable from the equation, else keep it.\n  Forward Selection: In forward selection, you start with linear regression using every single variable. You will end up with n simple linear equation. Next, you chose the one with the lowest P-Value. This is your starting equation. Y = m0X0. Next, you pick one variable again and create an equation with two variables and out of n-1 possibilities again chose the one with the lowest P-value. The process continues until we don\u0026rsquo;t have any variable that is lower than our selected Significance level.\n  Bi-Directional elimination: In bi-directional elimination, you chose 2 significance level. One to enter the equation and one to stay. You start with the forward selection using condition P-Value \u0026lt; SL Enter and then follow backward elimination using condition P-value \u0026lt; SLstay. You stop and declare the final equation when no new variable can enter or exit the equation.\n  Score Comparison: In this model, you create all possible combination of the equation, compare the performance using say MSE(Mean Square Error) and use the one with the lowest MSE. That is an insane amount of possible equation. For Example - A model with 10 variables will have 1023 possible combination.\n Note for the purpose of brevity and sanity, we will be using Backward Elimination  model to solve this problem. Also, because this model is fastest and we will still be able to see how the step by method works.\n Step 3: Data preprocessing in python  We will now start the calculation using the process that we learnt in the first post of this series. If you remember from Linear regression post\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  # -*- coding: utf-8 -*-\r import numpy as np\rimport matplotlib.pyplot as py\rimport pandas as pd\r#Read the dataset\r dataset = pd.read_csv(\u0026#34;50_Startups.csv\u0026#34;)\r#Divide the dataset in dependent and Independent variables\r X= dataset.iloc[:, :-1].values\ry = dataset.iloc[:, -1].values\r  1 2    Next part of data processing is to find if there is any missing data. If there is missing data then we need to use Imputer to fix the missing data. To do that we will first check the data description, then try to get a count of missing values in the dataset\n1 2 3 4 5 6 7  #Describe the dataset\r pd.DataFrame.describe(dataset)\r#Check for missing data\r null_columns=dataset.columns[dataset.isnull().any()]\rnum_emptycolumns = dataset[null_columns].isnull().sum()\rprint(num_emptycolumns)\r  Series([], dtype: float64)\r Currently, there are no missing values in the dataset hence the result of num_emptycolumns.\nMoving on to the next item in the data clean up is taking care of categorical values in the State column.\n1 2 3 4 5 6  #Taking care of Categorical values.\r from sklearn.preprocessing import OneHotEncoder, LabelEncoder\rlabel_encoder = LabelEncoder();\rX[:,3]=label_encoder.fit_transform(X[:, 3])\roneHotEncoder = OneHotEncoder(categorical_features=[3])\rX= oneHotEncoder.fit_transform(X).toarray()\r  1     Hey, what about all the talk about keeping n-1 categorical items?\n So you are right to notice that whatever we did will lead us directly to the dummy variable trap. I fell into one when I was trying to learn it. So how do we fix it? If you have been thinking about just crossing out one of the columns as we did in the pic few scrolls above \u0026hellip;\u0026hellip;. you are right!!! That\u0026rsquo;s exactly how we are going to fix it.\n1 2  #getting out of dummy variable trap\r X = X[:,1:] # Select all the rows and all the columns starting from index 1 onwards.\r   Now divide the data in training and test set\n1 2 3 4 5 6  #Create training and test set\r from sklearn.model_selection import train_test_split\rX_train, X_test, y_train, y_test = train_test_split(X, y,\rtest_size = 0.20,\rtrain_size=0.80,\rrandom_state=0)\r  Step 4: Training the model\nNow that we have cleaned up our data, we can train our data. We are not going to do any feature scaling here, because the library and class that we are going to use, will do that automatically for us. We will use the same LineaRegression class that we used in the linear regression post.\n1 2 3  from sklearn.linear_model import LinearRegression\rregressor = LinearRegression()\rregressor.fit(X_train, y_train)\r  The above code trained our data. Now we need to check how does our model score or how good is it at predicting the data?\nTo Predict we just need to call the predict function.\n1  y_pred = regressor.predict(X_test)\r  You can see that the predicted values y-pred is pretty close to y_test. Some of the rows do have a significant difference and the numbers may look far apart but the others are pretty close. So how close are we? How confident are we that the trendline would fit closely. To answer this we need to look at our training and test score.\n1 2 3  print(\u0026#39;Train Score: \u0026#39;, regressor.score(X_train, y_train))\rprint(\u0026#39;Test Score: \u0026#39;, regressor.score(X_test, y_test))\r  Train Score: 0.9501847627493607\rTest Score: 0.9347068473282446\r The above score tells us that our model has 95% and 93.5% accurate for training and test data. This not bad.\nOne last thing that I learnt was that if someone asked me how do I calculate the future values that may come up? To do that we need to get the co-efficient and intercept of the regression equation. The regression equation as discussed earlier would look something like this -\n Y = b0X0 + b1X1+ b2X2 + b3X3 + b4X4 + b5X5 + C\n 1 2 3  print(regressor.coef_)\rprint(regressor.intercept_)\r  [-9.59284160e+02 6.99369053e+02 7.73467193e-01 3.28845975e-02\r3.66100259e-02]\r42554.16761772438\r If we take the first row from X_test - 1\t0\t66051.5\t182646\t118148\n 1*-9.59284160e+02 + 0*6.99369053e+02 + 66051.5 * 7.73467193e-01 + 182646*3.28845975e-02 + 118148 * 3.66100259e-02 + 42554.16761772438\n The output would be 103015.19329118208, which is same as first row of y_pred.\n1  1 * -9.59284160e+02 + 0 * 6.99369053e+02 + 66051.5 * 7.73467193e-01 + 182646 * 3.28845975e-02 + 118148 * 3.66100259e-02 + 42554.16761772438\r  103015.19329118208\r So that is the most basic way to do to solve a problem using Multiple Linear regression. Hope you enjoyed this series. Stay tuned for the next series where we will actually see the continuation of Multiple Linear regression and learn the Backward Elimination process.\n"
},
{
	"uri": "/2019/01/27/part-3-ml-understanding-p-value/",
	"title": "Part 3 Machine Learning Understanding P Value",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "Machine learning tutorial on Data preprocessing",
	"content": "In the previous post, we learnt about Simple Linear regression. I wanted to start this section with multiple linear regression tutorial but as I was going over the content on the template to run create the regression model, I felt that we need understand P-Value concept before we move ahead.\nSo what is P-Value ?\nBefore I bore you with stats definition of the P-Value. Let\u0026rsquo;s start with something simple.\nMr X and Mr Y are good friends. One day Mr X and Mr Y decided to go scuba diving. The water in the lake was perfect blue and you could see the bottom and all the fishes swimming in there. After a while,\nMr X:\n I deem that more than 10% of the fishes in the lake are male\u0026rdquo;.\n Mr Y who was also the warden of the lake.\n It is not possible as they release more female fishes than male.\n Mr X:\n Every other fish that I see is male, hence my statement stands correct.\n Mr Y:\n Let\u0026rsquo;s use stats and find out if your statement is true. As I am the warden and know the fact that there are more female than male. Let\u0026rsquo;s call my statement as\n  *H0: \u0026ldquo;There are more female than male.\u0026rdquo;\nand your statement as *\n  Ha: \u0026ldquo;The number of male fish in the lake is more than 10%\n Mr Y:\n Now if only I can prove that chances of my statement H0 happening is much higher than then your statement Ha can be rejected. Let\u0026rsquo;s use P-value\n Mr X:\n What\u0026rsquo;s a P-Value?\n Mr Y:\n So based on the definition below, if we catch 10 samples of fish from the lake and 2 or more of those are male. We will then repeat the experiment multiple times and note down the result. Then we will find out the probability of the number of males caught in 100 experiments and conclude that my statement H0 is true and you cannot reject my argument.\n Mr X\n I caught 10 fishes and got 7 are female and 3 are male. I will now repeat this experement 100 times.\n Based on the above experiment what is the likelihood that Mr X would have got the same result? Calculating this likelihood is called P-Value.\n What do we do with this P-Value?\n The P-Value is used to validate a hypothesis. In the above example, the significance level chosen was 0.05. The P-Value calculated(Standard way using historgram)\nSo based on the above histogram shows how many females were caught. The diagram above is a random diagram that I copied from a different dataset. But assume that number of times the male figure was more than 1 is 21. Then the\n probability(fish is male) = 21/100 or 0.21 or 21%\n So Hypothesis rule is that if the\n p-value is less than Significance level - Reject the H\u0026lt;sub\u0026gt;0\u0026lt;/sub\u0026gt;\np-value is greater than or equal to Significance level - Cannot reject the H\u0026lt;sub\u0026gt;0\u0026lt;/sub\u0026gt;. We do not have enough eveidence for the claim H\u0026lt;sub\u0026gt;a\u0026lt;/sub\u0026gt;\n In the above case we chose Significance level = 0.01 and our p-value=0.21, so which means that we cannot reject the null hypothesis or H\u0026lt;sub\u0026gt;0\u0026lt;/sub\u0026gt; and we do not have enough evidence to say that Number of male fishes is more than 10% in the lake\nCommon conception about P-VALUE There are two things that you need to understand about P-Value. The two most common things that I had to keep reminding myself(every few months as I tend to forget) are\n  **The p-value is NOT the probability the claim is true. **\nWouldn\u0026rsquo;t it be amazing if that was true! Imagine - “there is 30% chance that this M\u0026amp;M pack is heavier than 100g”. Sadly, that\u0026rsquo;s not the case.\n  The p-value is NOT the probability the null hypothesis is true.\nThis one trips me up all the time. When I was trying to refresh my notes from Khan Academy about hypothesis testing, I had to keep repeating this rule as I got almost every question wrong, when it asked someting like - \u0026ldquo;You should accept that null hypothesis is true. The correct way to interpret the result is by reminding that \u0026ldquo;Null hypothese cannot be rejected\u0026rdquo;. Another way of saying it is - I will give you benefit of doubt that Null hypothesis is true - until a more conclusive proof comes forward.\n  The P-Value only tells us whether there is a Strong or Weak/low evidence that our null hypothesis H\u0026lt;sub\u0026gt;0\u0026lt;/sub\u0026gt; is true or not.\nHow to calculate P-Value There are a number of ways to calulate P-value, a topic which I am not going to touch in this series. Here are some of the resources which will help you understand different techniques:\n P-Value calculator Wikihow - Calculate P-Value  This conclues this series on P-Value. In the next series we will review Multiple linear regression and you will understand how P-Value fits in the bigger picture.\n"
},
{
	"uri": "/2019/01/22/part-2-ml-simplelinear-regression/",
	"title": "Part 2 Machine Learning Simplelinear Regression",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "Machine learning tutorial on Data preprocessing",
	"content": "In the previous post we learned about data pre-processing. In this post we will review the simplest algorithm - Simple Linear Regression.\nBusiness Problem: In this series, we are going to learn about Simple Linear Regression. We will review a data set about Salary and Experience in age. As a data scientist, your job is to help the HR department predict the salary of a person based on his years of experience if he or she accepts the job offer. If you offer too low, the person will not accept the job offer. If you offer too high, then you will be wasting the company\u0026rsquo;s resources($$).\nGetting the dataset  Jupyter Notebook \u0026amp; images Simple Regression  What is Simple Linear regression? If we draw a graph of salary vs Experience, you will see a linear trend.\nBased on the graph, it is clear that this is a positive slope. If the co-efficient b1 is big, the slope is going to steeper, which means that if there is a small increase in the age, then there will be a big increase in the salary. If the value of b1 is small, the slope is going to be more gentle and with change is experience, the salary is going to increase gently.\nHow is a trendline determined by a model? The model tries to find the trendline by determining the least of Sum of errors. In the below diagram, imagine the red cross as observed value and green cross as determined value(model prediction). The algorithm finds the difference between the and squares them. The algorithm does this for all the observed values and determines the slope of trendline which given the minimum of SUM(y - y^)2\nSteps to solve the problem.  Step 1: Data Preprocessing  We will follow the same process as we did in the first series. We will import the libraries and read the csv file and take a look at the data.\n1 2 3 4 5 6 7 8 9  # Importing the libraries\r import numpy as np\rimport matplotlib.pyplot as plt\rimport pandas as pd\r# Importing the dataset\r dataset = pd.read_csv(\u0026#39;../Salary_Data.csv\u0026#39;)\rX = dataset.iloc[:, :-1].values\ry = dataset.iloc[:, 1].values\r   Step 2: Split the data into training and test data  Since there are 30 rows, we will divide the data in 20:10(training:test)\r 1 2 3  #Split the data into training and test data\r from sklearn.model_selection import train_test_split\rX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=1/3, random_state=0)\r    Step 3: Feature Scaling\nWe won\u0026rsquo;t be feature scaling or normalizing here because the library that will execute the model takes care of it. So we are going to skip this step.\n  Step 4: Train the model\nAt this point our data pre-processing is complete and we will use the library to run the regression on the training data set.\n  1 2 3 4  #Fittiing the Simple linear regression on the training set\r from sklearn.linear_model import LinearRegression\rregressor = LinearRegression( )\rregressor.fit(X_train, y_train)\r  LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\rnormalize=False)\r In the above code, we have trained our model and saved it in the variable regressor.\n Step 5: Predict and compare with the actual test set  Next, we are going to predict the values of the test sample and get the predicted results in variable y_pred.\n1 2  # Predicting the salary of the test sample\r y_pred = regressor.predict(X_test)\r  Let\u0026rsquo;s see how did the model predict.\n Step 5: Plot the data  To better understand, let\u0026rsquo;s create plot the trendline of our model and look for two things\n What is the fit of trendline for training data? What is the fit of trendline on test data against predicted values?  1 2 3 4 5 6 7  plt.scatter(X_train, y_train, color=\u0026#39;red\u0026#39;)\rplt.plot(X_train, regressor.predict(X_train), color=\u0026#39;blue\u0026#39;)\rplt.title(\u0026#39;Salary vs Experience (Training Set)\u0026#39;)\rplt.xlabel(\u0026#39;Years of Experience\u0026#39;)\rplt.ylabel(\u0026#39;Salary\u0026#39;)\rplt.show()\r  Here\u0026rsquo;s how the graph would like for Training data\nCouple of things to note. The scatter function just plots the x,y values on the graph as red dots\n plt.scatter(X_train, y_train, color='red\u0026rsquo;)\n The plot function also maps the data as blue dots but it joins them via line starting from first mapping to the last. Additionally, you will also notice that in the y-axis, we have passed model function predict(X_train) and not predict(x_test) because we want to use the function created using the training set - y=mx+c.\n plt.plot(X_train, regressor.predict(X_train), color='blue\u0026rsquo;)\n Plot vs Scatter The primary difference of plt.scatter from plt.plot is that it can be used to create scatter plots where the properties of each individual point (size, face color, edge color, etc.) can be individually controlled or mapped to data.\nThe purpose of the above code is to show trendline against the training data points(red dots). If we wanted to show predicted line as set plotted dots, we would have used\n plt.scatter(X_train, regressor.predict(X_train), color='blue\u0026rsquo;)\n In that case the graph would have looked like this.\nHere\u0026rsquo;s how the graph would like for Test data\n1 2 3 4 5 6 7 8  #Plot the data against test set\r plt.scatter(X_test, y_test, color=\u0026#39;red\u0026#39;)\rplt.plot(X_train, regressor.predict(X_train), color=\u0026#39;blue\u0026#39;)\rplt.title(\u0026#39;Salary vs Experience (Test Set)\u0026#39;)\rplt.xlabel(\u0026#39;Years of Experience\u0026#39;)\rplt.ylabel(\u0026#39;Salary\u0026#39;)\rplt.show()\r  As explained earlier, the trend line is what the model was trained against the training data set. Hence\n plt.plot(X_train, regressor.predict(X_train), color='blue\u0026rsquo;)\n and not\n plt.plot(X_test, regressor.predict(X_test), color='blue\u0026rsquo;)\n Now let\u0026rsquo;s create a more complete picture - the training set(RED DOTS), test set(GREEN DOTS) and predicted value (BLACK DOTS).\n1 2 3 4 5 6 7 8 9 10  #Plot the data against test set\r plt.scatter(X_train, y_train, color=\u0026#39;red\u0026#39;)\rplt.scatter(X_test, y_test, color=\u0026#39;green\u0026#39;)\rplt.scatter(X_test, y_pred, color=\u0026#39;black\u0026#39;)\rplt.plot(X_train, regressor.predict(X_train), color=\u0026#39;blue\u0026#39;)\rplt.title(\u0026#39;Salary vs Experience (Test Set)\u0026#39;)\rplt.xlabel(\u0026#39;Years of Experience\u0026#39;)\rplt.ylabel(\u0026#39;Salary\u0026#39;)\rplt.show()\r  So you will notice that all the black dots lie on the trend line because they are created using the trendline equation.\nThat\u0026rsquo;s it. We just trained a model using Simple linear regression and predicted the values, then compared it against test data.\n1    "
},
{
	"uri": "/2019/01/21/part-1-ml-data-preprocessing/",
	"title": "Part 1 Machine Learning Data Preprocessing",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "Machine learning tutorial on Data preprocessing",
	"content": "This is the first of many series on machine learning.\nGet the Dataset   Download the following zip files\n Jupyter Notebook \u0026amp; images Data    Unzip the folder and copy Files and Data under folder location Machine Learning A-Z Template Folder\\Part 1 - Data Preprocessing\n  Review the dataset The above dataset shows Country, Age, Salary and Purchased. The field that we need to research is called Dependent field and others are called Independent Field\nDependent Field A dependent field is a whose outcome or value is derived from other fielda. In this example, we are trying to find Whether a customer made a purchase or not. Hence, Purchased here becomes the dependent field. In terms of coordinate, if we map this on the graph then Purchased will be plotted on the y-axis.\nIndependent field Independent fields are values that we observe. Example - If I stand on the side of the freeway and start noting down the color of each car passed, whether it is a car or a truck, is it raining that day or sunny? etc. These values are called Independent fields. In the above datasheet, Country, Age and Salary are independent fields.\nIn data science, everything is a function. Hence if Purchased field = Y and Country, Age and Salary can be represented as c, a \u0026amp; i respectively. Then the above function can be represented as\nY = Xc + Ta + Zi\nImporting the essential library There are three essential libraries for most basic machine learning projects. Add the below library\nimport numpy as np\rimport matplotlib.pyplot as plt\rimport pandas as pd\r\n1 2 3 4  # Importing the libraries\r import numpy as np\rimport matplotlib.pyplot as plt\rimport pandas as pd\r  Import the dataset Use panadas to import the file data.csv file\n1 2  #Import the dataset\r dataset = pd.read_csv(\u0026#34;../data.csv\u0026#34;)\r  1  dataset.head(6)\r  \r.dataframe tbody tr th:only-of-type {\rvertical-align: middle;\r}\r.dataframe tbody tr th {\rvertical-align: top;\r}\r.dataframe thead th {\rtext-align: right;\r}\r \n\r\rCountry\rAge\rSalary\rPurchased\r\r\r\r\r0\rFrance\r44.0\r72000.0\rNo\r\r\r1\rSpain\r27.0\r48000.0\rYes\r\r\r2\rGermany\r30.0\r54000.0\rNo\r\r\r3\rSpain\r38.0\r61000.0\rNo\r\r\r4\rGermany\r40.0\rNaN\rYes\r\r\r5\rFrance\r35.0\r58000.0\rYes\r\r\r\r\rCreate the dependent and Independent Variable matrix of features 1 2 3  x = dataset.iloc[:, :3].values\ry = dataset.iloc[:, 3:4].values\r  Identify the missing data In the real world when you are handed a dataset. You will find that a lot of data might be missing. Ex - Row 6 Salary is empty and Row 7 Age is missing in our data.csv\nStrategies to handle missing data  Remove the rows that have missing data. This approach is simplest but will skew our dataset if lots of fields are missing. Replace the missing data with Mean Replace the missing data with Median Replace the missing data with Mode or Frequency  As a general rule of thumb mean and median can be applied to numerical values only. It cannot be applied to alphanumeric or String values. This is where we can use Mode or Frequency.\nTaking Care of missing data * (Numerical values)* Scikit library in python provides a class called Imputer which helps in fixing the missing values using the above strategies.\n1 2 3 4  from sklearn.impute import SimpleImputer\rimputer = SimpleImputer(missing_values = np.nan, strategy=\u0026#39;mean\u0026#39;)\rimputer = imputer.fit(x[:,1:3])\rx[:, 1:3] = imputer.transform(x[:, 1:3])\r  In the above code we define a SimpleImputer class object.\nimputer = SimpleImputer(missing_values = np.nan, strategy='mean')\nThe next line imputer = imputer.fit(x[:,1:3]) is telling imputer object on which matrix columns it needs to look for missing value and mark them for filling value as mean\nThe last line x[:, 1:3] = imputer.transform(x[:, 1:3]) fills in the cells of X matrix that were marked by the imputer.\nOne thing that I wanted to try was that would happen if I just used imputer.fit(x) and did not provide the columns which actually had the missing values. What happens is that since you have marked the strategy as strategy='mean', the imputer will try to take the average/mean of each row country, Age \u0026amp; Salary. Since Country is of type String, python will shit in its pant and complain about it. However, if the Country column was numeric, then this imputer.fit(x) would have worked. Additionally, on the left side we have defined that data be copied into x[:, 1:3]. This is because if you write x = imputer.transform(x[:, 1:3]), imputer has marked the cell to be transformed is (1,5) as there are two columns it is looking at Age and Salary but if put only x on the left side, then (1,5) refers to Age 40, while imputer is expecting it to be a Salary column.\nAs you can see, the imputer has filled in the missing values for Salary as $63777.78 and Age as 38.7.\nTaking care of Categorical data Categorical data is any data that is not numeric. Think of it as attributes of an object. Ex - If I am observing cars on a freeway and noting down the speed at which the car is driving and the color of the car. The cars may have different colors such as red, green, blue etc. I can only observe them but cannot do anything else with them like add, subtract, find mean or anything. However, a machine learning algorithm may see value in finding a relation between dependent and independent feature. The algorithm can only make use of item if it is defined in numbers.\nOne way to define them is by assigning them numbers ex- Red =1, Blue =2 and so on.\nIn our current example, we have a categorical data - Country. To convert or encode as it is called in ML, we will again use a library from Scikit\n1 2 3 4  from sklearn.preprocessing import LabelEncoder\rlabelEncoder_x = LabelEncoder()\rx[: ,0] =labelEncoder_x.fit_transform(x[:, 0])\rx\r  array([[0, 44.0, 72000.0],\r[2, 27.0, 48000.0],\r[1, 30.0, 54000.0],\r[2, 38.0, 61000.0],\r[1, 40.0, 63777.77777777778],\r[0, 35.0, 58000.0],\r[2, 38.77777777777778, 52000.0],\r[0, 48.0, 79000.0],\r[1, 50.0, 83000.0],\r[0, 37.0, 67000.0]], dtype=object)\r The above code uses LabelEncoder class to encode the values of the country. Here, France =0, Spain = 2, Germany=1\nThere is however a simple problem here.\n#####Problem:\nThe models are based on equation. Since the LabelEncoder here, has assigned them values 0,1,2, the equation would think that Germany has higher value than France and Spain has a higher value than Germany. This certainly is not the case. These are supposed to be treated as observational values. Example - Picking on our earlier example of observing car speeds and color. If we use LabelEncoder for encoding car colors, the model may come back and say that A red Prius will always be faster than a White Ferrari\nTo get over this problem and use category as markers, we will use another class which will create dummy encoding and this gives equal value to all categorical data. It does that by creating a sparse matrix.\n1 2 3 4 5  from sklearn.preprocessing import OneHotEncoder\roneHotEncoder = OneHotEncoder(categorical_features=[0])\rx= oneHotEncoder.fit_transform(x).toarray()\r  So after dummy encoding, the complete sparse matrix of x looks like this\nSo now let\u0026rsquo;s convert the dependent column Purchased as well. However, we do not need to use dummy encoding as there are only two variables and that it is a dependent variable.\n1 2  labelEncoder_y = LabelEncoder()\ry =labelEncoder_y.fit_transform(y)\r  Splitting dataset into training and test set   Why do we need to split the data into training and test set?\n  This is about an algorithm that will create the equation to predict the result of new information based on history. If you let it run on all of the data then it will learn too much and will have correlation value or in other words overfitting. A simple example in the real world is of a boy who memorizes the book word by word but fails in the actual exam because instead of asking what is 2 +2 like he read in the book, the exam asked what is 1+3. The student learnt too much but cannot relate or imply the same knowledge on a new data set.\n  Sometimes you may have limited data to build the model and may not additional data to test your model.\n    ** What is a good ratio to split the data?**\nUsually, 80/20 or up to 70/30 is a good number. Going beyond 70/30 is not recommended.\n  To split a dataset into training and test set. We will use another class called train_test_split, which returns 4 different values - Training_X, Test_X,Training_Y, Test_Y\n1 2  from sklearn.model_selection import train_test_split\rx_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=0)\r  The data is now split into 8 and 2 observation.\nFeature Scaling/ Normalization/Standardization If you look your dataset and pay attention to independent features Age and Salary, the range varies for Age between 27 - 50 and Salary between 48000 - 83000. When an equation is created, the distance between two dat apoints is huge and the values can be skewed because one of the columns have 27 for age and 83000 for salary.\nThe models are usually based on Euclidean distance. In our case since Salary has a higher range, it will dominate the age values which means when we do distance between observation (27, 48000) and (48, 79000) then (x2-x1) ^2 vs (y2-y1) ^2 is\n441 vs 961000000. Hence Age is overshadowed by Salary.\nIf you are from statistics field, you probably are already familair with standardization or Z-index etc. Above is the two way to calculate the standard range which will always give us a value between 0 and 1\n1 2 3 4  from sklearn.preprocessing import StandardScaler\rsc_x = StandardScaler()\rx_train = sc_x.fit_transform(x_train)\rx_test = sc_x.transform(x_test)\r  NOTE: We are not fitting and transforming the x_test because it is already fitted based on xtrain so that they are now on the same scale. If we would have used fit_transform on both test and train then their scale would have been different say one could between -1 and +1 while the other could be on -3 and +3\n Why did we not apply feature scaling on y or dependent variable?\nIn this case, the values are 0 and 1 only or in other words, this is a classification problem which has two choices, whether a customer bought the product or he did not buy the product. In other scenarios such as that related to multiple regression, we may have situation where we may have to do feature scaling on y as well.  That\u0026rsquo;s all for the first series. Stay tuned for next series.\n"
},
{
	"uri": "/2018/12/30/spring-bean-vs-component/",
	"title": "Spring Bean vs Spring Component",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "The Difference Between @Bean and @Component and When to Use What? This is the most common question that new as well as experienced Spring users get confused about. There are literally hundreds of questions on this Stackoverflow. This article will clear all the confusion.\n Similarities between @Bean and @Autowired  @Bean\n @Bean is an annotation based configuration and hence is used in @Configuration based class. This is an explicit way of defining a bean and is also used on the methods defined in configuration class.  @Component\n This is used in classes which you create in your app. This will only work after you enable component scan on the package that contains your class. With component scan, Spring framework will scan the classpath and add all the classes that are marked with a @Component annotation.\n-This is also called the automated way of binding and discovering your bean.  So the bottom line is that both can do the job of wiring your bean. It\u0026rsquo;s just that with @Bean you have to define each class explicitly and in case of @Component, Spring does this automatically for you. The @Bean way of wiring your bean is analogous to defining Beans in XML, prior to Spring 2.5. Now that you understand what each does(the end result is the same), let\u0026rsquo;s take a look at what is the difference between the two and when you should choose one over the other.\n Difference between @Bean and @Autowired  Scenario: We have a jar file which contains different services ex - Address check service, credit check service etc. This jar file is shared by many different applications/companies Ex - AT\u0026amp;T wants to use Address validator service while FICO wants to use only credit check service.\nIf you use @Component on those service classes and use component scan in the application, then both AT\u0026amp;T and FICO applications will end up detecting credit check in case of AT\u0026amp;T and address validator in case of FICO. As a result, you would face one of the two problems -\n You will end up adjusting the filter on the component scan. In case you have classes sharing the same name by any chance then you would have to add qualifier otherwise application would complain that it found more than two classes were found with same bean name and will fail to run.  Hence, in this scenario, you should use @Bean\nScenario : You downloaded a jar file from GitHub and it is not using Spring. The jar file is a simple and basic java program. Your app wants to use this third-party jar file but since your application is using Spring while the third party jar is not, you will have to write new() keyword to access the functionalities. You want to wire the third party classes.\nSay your class name is MyClass.java and you want to use ThirdPartyClass.java. In this case if you write\n1 2 3 4 5 6 7 8  public class MyClass{\r.....\r@Autowired\rThirdPartyClass thirdPartyClass;\r}\r  Your code will throw NullPointerException if you try and access any method of class object thirdPartyClass. In this scenario, you should use @Bean.\n Rule of Thumb  A simple way to decide between @Component and @Bean is that\n if you want to use third-party classes or jar then use @Bean. If you are writing your own classes for your application then use Component. If you want to use a third party class or jar that is not written using Spring Component then use @Bean.  "
},
{
	"uri": "/2017/03/20/scala-tail-recursion/",
	"title": "Scala: Tail Recursion",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "Tail recursion is a basic but important concept in Functional programming. Recursive functions has always been a pain point for me. I would be eliminated out of several interview rounds if interviewers places emphasis on recursion. In Java world thankfully, most people I know hate recursion because when nesting goes too deep, it impacts the performance if the nested recursion is more than 100 levels deep.\nUnfortunately(Fortunately), functional programming languages like Scala and Haskell have solved this concept with the term Tail Recursion. We will look into the concept of Tail recursion using a sample code below by implementing a function that calculates “factorial”.\nRegular Recursion code: Calculate factorial\ndef factorial(n:Int) :Int={\rif(n\u0026gt;0) n * factorial(n-1)\relse 1 }\r\rSo the problem with above code is that if I pass a value factorial(5) , then the code will create a series of wait to get the result back ex –\nCall 1: 5 * factorial(4)\nCall 2: 4* factorial(3)\nCall 3: 3* factorial(2)\nCall 4: 2* factorial(1)\nCall 5: 1*1\nNow the call retraces the nested flow to jump back to Step 4 to provide the value as 2*1, which traces back to Step 3 – 3*(2*1) and so on.\nImagine what will happen if you pass a factorial(100)??\nNow let’s take a look at how it is done properly in Functional progaramming using scala.\ndef factorial(n:Int) :Int={\rdef calculateFactorial(n: Int, acc:Int){\rif(n\u0026lt;=0) acc\relse calculateFactorial(n-1, n* acc)\r}\rcalculateFactorial(n,1)\r}\rDo you see the difference in code? No?. Let me explain what we just did. In Scala, you can define a local method inside another method. So I created a new method called “calcuateFactorial” that takes two parameter, n:Int and **acc:Int, **where acc is accumalor of the result. Now when I call the function **factorial(5), **the recursion code is not doing any processing or calculation on the method. It just returns the accumalator acc as a result. Ex –\ncall 1 – Intput 5,1\ncall 2 – Input 4, 5*1\ncall 3 – Input 3, 4*(5*1)\ncall 4 – Input 2, 3*(4*(5*1))\ncall 6 – Input 1, 2*(3*(4*(5*1)))\ncall 7 – Input 0, 1*(2*(3*(4*(5*1)))) – **RETURN RESULT as 1*2*3*4*5 which is the second input param\n**\nThat is when a recursion becomes tail recursion. The final call when nesting stops, just returns the result and the previous nested call is not waiting for a result to complete the call/result.\nHope the concept will stay with me and with those of you who hated recursion earlier. It just got real so learn and deal with it 🙂\n~ Ciao\n"
},
{
	"uri": "/2016/06/16/understanding-java-8-lambda-final-finally-variable/",
	"title": "Understanding Java 8 Lambda final finally variable",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "I am a little late to the java 8 party and was trying to quickly get some hands on with lambdas and ran into an issue where I got the error message \nVariables used in lambda should be final or effectively final  . I know what final is but what is effectively final.\nHere is what I was trying to do. I had a HashMap which had values like “one : 1”, “two : 2”, “three : 3” and wanted to replace the String ${one} with 1 etc.\n  public String evaluate(HashMap\u0026lt;String, String\u0026gt; variables){\r  String result = \u0026quot;${One}, ${two}, ${three}\u0026quot;;\rvariables.forEach((k,v)-\u0026amp;gt;{\rString regex = \u0026quot;\\\\$\\\\{\u0026quot; + k + \u0026quot;\\\\}\u0026quot;;\rresult=result.replaceAll(regex, v);\r});\rreturn result;\r}\r \nWhen I assigned result=result.replaceAll(regex, v); I got the error message –\nVariables used in lambda should be final or effectively final . On further research using SO forums and blog I learned that Java 8 has new concept called “Effectively final” variable. It means that a non-final local variable whose value never changes after initialization is called “Effectively Final”. This concept was introduced because prior to Java 8 we could not use a non-final local variable in an anonymous class. If you have access to a local variable in Anonymous class, you have to make it final.\nWhen Lambdas was introduced, this restriction was eased. Hence to the need to make local variable final if it’s not changed once it is initialized as Lambda in itself is nothing but an anonymous class. Java 8 realized the pain of declaring local variable final every time developer used Lambda and introduced this concept and made it unnecessary to make local variables final. So if you see the rule for anonymous class still not changed, it’s just you don’t have to write final keyword every time when using lambdas.\nOK. So now I understand what the error means but how do I solve my issue where I want to replace the variables using regex. Surprisingly, before I looked up\ndocumentation and SO forums, I checked the options suggested by IntelliJ. It said – “Transform result variable into final one element array”. As I clicked continue, My code transformed to\n  public String evaluate(){\r  final String[] result = {\u0026quot;${One}, ${two}, ${three}\u0026quot;};\rvariables.forEach((k,v)-\u0026amp;gt;{\rString regex = \u0026quot;\\\\$\\\\{\u0026quot; + k + \u0026quot;\\\\}\u0026quot;;\rresult[0] = result[0].replaceAll(regex, v);\r});\rreturn result[0];\r }\n\nNow what the heck just happened? Why is a String not allowed to change but an Array is allowed to change? Going back to basics of Java I realized that when we decalre a variable final, it is the reference to the object that is set to final. So in this case when I write\nfinal String result= “abc”; The reference is STRING OBJECT result —memory location —\u0026gt; “abc” and because the result is declared final, it cannot change the memory reference and point to memory location who value is say ” DEF”.\nWhen I write\nfinal String [] result = {“abc”} In this case, result is pointing to a reference that is a Array and that array has value that reference memory location of String “abc”.\nFINAL STRING [] result —- Memory location –\u0026gt; Single Array —–Memory location —\u0026gt; “abc”.\nSo as you see our result now references the memory location of Array element but the value Array element can change. Remember what is constant here is the reference, not its values.\n ~~ Smell the Java ~~\nDinesh\n"
},
{
	"uri": "/2015/12/26/how-to-set-up-apache-storm-on-mac-using-brew/",
	"title": "How to set up Apache Storm on mac using brew",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "I am learning about Apache Storm and the guide had long and winding instructions on how to install Apache Storm. I installed the single node using brew and it was a breeze. I did not had to spend time figuring out out if I was installing latest version.\nPre-requisites:\nMake sure that you have ‘HomeBrew‘ installed. One reason that I prefer ‘brew’ is that I do not have to remember where things are installed and brew manages and fixes any updates that have been introduced. It also makes installation and uninstall super easy. Everything this is saved under\n/url/local/Cellar. Step 1: Install Zookeeper  ‘ brew install zookeeper’\n After the installation is complete, you will see this message.\n To have launchd start zookeeper at login:\n  ln -sfv /usr/local/opt/zookeeper/*.plist ~/Library/LaunchAgents\n  Then to load zookeeper now:\n  launchctl load ~/Library/LaunchAgents/homebrew.mxcl.zookeeper.plist\n  Or, if you don’t want/need launchctl, you can just run:\n  zkServer start\nI prefer not to launch zookeeper at login as it will sow down my mac login. So I prefer to start and stop Zookeeper using the command-\n  ‘zkServer start/stop’\n Step 2: Install ZeroMQ ‘brew install zeromq’\nStep 3: Install Apache storm ‘brew install storm’\nThis above command will install everything in Cellar folder and will have a symlink in ‘/usr/local/opt/storm’ folder.\nStep 4: Update the storm config file storm.yaml. This file will be in /usr/local/opt/storm/libexec/conf folder.\nAfter opening this file you will see that everything is commented out. So we will add the following.\n storm.zookeeper.servers:\n  – “localhost”\n  # – “server2”\n  #\n  nimbus.host: “localhost”\n  nimbus.thrift.port: 6627\n  ui.port: 8772\n  storm.local.dir: “/Users/dinesharora/storm/data”\n  java.library.path: /usr/lib/jvm”\n  supervisor.slots.ports:\n  – 6700\n  – 6701\n  – 6702\n  – 6703\n If you will notice that I have added “storm.local.dir”. Make sure that whatever folder you create, they have the right permissions because I initially added “/home/user/storm/data” and did not realize that you cannot create any directory under “/home” folder. This was causing issues when I started nimbus and supervisor.\nStep 5: start zookeeper, nimbus, supervisor and ui Below are the location on shell scripts. Start them in the given sequence\n ‘zkServer start’\n  ‘/usr/local/opt/storm/libexec/bin/storm nimbus’\n  ‘/usr/local/opt/storm/libexec/bin/storm supervisor’\n  ‘/usr/local/opt/storm/libexec/bin/storm ui’\n Step 6: Check that everything is running smoothly.\nTo do that run the below command.\n‘jps’\nThe above command should give the following result.\n Dineshs-MBP:bin dinesharora$ jps\n  5282 supervisor\n  5267 nimbus\n  5460 core\n  5735 Jps\n  4235 QuorumPeerMain\n Step 7: Check the server index page. Access the url – ‘http://localhost:8772/index.html’. If you are able to access the page then your installation is successful.\n P.S. If you upgraded to new OSX – El Captain then you might have issues with brew itself. Do yourself a favor and reinstall brew again.\n ~ Stir a storm\n"
},
{
	"uri": "/2015/09/27/waffle-windows-single-sign-on/",
	"title": "Waffle : Windows Single Sign On",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "Last week, I was working on an application where I had to do LDAP authentication. My cmpany has been using a very old jar file that had the required code for authenticating and authorizing users. There were two problems for me.\n  I had to revisit the documentation on LDAP setting in Jboss 4 and figure how to do the set up. Making changes in login-config.xml etc.\n  My new application is using Spring-boot, which comes with built in tomcat libraries. I had to either find some documentation on Timcat with Spring boot 4 or build the app as war and deploy in Jboss 7 and not Jboss 4, which means going over documentation and tutorial.\n  What is waffle? While trying to figure out a lazy way of doing things, I ran into Waffle project. WAFFLE is a native Windows Authentication Framework consisting of two C# and Java libraries that perform functions related to Windows authentication, supporting Negotiate, NTLM and Kerberos. Waffle also includes libraries that enable drop-in Windows Single Sign On for popular Java web servers, when running on Windows. While Waffle makes it ridiculously easy to do Windows Authentication in Java, on Windows, Waffle does not work on *nix. In Short, if a user logs into his company computer, he would be authenticating over LDAP to make sure that he is authorized to use the computer. Waffle gives you an opportunity to make use of the exixsting infrastrutuce and help you authenticate and authorzie the user.\nSet Up:: To use waffle in java, we just need to add the maven dependency:\n\u0026lt;properties\u0026gt;\r\u0026lt;waffle.version\u0026gt;1.5\u0026lt;/waffle.version\u0026gt;\r\u0026lt;/properties\u0026gt;`\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.github.dblock.waffle\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;waffle-jna\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;${waffle.version}\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt; net.java.dev.jna\u0026lt;/\u0026lt;wbr /\u0026gt;groupId\u0026gt;\r\u0026lt;artifactId\u0026gt; platform\u0026lt;/\u0026lt;wbr /\u0026gt;artifactId\u0026gt;\r\u0026lt;version\u0026gt;3.5.2\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt; Create a new instance of waffle.windows.auth.impl.WindowsAuthProviderImpl.\nHere are a couple of scenario that you can do without any nasty setup in Java, Jboss, Tomcat etc.\nScenario 1: Logon a user and get his domain and local groups This calls Win32-LogonUser, checks the user token and extracts all local domain information.\nIWindowsAuthProvider prov = new WindowsAuthProviderImpl()\rIWindowsIdentity identity = prov.logonUser(\u0026quot;userName\u0026quot;, \u0026quot;pwd\u0026quot;)\rSystem.out.println(\u0026quot;User identity: \u0026quot; + identity.getFqn())\rfor(IWindowsAccount group : identity.getGroups()) {\rSystem.out.println(\u0026quot; \u0026quot; + group.getFqn() + \u0026quot; (\u0026quot; + group.getSidString() + \u0026quot;)\u0026quot;)\r}\rOutput::\n\rUser identity: acnna\\darora\racnna\\\\None (S-1-5-21-42300245183-42300245183-3597729351-513)\rEveryone (S-1-1-0)\racnna\\\\HomeUsers (S-1-5-21-42300245183-42300245183-3597729351-2418)\rBUILTIN\\Administrators (S-1-5-32-544)\rBUILTIN\\Users (S-1-5-32-545)\rNT AUTHORITY\\NETWORK (S-1-5-2)\rScenario 2: Active directory: get the list of trusted domains IWindowsAuthProvider prov = new WindowsAuthProviderImpl()\rIWindowsDomain[] domains = prov.getDomains()\rfor(IWindowsDomain domain : domains) {\rSystem.out.println(domain.getFqn() + \u0026quot;: \u0026quot; + domain.getTrustDirectionString())\r}\rOutput::\nScenario 3:: Is computer active on a domain? \rIWindowsAuthProvider prov = new WindowsAuthProviderImpl()\rIWindowsComputer computer = prov.getCurrentComputer()\rSystem.out.println(computer.getComputerName())\rSystem.out.println(computer.getJoinStatus())\rSystem.out.println(computer.getMemberOf())\rFor systems that run both with and without active directory you need to programmatically figure out whether a computer is joined to a domain or a workgroup. If it’s joined to a domain or a workgroup you want to know what domain the computer is joined to.\nScenario 4: Negotiate Single Sign on This lets both client and server side to negotatite the sign on protocol. The code below, gets the token which can be shared between client and server and be used to lookup its domains.\n\rString securityPackage = \u0026quot;Negotiate\u0026quot;\r// client credentials handle\rIWindowsCredentialsHandle clientCredentials = WindowsCredentialsHandleImpl.getCurrent(securityPackage)\rclientCredentials.initialize()\r// initial client security context\rWindowsSecurityContextImpl clientContext = new WindowsSecurityContextImpl()\rclientContext.setPrincipalName(Advapi32Util.getUserName())\rclientContext.setCredentialsHandle(clientCredentials.getHandle())\rclientContext.setSecurityPackage(securityPackage)\rclientContext.initialize()\r// accept on the server\rWindowsAuthProviderImpl provider = new WindowsAuthProviderImpl()\rIWindowsSecurityContext serverContext = null\rdo\r{\rif (serverContext != null) {\r// initialize on the client\rSecBufferDesc continueToken = new SecBufferDesc(Sspi.SECBUFFER_TOKEN, serverContext.getToken())\rclientContext.initialize(clientContext.getHandle(), continueToken)\r}\r// accept the token on the server\rserverContext = provider.acceptSecurityToken(clientContext.getToken(), securityPackage)\r} while (clientContext.getContinue() || serverContext.getContinue()) `\rSystem.out.println(serverContext.getIdentity().getFqn())\rfor (IWindowsAccount group : serverContext.getIdentity().getGroups()) {\rSystem.out.println(\u0026amp;#8221 \u0026amp;#8221 + group.getFqn())\r}\rserverContext.dispose()\rclientContext.dispose()\rclientCredentials.dispose()\r~Ciao\n"
},
{
	"uri": "/2015/07/22/4-ways-to-set-up-datasources-in-jboss-as-7/",
	"title": "4 ways to set up datasources in Jboss AS 7",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "Last year my company decided to move from JBoss 4.x/5.x to Jboss AS 7. We use Maven and IZPack plugin to create automated deployment to Jboss 4. As a part of IZPack plugin, we would write the install.xmls for various environment, which would help us deploy war files, log.xml, jars, properties file in respective folders. So the advantage was that Jboss-4 allows you to deploy several xxx-ds.xml files in deploy folder and you can have multiple apps deployed in same Jboss and each app uses it’s respective xxx-ds.xml file.\nWhen we started with Jboss AS 7 we learnt that all datasource setting had to be done in standalone.xml file. **Jboss 7.0 ** got rid of xxx-ds.xml file concept. The problem with this approach was that we could not use IZPack plugin to replace the environment variable if we were deploying multiple apps in the Jboss because every IZPack installation would overwrite the previous standalone.xml setting for datasource section. So our deployment engineer had to manually go and configure each datasource in standalone.xml. God forbid when we have to update expiring passwords for database every few months, then changing all these passwords would have created a havoc.\nAs a result, we abandoned or let’s say delayed the Jboss4 to Jboss AS 7 upgrade. I was not involved in this first attempt however last week I had some time on hand so I started looking into the issue. It turns out the newer version of Jboss AS 7.1.1-FINAL had re-introduced the concept of deployable datasources.\n Let me walk you through 4 ways of configuring the datasources in Jboss AS 7.1.1-FINAL.\n**METHOD 1: Standard way. Setting up datasource using standalone.xml(**Not preferred if you have multiple apps in the deployments folder). In this example let’s assume we are using Oracle database.\n**Step 1: **Add the Ojdbc14.x.x jar file in the folder\n Jboss/modules/com/oracle/jdbc/main\n Keep in mind that the folder structure is really important.\nStep 2: Create a file module.xml and it along with for jdbc jar file. Add the below xml in the module.xml file.\nSo in the above file, we are defining the location of the jar file in \u0026lt;**resource-root\u0026gt; **tag. You can actually put the jar file in some other folder as well and define the path here but that is not an advisable approach as you will have to provide the full path of the jar file which will cause issues if you have to move the Jboss folder to some other server location.\n**Step 3: **Open the standalone.xml file under jboss-as-7.1.0.Final\\standalone\\configuration folder. In the datasources section define datasources. EX:\nThat’s it. But this is the standard way of adding the datasource. The next time I want to deploy another application in the same Jboss which uses MySQl, I would have to manually update the **standalone.xml **so that I do not change mess up the datasource set up for Oracle.\n Method 2: Deploy datasource in stanadalone jar. Assume we are configuring for Oracle datasource.\n**Step 1: **Copy ojdbc14.xx.jar in the Jboss/standalone/deployments folder.\n cp ojdbc14.10.1.05.jar /usr/jboss-as-7.1.1.Final/standalone/deployments\n Step 3: Start the Jboss server to see if the jar file is successfully deployed.\n\u0026lt;strong\u0026gt;09:32:10,400 INFO [org.jboss.as.server] (DeploymentScanner-threads - 2) JBAS018559:\u0026lt;br /\u0026gt;\rDeployed \u0026quot;mysql-connector-java-5.1.18-bin.jar\u0026quot;\u0026lt;/strong\u0026gt;\nStep 4: Deploy the datasource file\nJust fill in an xml file which ends (as we used to do) in -ds.xml, for example this is a oracle-ds.xml which is suitable for Oracle database. ** **\nStep 5: Deploy your web app and you are good to go.\nAt this point you might wonder if there is any pitfall when using the older -ds.xml approach ? well actually if you “bypass” the management interface and deploy the datasource in the old way, you will not be able to manage it through the CLI or Web admin interface. As you can see from this snapshot, our datasource is not enlisted through the manageable resources of the Web interface.\n METHOD 3: Deploying the datasource along with your application\nYou can actually deploy your datasource along with your application, just you used to do in the past.\nHere’s a sample Web application Structure which ships with a datasource (in the WEB-INF folder). For other a JAR archive you would rather need copying the datasource in the META-INF folder:\n*Method 4: Hybrid approach using -ds.xml + standalone.xml\nI found this approach to be the best because I do not like put jar files inside a WAR applcation which is written in MAVEN. I also do not like to drop JDBC jar files in deployments folder as it I consider it a sacred place for WAR files only. So I figured out a hybrid approach.\n**Step 1: **Add the Ojdbc14.x.x jar file in the folder\n Jboss/modules/com/oracle/jdbc/main\n Keep in mind that the folder structure is really important.\nStep 2: Create a file module.xml and it along with for jdbc jar file. Add the below xml in the module.xml file.\nSo in the above file, we are defining the location of the jar file in \u0026lt;**resource-root\u0026gt; **tag. You can actually put the jar file in some other folder as well and define the path here but that is not an advisable approach as you will have to provide the full path of the jar file which will cause issues if you have to move the Jboss folder to some other server location.\n**Step 3: **Open the standalone.xml file under jboss-as-7.1.0.Final\\standalone\\configuration folder. In the datasources section define datasources. Here you only define the drivers in the datasources section.\nNotice that I have defined 2 drivers and have named them as “mssql” and “oracle“. Also notice the module, this is suppose to be exactly like the folder structure of jar file under **jboss/modules ** section.\n**Step 4: **Create a **xx-ds.xml **file and drop it in deployments folder.\nNotice that I have commented out the ** section. **The way Jboss figures out the driver is by looking at tag name **oracle **in my xx-ds.xml.\n That’s it.\n~Ciao\n"
},
{
	"uri": "/2015/04/23/powermock-how-to-test-a-private-method/",
	"title": "PowerMock : How to test a private method",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "“I HAVE THE POWER!!” – I had this feeling a few days ago. I will be honest that at work I do not get time to write unit test cases for each and every piece of code that I write. Often when I do have time, I make an effort to write test cases even for the trivial piece of code blocks such as — Check if properties file is present.\nI was working on new code where I had the luxury to write the code in peace (a rarity at my work place where every project is like a fire drill). While writing test cases I came across a situation where I had a class with two methods:\n1 2 3 4 5  public void my_public_method()\rprivate void my_private_method()\r  I wanted to write test cases for both the method. However Junit would not allow me to write a test case for a private method. I searched over internet forums and every one suggested that I use Java Reflection API to write my test cases or make my private method public, which I did not want to do.\nThat’s when POWERMOCK steps in and in a tiny little section of its documentation I noticed a piece of “**WhiteboxImpl” ** class which can help me test private methods.\nSo that’s what I am going to demonstrate in this tutorial.\nSTEP 1: Add Maven jar files\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  \u0026lt;properties\u0026gt;\r\u0026lt;relative.path\u0026gt;relative/svn/path\u0026lt;/relative.path\u0026gt;\r\u0026lt;powermock.version\u0026gt;1.6.2\u0026lt;/powermock.version\u0026gt;\r\u0026lt;/properties\u0026gt;\r\u0026lt;dependencies\u0026gt;\r\u0026amp;#8230;\u0026amp;#8230;..\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;4.11\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.powermock\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;powermock-module-junit4\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;${powermock.version}\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.powermock\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;powermock-api-easymock\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;${powermock.version}\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependencies\u0026gt;\r  STEP 2: Create a class MyClass.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  public class MyClass {\r//PUBLIC METHOD\r\rpublic String my _public _method(){\rString msg=\u0026#34;This is my PUBLIC method\u0026#34;;\rSystem.out.println(msg);\rreturn msg;\r}\r//PRIVATE METHOD\r\rprivate String my _private _method(){\rString msg=\u0026#34;This is my PRIVATE method\u0026#34;;\rSystem.out.println(msg);\rreturn msg;\r}\r}\r  STEP 3: Write a test case for public method : my _public _method\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  import org.junit.Assert;\rimport org.junit.Test;\rimport org.junit.runner.RunWith;\rimport org.powermock.core.classloader.annotations.PrepareForTest;\rimport org.powermock.modules.junit4.PowerMockRunner;\rimport org.powermock.reflect.internal.WhiteboxImpl;\r@RunWith(PowerMockRunner.class)\r@PrepareForTest(MyClass.class)\rpublic class MyClassTest {\rfinal String publicMsg = \u0026#34;This is my PUBLIC method\u0026#34;;\rfinal String privateMsg = \u0026#34;This is my PRIVATE method\u0026#34;;\r@Test\rpublic void testMy _public _method() throws Exception {\rMyClass myClass = new MyClass();\rString msg=myClass.my _public _method();\rAssert.assertEquals(publicMsg,msg);\r}\r}\r  As you can see above that there is no issue with calling a public method and it will run successfully but when you try and call the private method, the code will show error that private method is not visible.\nSTEP 4: Use PowerMock’s WhiteboxImpl class to test a private method.\nBefore you do anything you need to make sure that you added Powermock annotations correctly.\n Add these two annotations to your class.  [java]\n@RunWith(PowerMockRunner.class)\n@PrepareForTest(MyClass.class)\n[/java]\n Write the code to test private method.  1 2 3 4 5 6 7 8 9 10 11 12 13  @Test\rpublic void testMy _private _method() throws Exception {\rMyClass myClass = new MyClass();\rString msg= WhiteboxImpl.invokeMethod(myClass, \u0026#34;my _private _method\u0026#34;);\rAssert.assertEquals(privateMsg,msg);\r}\r  The syntax is pretty simple WhiteboxImpl.invokeMethod(, “,input param1, input param2,…);\nThe WhiteBoxImpl class actually uses “Java Reflection API” in the background to make a call, but for the lazy coders like me, who do not want to write Reflection API(Read hate Reflection API), the WhiteBoxImpl class is a small piece of coding heaven.\nNow run the test class and you will see that test cases have passed.\n~Ciao –Repeat the mantra – “I HAVE THE POWER{MOCK}!!!”\n"
},
{
	"uri": "/categories/uncategorized/",
	"title": "Uncategorized",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/2015/03/30/install-or-manage-multiple-versions-of-java-on-os-x/",
	"title": "Install Or Manage multiple versions of Java on OS X",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "A few weeks ago my Mac hard drive crashed and I had to get a new grad drive. As part of upgrade, I had to wipe my drive clean and install Yosemite. What I did not realize was that Apple had goofed up Java instlation on Mac, as result of which my IntelliJ idea compalained that it requires legacy Jdk version of Java 6. The dilemma that I had was hwo am I going to mainain the different version of Java.\nHomeBrew as always came to my rescue. For those who are not sure what is HomeBrew and what it is used for should definitely install brew. With so many apps and softwares out there, one needs to maintain several versions of Java JDK as not all of them are compatible with all the versions of Java. The problem with that approach is that you may have downloaded all the versions of Java JDK but you have to tweak around the the bash profiles, set environment, JAVA_HOME settings etc., which is kind of a pain and error prone. This is where neat little tool called jEnv comes into picture. This tool allows you to change different java versions using a simple command. It will be familair to anyone who has used RVM. To read more about, see this post.\nSo Let’s begin by installing jEnv\nStep 1: Run this in the terminal\n brew install https://raw.github.com/gcuisinier/jenv/homebrew/jenv.rb\n Step 2: Add jEnv to the bash profile\n if which jenv \u0026gt; /dev/null; then eval \u0026quot;$(jenv init -)\u0026quot;; fi\n Step 3: When you first install jEnv will not have any JDK associated with it.\nFor example, I just installed JDK 8 but jEnv does not know about it. To check Java versions on jEnv\n  At the moment it only found Java version(jre) on the system. The ‘*’ shows the version currently selected. Unline rvm and rbenv, jEnv cannot install JDK for you. You need to install JDK manually from Oracle website.\nStep 4: Install JDK 6 from Apple website. This will install Java /System/Library/Java/JavaVirtualMachines/ . The reason we are installing Java 6 from Apple website is that SUN did not come up with JDK 6 for MAC, so Apple created/modified its own deployment version.\nStep 5: Similarly install JDK7 and JDK8.\nStep 6: Add JDKs to jEnv.\nJDK 6:\nJDK 7:\n  JDK 8:\n  Step 8: Check the java versions installed using jenv\n  Step 9: So now we have 3 versions of Java on our system. To set a default version use the command\n jenv local \u0026lt;jenv version\u0026gt;\n Ex – I wanted Jdk 1.6 to start IntelliJ\n jenv local oracle64-1.6.0.65\n Step 10: check the java version\n java -version\n That’s it. We now have multiple versions of java and we can switch between them easily. jEnv also has some other features, such as wrappers for Gradle, Ant, Maven, etc, and the ability to set JVM options globally or locally. Check out the documentation for more information.\n~~Ciao\n"
},
{
	"uri": "/2015/01/26/restful-webservice-7-steps-using-spring-boot/",
	"title": "Restful Webservice in 7 Steps using Spring boot",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "Last week I was working on a new application which required me to build a web service to access it’s functionality. I decided to check out Spring 4 RestController.\nI was amazed at how far we have come from writing all the boiler template code, xmls etc for making a restful call. With Spring4 boot, it was matter of adding simple annotation for RestController.\nI will be honest, I have not been up to date on how to use a Restful webservice, I built a couple of Restful service a couple of year ago, but most of the services in my current project are old school (SOAP calls), so I never got a chance to build one from scratch and at peace.\nPrerequisites: Read Carefully\n  Spring 4 requires you to use Maven 3 in fact it will force you to use Maven 3. This is very important point because it took me an hour to figure this out. If you try to use Maven 2, it will build and “might” compile but the code will complain that some of the RestController class methods are not found. This happens because by default, maven 2 will pull in Spring 2.5.x jar files.\n  Requires a minimum of JDK 6.\n  What are we building?\nWe will build a service that will accept HTTP GET request at: http://localhost:9000/welcome\nand respond with a JSON message:\n{\u0026quot;content\u0026quot;:\u0026quot;Hello Dinesh\u0026quot;}\nStep 1: Create a maven project using command line tools or your favorite IDE.\nStep 2: In the pom.xml add the following information\na) Parent:\nb) Add spring-boot dependency\nc) Add spring-boot plugin\nd) Add spring repositories\nWhy do we need Spring Boot Maven Plugin?\nYou might be wondering what happened to the good old maven build plugin. Well that plugin still works and will compile and build your project, but Spring-boot-maven-plugin searches for the public static void main() method to mark it as runnable class if you use the command “mvn:run”. Secondly, it comes with its own dependency resolver for the version number to match the Spring-boot-starter-web dependencies.\nStep 3: Create JSON Message POJO class\n src/main/java/dinesh/Welcome.java\n 1 2 3 4 5 6 7 8 9 10 11 12 13  package dinesh;\rpublic class Welcome {\rprivate final String content;\rpublic Greeting(String content) {\rthis.content = content;\r}\rpublic String getContent() {\rreturn content;\r}\r}\r  Note: Spring 4 Boot automatically uses Jackson JSON library to marshal instances of Welcome into JSONObjects.\nStep 4: Create a resource Controller\nAll Spring HTTP requests are handled by Spring controllers. For Restful services Spring 4 comes with a new annotation @RestController annotation. This will handle the requests which are posted to url /welcome by returning a new instance of Welcome class.\nsrc/main/java/dinesh/WelcomeController.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  package hello;\rimport org.springframework.web.bind.annotation.RequestMapping;\rimport org.springframework.web.bind.annotation.RequestParam;\rimport org.springframework.web.bind.annotation.RestController;\r@RestController\rpublic class WelcomeController {\rprivate static final String template = \u0026#34;Hello, %s!\u0026#34;;\r@RequestMapping(\u0026#34;/welcome\u0026#34;)\rpublic Welcome welcome(@RequestParam(value=\u0026#34;name\u0026#34;, defaultValue=\u0026#34;World\u0026#34;) String name) {\rreturn new Greeting(String.format(template, name));\r}\r}\r  If you look closely, you will know why I said Maven 2 will not work. Maven 2 will pull in RequestParm class from old Springmvc jar file which does not have method defined for defaultValue(). It is going cry out loud during compilation.\n@RestController – annotation marks the class as controller where every method returns a domain object instead of a view, which is major distinction between @Controller and @RestController which is a short hand for @Controller + @ResponseBody\nThe @RequestMapping annotation helps Spring to identify what method to invoke when some one accesses “/welcome” url.\nThe @RequestParam binds the value of parameter “name” into the name parameter of the welcome() method. If you do not pass any value in the query string then the default value is “world” – default value=”World”. If you do not add default value and forget to pass a “name=xx” in the query string, you will hear a loud cracking, lots of smokes, some curses and code will complain of NP exceptions :-).\nOne important thing that you notice is that we have not done anything to marshall request/response as JSONobject. The old of way of doing this would need you to use Jackson libraries and a lot of annotation to make them as JSON properties. Thanks to Spring 4, it takes of it using Jackson dependencies in the background.\nStep 5: Create an executable “jar” file. yes you read it right. Although you can create a war file, for smaller project like the one I build and the one for this example, I am not going to go through those steps. you cn check the Spring documentation on this topic. Just a high level view what is required is that you get right of the boot plugin, change the packaging tag in the pom.xml to war.Here’s a good post \n src/main/java/dinesh/Execute.java\n 1 2 3 4 5 6 7 8 9 10 11 12 13  package dinesh;\rimport org.springframework.boot.autoconfigure.EnableAutoConfiguration;\rimport org.springframework.boot.SpringApplication;\rimport org.springframework.context.annotation.ComponentScan;\r@ComponentScan(basePackages = \u0026#34;dinesh.*\u0026#34;)\r@EnableAutoConfiguration\rpublic class Execute {\rpublic static void main(String[] args) {\rSpringApplication.run(Execute.class, args);\r}\r}\r  @ComponentScan tells the app to check for @component annotation and it makes sure that Spring finds and registers WelcomeController, because it is marked as “@RestController” .\nStep 6: Build and run\nMethod 1 :\nRun ‘mvn clean install’ in the command line\nAfter the jaris built, run\n java -jar target/xxx.jar\n Method 2:\n Run spring-boot:run\n Spring 4 comes with built-in Tomcat 7, so you do not need a full-blown JEE application server to deploy and run your web service. Either of the method will fire up the application on port 8080.\nHow do I change port number?\njust run\n spring-boot:run -Dserver.port=9000\n Step 7: Test your service\nOnce the service is up, visit http://localhost:8080/welcome?name=your-name and you will get back a response\n1 2 3  {\rHello, your-name\r}\r  ~Ciao\n"
},
{
	"uri": "/2014/10/17/quick-tutorial-saaj-api/",
	"title": "A quick tutorial on SAAJ API",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "We ran into an issue last week. I had to call a third party web service that was built in PHP. Anyone who wokrs with Java will tell you that calling a web service is not more 15 minutes coding. You take the wsdl, run wsdl2Java command from Axis2 and start calling the service.\nLike I said before, things are never so straightforward. No matter what version of Axis or CXF we used, we kept getting this error:\n1 2 3 4 5 6 7 8 9 10 11 12 13  \u0026gt; Caused by: org.apache.axiom.soap.SOAPProcessingException: Transport level information does not match with SOAP Message namespace URI\r\u0026gt; at org.apache.axis2.builder.BuilderUtil.validateSOAPVersion(BuilderUtil.java:772)\r\u0026gt; at org.apache.axis2.builder.SOAPBuilder.processDocument(SOAPBuilder.java:58)\r\u0026gt; at org.apache.axis2.transport.TransportUtils.createDocumentElement(TransportUtils.java:179)\r\u0026gt; at org.apache.axis2.transport.TransportUtils.createSOAPMessage(TransportUtils.java:145)\r\u0026gt; at org.apache.axis2.transport.TransportUtils.createSOAPMessage(TransportUtils.java:108)\r\u0026gt; \u0026amp;#8230; 13 more\r  Now what this usually means is that client and server are using different version of SOAP(1.1 vs 1.2). For a long time my colleague tried to look for a solution on various forums, blogs etc. and everyone confirmed the same that the issue is at the service provider end. However, the same service was being used by 20 other vendors without an issue. Our Canada office reported that they were able to call the service without any issue albeit in PHP(OOPS!!).\nOne fine afternoon it just struck me that Axis, CXF etc. are nothing but a wrapper around Java’s SAAJ API. Imagine how did developers call services before Axis and CXF? They coded QNAME, SOAPMessage manually! Lo and Behold but I went down to … let’s call it low level programming because I had to write code for all the XML node element, define namespaces etc.. which was not fun at all.\nSo this tutorial will walk you through basics of SAAJ, how and when to use the SAAJ API.\nWHY DO I NEED SAAJ over AXIS2 or CXF?\nI so badly want to say that when you want to avoid the above error, use SAAJ :-). SAAJ is helpfule when you want complete control over SOAP elements. For example if you need to change name spaces or modify soap message attributes then SAAj comes in handy.\nA typical SOAP message looks like this\nAs you can see SAAJ provides SOAPMessage, SOAPHeader, SOAPBody classes to capture the message. When you create a new SOAPMessage object, it will automatically have the parts that are required to be in a SOAP message. In other words, a new SOAPMessage object has a SOAPPart object that contains a SOAPEnvelope object. The SOAPEnvelope object in turn automatically contains an empty SOAPHeader object followed by an empty SOAPBody object. If you do not need the SOAPHeader object, which is optional, you can delete it. The rationale for having it automatically included is that more often than not you will need it, so it is more convenient to have it provided. The SOAPHeader object may contain one or more headers with information about the sending and receiving parties. The SOAPBody object, which always follows the SOAPHeader object if there is one, provides a simple way to send information intended for the ultimate recipient. For example, if there is a SOAPFault object, it must be in the SOAPBody object.\nSo If have a service where I need the request SOAP Message should look like\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  \u0026gt; \u0026lt;soapenv:Envelope xmlns:soapenv=\u0026amp;#8221;http://schemas.xmlsoap.org/soap/envelope/\u0026amp;#8221; xmlns:urn=\u0026amp;#8221;urn:http://com.mycompany.IamDoingSomething\u0026amp;#8221;\u0026gt;\r\r\u0026gt; \u0026lt;soapenv:Header/\u0026gt;\r\u0026gt; \u0026lt;soapenv:Body\u0026gt;\r\u0026gt; \u0026lt;urn:getPresaleByAddress\u0026gt;\r\u0026gt; \u0026lt;stnum\u0026gt;123\r\u0026gt; \u0026lt;stnumsuff\u0026gt;\u0026lt;/stnumsuff\u0026gt;\r\u0026gt; \u0026lt;stnam\u0026gt;Forest\u0026lt;/stnam\u0026gt;\r\u0026gt; \u0026lt;sttyp\u0026gt;DR\u0026lt;/sttyp\u0026gt;\r\u0026gt; \u0026lt;stdir\u0026gt;\u0026lt;/stdir\u0026gt;\r\u0026gt; \u0026lt;loctypa\u0026gt;\u0026lt;/loctypa\u0026gt;\r\u0026gt; \u0026lt;locnuma\u0026gt;\u0026lt;/locnuma\u0026gt;\r\u0026gt; \u0026lt;loctypb\u0026gt;\u0026lt;/loctypb\u0026gt;\r\u0026gt; \u0026lt;locnumb\u0026gt;\u0026lt;/locnumb\u0026gt;\r\u0026gt; \u0026lt;muni\u0026gt;OTTAWA\u0026lt;/muni\u0026gt;\r\u0026gt; \u0026lt;post\u0026gt;K1A1A1\u0026lt;/post\u0026gt;\r\u0026gt; \u0026lt;prov\u0026gt;on\u0026lt;/prov\u0026gt;\r\u0026gt; \u0026lt;!--\u0026lt;span class=\u0026#34;hiddenSpellError\u0026#34; pre=\u0026#34;\u0026#34; data-mce-bogus=\u0026#34;1\u0026#34;--\u0026gt;urn:getPresaleByAddress\u0026gt;\r\u0026gt;\r\u0026gt;\r\u0026gt; \u0026lt;!--\u0026lt;span class=\u0026#34;hiddenSpellError\u0026#34; pre=\u0026#34;\u0026#34; data-mce-bogus=\u0026#34;1\u0026#34;--\u0026gt;soapenv:Body\u0026gt;\r\u0026gt;\r\u0026gt;\r\u0026gt; \u0026lt;!--\u0026lt;span class=\u0026#34;hiddenSpellError\u0026#34; pre=\u0026#34;\u0026#34; data-mce-bogus=\u0026#34;1\u0026#34;--\u0026gt;soapenv:Envelope\u0026gt;\r  and I need to send this message to web service url “http://some-webservice-url.com”\nSTEPS\n Create a SOAP Message  1 2 3 4  \u0026gt; MessageFactory factory = MessageFactory.newInstance();\r\u0026gt; SOAPMessage message = factory.createMessage();\r  Result:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026gt; xmlns:SOAP-ENV=\u0026amp;#8221;http://schemas.xmlsoap.org/soap/envelope/\u0026amp;#8221;\u0026gt;\r\u0026gt; \u0026lt;SOAP-ENV:Header/\u0026gt;\r\u0026gt; \u0026lt;SOAP-ENV:Body/\u0026gt;\r\u0026gt; \u0026lt;/SOAP-ENV:Envelope\u0026gt;\r2. Access Soap parts or message\r\u0026gt; SOAPHeader header = message.getSOAPHeader();\r\u0026gt; SOAPBody body = message.getSOAPBody();\r  Add Message Content  1 2 3 4 5 6 7  \u0026gt; SOAPBody body = message.getSOAPBody();\r\u0026gt;\r\u0026gt; SOAPFactory soapFactory = SOAPFactory.newInstance();\r\u0026gt; Name bodyName = soapFactory.createName(\u0026amp;#8220;getPresaleByAddress\u0026amp;#8221;,\u0026amp;#8221;urn\u0026amp;#8221;, \u0026amp;#8220;http://com.mycompany.IamDoingSomething\u0026amp;#8221;);\r\r\u0026gt; SOAPBodyElement bodyElement = body.addBodyElement(bodyName);\r  Result:\n1 2 3 4 5  \u0026gt; \u0026lt;urn:getPresaleByAddress\u0026gt;\r\u0026gt;\r\u0026gt; \u0026amp;#8230;\r\u0026gt;\r\u0026gt; \u0026lt;!--\u0026lt;span class=\u0026#34;hiddenSpellError\u0026#34; pre=\u0026#34;\u0026#34; data-mce-bogus=\u0026#34;1\u0026#34;--\u0026gt;urn:getPresaleByAddress\u0026gt;\r  Add Message Headers namespaces if Any  1 2 3 4 5 6 7 8 9 10 11 12  \u0026gt; MimeHeaders headers = soapMessage.getMimeHeaders();\r\u0026gt; headers.addHeader(\u0026amp;#8220;SOAPAction\u0026amp;#8221;, leonidUrl+ \u0026amp;#8220;/getPresaleByAddress\u0026amp;#8221;);\r\u0026gt; SOAPPart soapPart = soapMessage.getSOAPPart();\r\u0026gt; // SOAP Envelope\r\r\u0026gt; SOAPEnvelope envelope = soapPart.getEnvelope();\r\u0026gt; envelope.addNamespaceDeclaration(\u0026amp;#8220;urn\u0026amp;#8221;, \u0026amp;#8220;urn:http://com.mycompany.IamDoingSomething\u0026amp;#8221;);\r\r  Add Basic Authentication if any  1 2 3  \u0026gt; String authorization = new sun.misc.BASE64Encoder().encode((\u0026amp;#8220;myUserName\u0026amp;#8221;+\u0026amp;#8221;:\u0026amp;#8221;+\u0026amp;#8221;myPassword\u0026amp;#8221;).getBytes());\r\u0026gt; headers.addHeader(\u0026amp;#8220;Authorization\u0026amp;#8221;, \u0026amp;#8220;Basic \u0026amp;#8221; + authorization);\r  Add child elements  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  \u0026gt; QName bodyName = new QName(\u0026amp;#8220;urn:http://com.mycompany.IamDoingSomething\u0026amp;#8221;,\u0026amp;#8221;getPresaleByAddress\u0026amp;#8221;,\u0026amp;#8221;urn\u0026amp;#8221;) ;\r\r\u0026gt; SOAPBodyElement bodyElement = body.addBodyElement(bodyName);\r\u0026gt; QName node_name = new QName(qName);\r\u0026gt; SOAPElement node_element = null;\r\u0026gt; try {\r\u0026gt; node_element = bodyElement.addChildElement(\u0026amp;#8220;stnum\u0026amp;#8221;);\r\u0026gt; if(hasNodeValue){\r\u0026gt; node_element.addTextNode(\u0026amp;#8220;123\u0026amp;#8221;);\r\u0026gt; }\r\u0026gt; }\r  Result:\n1  \u0026gt; \u0026lt;stnum\u0026gt;123\u0026lt;/stnum\u0026gt;\r  Get a Soap Connection Object  1 2 3 4  \u0026gt; SOAPConnectionFactory soapConnectionFactory = SOAPConnectionFactory.newInstance();\r\u0026gt; SOAPConnection connection = soapConnectionFactory.createConnection();\r\u0026gt;\r  SOAP messages are sent and received over a connection. This connection is represented by a SOAPConnection object, which goes from the sender directly to its destination. This kind of connection is called a point-to-point connection because it goes from one endpoint to another endpoint. Messages sent using the SAAJ API are called request-response messages. They are sent over a SOAPConnection object with the method call, which sends a message (a request) and then blocks until it receives the reply (a response).\nSend the message  1 2 3 4 5 6 7  \u0026gt; // Create an endpoint point which is either URL or String type\r\r\u0026gt; java.net.URL endpoint = new URL(\u0026amp;#8220;http://some-webservice-url.com\u0026amp;#8221;);\r\u0026gt;\r\u0026gt; // Send a SOAPMessage (request) and then wait for SOAPMessage (response)\r\r\u0026gt; SOAPMessage response = connection.call(message, endpoint);\r  Print the SOAP Response XML  1 2 3 4 5 6 7 8 9 10 11  \u0026gt; Transformer transformer = transformerFactory.newTransformer();\r\u0026gt; Source sourceContent = response.getSOAPPart().getContent();\r\u0026gt; ByteArrayOutputStream outputStream = new ByteArrayOutputStream();\r\u0026gt; StreamResult result = new StreamResult(outputStream);\r\u0026gt; transformer.transform(sourceContent, result);\r\u0026gt; log.info(\u0026amp;#8220;nResponse SOAP Message ::n {}\u0026amp;#8221; , result.getOutputStream().toString());\r  That’s it!!\nThere are many other things that you can do with SAAJ. To read more about SAAJ and it’s capabilities you can read here and here\n~Ciao\n"
},
{
	"uri": "/2014/04/18/apache-poi-tutorial-reading-writing-excel-files-java/",
	"title": "Read / Write Excel file in Java using Apache POI",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "About a year or two ago I was working with finance team where they wanted to pull the credit card transactions for all the customer using various combinations. Ex –\n– Get the credit card txns for today or certain date.\n– Get the txns for customer who used Mastercard or Visa.\nHowever they wanted this application to generate a Excel file and save it on their local machine so that they could prepare reports for our CEO. I used a Apache POI project to create jar files. This tutorial will walk you through the process of reading and writing excel sheet. So let’s see – How to read and write excel files in Java?\nBrief History on Apache POI\nApache POI is a powerful Java library to work with different Microsoft Office file formats such as Excel, Power point, Visio, MS Word etc. The name POI was originally an acronym for Poor Obfuscation Implementation, referring humorously to the file formats that seemed deliberately obfuscated, but poorly, since they were successfully reverse-engineered. In short, you can read / write MS Excel files using Java. In addition, you can read/write MS Word and MS PowerPoint files using Java. Apache POI is your Java Excel solution .\nApache POI can be used to create both old ( 2003-2008) and new( 2010 – newer) format. I think the newer jar file to create XLSX document is out of BETA phase now. Back when I used this POI it was still in Beta format.\nSo let’s see what does it entails to read /write Excel files in Java.\nI am will be using Maven and IntelliJ to create my project, however you are welcome to use Eclipse or Netbeans.\nApache POI dependencies\nThere are two different maven dependencies one for creating an older version of excel – XLS format and other for creating new version of Excel – XLSX format. I am listing both the dependencies here.\n \r  \u0026lt;!– For Excel 2007 –\u0026gt;\n  \r  org.apache.poi\n  poi\n  3.9\n  \r  \r  org.apache.poi\n  poi-ooxml\n  3.9\n  \r  \r Create a new module in IntelliJ.\nAdd the dependency in your pom.xml\nPAUSE \u0026amp; THINK: KEY POI CLASSES\nBefore we go ahead here’s quick primer on 3 key classes in POI.\n HSSF – Java implementation of the Excel ’97(-2007) file format. e.g. HSSFWorkbook, HSSFSheet. XSSF – Java implementation of the Excel 2007 OOXML (.xlsx) file format. e.g. XSSFWorkbook, XSSFSheet. SXSSF – Used when very large spreadsheets have to be produced, and heap space is limited. e.g. SXSSFWorkbook, SXSSFSheet.  There are other wide range of classes as well which can be used to manipulate the Excel sheet.\nEx – BuiltinFormats, ConditionalFormattingRule,ComparisonOperator,CellStyle, FontFormatting\n, IndexedColors, PatternFormatting, SheetConditionalFormatting. These used for formatting the sheet and formula evaluation.\nHOW TO CREATE A NEW EXCEL SHEET\nThis involves the following steps.\nSo go ahead and create a new file called NewExcel.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66  package com.dinesh;\rimport org.apache.poi.ss.usermodel.Cell;\rimport org.apache.poi.ss.usermodel.Row;\rimport org.apache.poi.xssf.usermodel.XSSFSheet;\rimport org.apache.poi.xssf.usermodel.XSSFWorkbook;\rimport java.io.File;\rimport java.io.FileNotFoundException;\rimport java.io.FileOutputStream;\rimport java.io.IOException;\rimport java.util.HashMap;\rimport java.util.Map;\rimport java.util.Set;\rimport java.util.TreeMap;\r/**\r* Created by darora on 4/18/14.\r*/\rpublic class NewExcel {\rpublic static void main(String[] args) {\r//Create a new Workbook\r XSSFWorkbook workbook = new XSSFWorkbook();\r//Create a blank sheet\r XSSFSheet sheet = workbook.createSheet(\u0026#34;Student data\u0026#34;);\r//Create the data for the excel sheet\r Map\u0026amp;lt;string, object[]=\u0026#34;\u0026#34;\u0026amp;gt; data = new TreeMap\u0026amp;lt;string, object[]=\u0026#34;\u0026#34;\u0026amp;gt;();\rdata.put(\u0026#34;1\u0026#34;, new Object[] {\u0026#34;ID\u0026#34;, \u0026#34;FIRSTNAME\u0026#34;, \u0026#34;LASTNAME\u0026#34;});\rdata.put(\u0026#34;2\u0026#34;, new Object[] {1, \u0026#34;Randy\u0026#34;, \u0026#34;Maven\u0026#34;});\rdata.put(\u0026#34;3\u0026#34;, new Object[] {2, \u0026#34;Raymond\u0026#34;, \u0026#34;Smith\u0026#34;});\rdata.put(\u0026#34;4\u0026#34;, new Object[] {3, \u0026#34;Dinesh\u0026#34;, \u0026#34;Arora\u0026#34;});\rdata.put(\u0026#34;5\u0026#34;, new Object[] {4, \u0026#34;Barbra\u0026#34;, \u0026#34;Klien\u0026#34;});\r//Iterate over data and write it to the sheet\r Set keyset = data.keySet();\rint rownum = 0;\rfor (String key : keyset)\r{\rRow row = sheet.createRow(rownum++);\rObject [] objArr = data.get(key);\rint cellnum = 0;\rfor (Object obj : objArr)\r{\rCell cell = row.createCell(cellnum++);\rif(obj instanceof String)\rcell.setCellValue((String)obj);\relse if(obj instanceof Integer)\rcell.setCellValue((Integer)obj);\r}\r}\r//Save the excel sheet\r try{\rFileOutputStream out = new FileOutputStream( new File(\u0026#34;c:\\Dinesh\\javahabitExcelDemo.xlsx\u0026#34;));\rworkbook.write(out);\rout.close();\rSystem.out.println(\u0026#34;javahabitExcelDemo.xlsx Successfully created\u0026#34;);\r} catch (FileNotFoundException e) {\re.printStackTrace();\r} catch (IOException e) {\re.printStackTrace();\r}\r}\r}\r  OUTPUT\nHOW TO READ A NEW EXCEL SHEET\nSo now that we have written an excel sheet. let’s try to read it back.\nThe steps involved are\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57  package com.dinesh;\rimport org.apache.poi.ss.usermodel.Cell;\rimport org.apache.poi.ss.usermodel.Row;\rimport org.apache.poi.xssf.usermodel.XSSFSheet;\rimport org.apache.poi.xssf.usermodel.XSSFWorkbook;\rimport java.io.File;\rimport java.io.FileInputStream;\rimport java.io.FileNotFoundException;\rimport java.io.IOException;\rimport java.util.Iterator;\r/**\r* Created by darora on 4/18/14.\r*/\rpublic class ReadExcel {\r//Create Workbook instance from excel sheet\r public static void main(String[] args) {\rtry {\r//Get the Excel File\r FileInputStream file = new FileInputStream(\rnew File(\u0026#34;c:\\Dinesh\\javahabitExcelDemo.xlsx\u0026#34;));\rXSSFWorkbook workbook = new XSSFWorkbook(file);\r//Get the Desired sheet\r XSSFSheet sheet = workbook.getSheetAt(0);\r//Increment over rows\r for (Row row : sheet) {\r//Iterate and get the cells from the row\r Iterator cellIterator = row.cellIterator();\r// Loop till you read all the data\r while (cellIterator.hasNext()) {\rCell cell = cellIterator.next();\rswitch (cell.getCellType()) {\rcase Cell.CELL_TYPE_NUMERIC:\rSystem.out.print(cell.getNumericCellValue() + \u0026#34;t\u0026#34;);\rbreak;\rcase Cell.CELL_TYPE_STRING:\rSystem.out.print(cell.getStringCellValue() + \u0026#34;t\u0026#34;);\rbreak;\r}\r}\rSystem.out.println(\u0026#34;\u0026#34;);\r}\rfile.close();\r} catch (FileNotFoundException e) {\re.printStackTrace();\r} catch (IOException e) {\re.printStackTrace();\r}\r}\r}\r  OUTPUT\nUsing formulas in excel sheet When working on excel sheets, we sometimes have to create cells which use formulas to calculate their values. Apache POI has supports methods for adding formula to cells and evaluating the already present formula in the cells. Neat!!\nSo Let’s see an example on setting a formula cells in the excel sheet.\nIn this code we will try to calculate the Simple interest. Formula – Principal * Interest * Time.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  package com.dinesh;\rimport org.apache.poi.ss.usermodel.Row;\rimport org.apache.poi.xssf.usermodel.XSSFSheet;\rimport org.apache.poi.xssf.usermodel.XSSFWorkbook;\rimport java.io.File;\rimport java.io.FileNotFoundException;\rimport java.io.FileOutputStream;\rimport java.io.IOException;\r/**\r* Created by darora on 4/18/14.\r*/\rpublic class CalculateFormula {\rpublic static void main(String[] args)\r{\r//Create the workbook\r XSSFWorkbook workbook = new XSSFWorkbook();\r//Create the sheet\r XSSFSheet sheet = workbook.createSheet(\u0026#34;Calculate Simple Interest\u0026#34;);\r//Create Wor Headers\r Row header = sheet.createRow(0);\rheader.createCell(0).setCellValue(\u0026#34;Principal\u0026#34;);\rheader.createCell(1).setCellValue(\u0026#34;Interest\u0026#34;);\rheader.createCell(2).setCellValue(\u0026#34;Time\u0026#34;);\rheader.createCell(3).setCellValue(\u0026#34;OUTPUT (P * r * t)\u0026#34;);\r//Create the Rows\r Row dataRow = sheet.createRow(1);\rdataRow.createCell(0).setCellValue(1000d);\rdataRow.createCell(1).setCellValue(12.00);\rdataRow.createCell(2).setCellValue(6d);\rdataRow.createCell(3).setCellFormula(\u0026#34;A2*B2*C2\u0026#34;);\r//Save the File\r try {\rFileOutputStream out = new FileOutputStream( new File(\u0026#34;c:\\Dinesh\\javahabitformulaDemo.xlsx\u0026#34;));\rworkbook.write(out);\rout.close();\rSystem.out.println(\u0026#34;Excel File with formla is created!\u0026#34;);\r} catch (FileNotFoundException e) {\re.printStackTrace();\r} catch (IOException e) {\re.printStackTrace();\r}\r}\r}\r  OUTPUT\nSo experiment your way with this jar file and do post your comments and suggestions on topics you had like to see in my future posts.\n~ Ciao\n–\n"
},
{
	"uri": "/2014/03/16/13-common-java-keytool-keystore-commands/",
	"title": "13 Most Common Java Keytool Keystore Commands",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "I was working on a project last month where I had to call a third-party web service. The third-party web service wanted me to add a SSL keystore and I struggled. I could have gone to my UNIX Admin and asked him to do this job but decided to learn about all about keystores. I went through couple of forums and SO and ended my spending 2 – 3 hours reading about keystores and commonly used commands.\nTo give you a quick run here what I was doing. I had to use a third party wsdl to create a client. I tried to use Maven jaxws plugin to generate the client. I downloaded the wsdl to my local machine and was able to successfully create a client. For production I wanted to generate the client using the current wsdl so decided to generate the client using the wsdl url of the third-party website but ran into keystore issue. I had to download their certificate and add it to my CACERT.\nThe whole charade led me to compile this post. Before I begin here is a quick run through Keystore\nWhy Do I need a keystore?\nBy using a public/private key mechanism. This provides a layer of security that prevents, among other things, remote attackers from pushing malicious updates to your application (all updates must be signed with the same key)\nWhat is a Java Keytool?\nIt is a key and certificate management utility. It allows users to manage their own public/private key pairs and certificates. It also allows users to cache certificates. Java Keytool stores the keys and certificates in keystore. It protects private keys with a password. A Keytool keystore has the private key and any certificates necessary to complete a chain of trust and set up the trustworthiness of the primary certificate.\n_Each certificate in a Java keystore is associated with a unique alias. When creating a Java keystore you will first create the .jks file that will initially only contain the private key. You will then generate a CSR and have a certificate generated from it. Then you will import the certificate to the keystore including any root certificates. _\nHere is a list of 13 most common commands CREATING AND IMPORTING COMMANDS 1. Create a Java Keystore and value pair\n keytool -genkey -alias yourDomainName -keyalg RSA -keystore YourkeystoreName.jks \n 2. Creating a signing request (CSR) for an existing keystore\n keytool -certreq -alias yourDomainName -keystore keystore.jks -file yourDomainName.csr\n 3. Importing a signed primary certificate to an existing keystore**\n**\n keytool -import -trustcacerts -alias yourDomainName -file yourDomainName.crt -keystore YourkeystoreName.jks\n 4. Importing a root or intermediate CA certificate to an existing keystore\n keytool -import -trustcacerts -alias root -file Thawte.crt -keystore YourkeystoreName.jks\n 5. Creating a keystore and self-signed certificate\n keytool -genkey -keyalg RSA -alias selfsigned -keystore Yourkeystore.jks -storepass password -validity 360\n CHECKING COMMANDS When you need to check the information about a certificate or keystore then you use these commands.\n6. Checking a particular certificate\n keytool -printcert -v -file Yourdomain.crt\n 7. Checking all certificates in a keystore\n keytool -list -v -keystore Yourkeystore.jks\n 9. Checking a particular keystore entry using an alias\n keytool -list -v -keystore Yourkeystore.jks -alias Yourdomain\n EDIT/IMPORT COMMANDS 10. Deleting a certificate from a keystore\n keytool -delete -alias Yourdomain -keystore Yourkeystore.jks\n 11. Changing a keystore password\n keytool -storepasswd -new new_password -keystore keystore.jks\n 12. Exporting a certificate from a keystore\n keytool -export -alias Yourdomain -file Yourdomain.crt -keystore Yourkeystore.jks\n 13. Listing Trusted CA Certs\n keytool -list -v -keystore $JAVA_HOME/jre/lib/security/cacerts\n  P.S. – If you liked the post please click on one of the ads in the right hand column to help me keep up this site and do drop a me a line to suggest some topics that would like to see on this site.\n So Long ……\n"
},
{
	"uri": "/2014/01/31/10-intellij-idea-keyboard-shortcuts-must-know/",
	"title": "10 IntelliJ IDEA Keyboard Shortcuts That You Must Know",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "Linux nerds/geeks happily flaunt their keyboard skills when they get a chance. I admit that I am not a shortcut junky but I too have some keyboard shortcuts under my sleeve that I use in day to day work. I have to say that not only have these shortcuts increased my productivity but they have also made my life a lot easier.\nI am sharing my 10 most used shortcuts at work.\n1. Comment or Un-Comment: CTRL + L\nYou will often run into situation where you need to add debug statement temporarily and remove or comment the line after the debug is complete. Instead of manually going to the beginning of the line and manually typing //, you can use the keyboard shortcut CTRL + L. A cool thing to know is that you can comment out multiple lines at once. 2. Documentation Comment Block : / + Enter**\nI may not follow other coding standard but I do follow this – “Leave the place cleaner before you leave”. One of my biggest pet peeves is developers not documenting about a method or sub routine. What are you conveying or trying to do in a particular method? I hate when I come across such code or even my code when I was beginner. So if commenting single line was not cool enough for you then you can use this to create documentation comments or comment out the code without ugly // marks showing at each line. To compare the difference, I have commented the same code using **CTRL+L and / + Enter VS\n3. Delete Line : CTRL + Y\nThis one is easy. If you have any vim experience or have used sublime text in the past then this would come easy. Simply place the cursor on the beginning of the line and hit CTRL + Y. Now it might not seem intuitive because the obvious choice of deleting should have been CTRL **+ D **(It actually adds a new line if you wondered what it does) but a cool way to remember is to think about confirmation dialog boxes in Unix. For example – Are you sure you want to delete this folder? (Y/N)\n4. Argument Documentation For Method Calls: CTRL + P\nThis one is a true life saver. Imagine you are about to call method which accepts 10 parameters. You start by typing – MyClass.someMethodWith10Params(.., ..,) and you forget what was the third parameter that I need to pass. One ugly way of doing is use your mouse and place the cursor at the beginning of the open bracket and wait for a second until the highlight shows you that the third parameter that you need to pass is a String variable. However if you are like me who forgets the fourth and then next parameters, you would be pulling your hair out. Here comes your knight in the shining armor – **CTRL+P. **This will tell pull up a callout with the information you need.\n5. Continuous Code Selection: CTRL + W\nRaise your hand if you never had to copy paste the code. Any one? This shortcut lets you select a word, block or comment without touching your mouse. When you press **CTRL+W **it will select the code next to the cursor and will continue to select intelligently. When I say intelligently I really mean it. Say you place your cursor in the middle of the code block and hit the key combination it will copy code from opening braces to closing braces and so on. Here’s a sample.\n6. Paste from history: CTRL + V + Shift\nA lot of time I copy and paste code. Sometimes I open multiple projects and files and copy paste code from one project file to another project file. Occasionally I have to use a copy of code which I copied two steps behind and in that case I would think hard what file did I copy it from. Well I found this cool shortcut that saves me all the trouble to recall the file name and line numbers. Usually one uses CTRL + V to paste, but if you use CTRL + V + Shift then IDEA will show the last five copies that you can choose from to paste.\n7. Last Changed files: CTRL + SHIFT + E\nI used SVN at work and git or Bazaar for my personal project. At times when I am not using either it can be hard to track and remember what files did I change in last 1-2 hours. Usually if you are using SVN then you can see uncommitted files to figure out the file changes. However how do you track the files that changed in the last one hour if you are not using SVN or git or mercurial tools. It turns out that IntelliJ keeps a track of your recent file changes. You can just use the shortcut CTRL + SHIFT + E to see the last edited files.\n8. File Structure popup: CTRL + F12\nThis shortcut comes in handy if you are traversing through a huge file looking for a particular method name. You can either do CTRL + F to search for the method name. But at times you may not remember the name of the method or are not sure what methods or members are present in that file. In that case you use this shortcut.\n9. Evaluate Expression : ALT + F8\nThis is one feature that comes in handy in the debug mode. This features allows you to quickly test the output of an expression. For ex – Say I have a method that accepts a number from user and adds 2. When you are in debug mode and need to test a program that is already running need to figure out what would happen if I add 290.756 instead of adding 2, then you would normally have to make code a change or rerun the program. Some IDEs let you do hot deploy while some do not also in a large project this restart and change may take up long time to test one expression. This is when you can use this shortcut to quickly test different expressions without restarting or making a code change. 10. System.out.println() : sout + tab\nI kept the easiest and most used shortcut as the last piece. This is not really a shortcut but when I was looking for a way to avoid typing this verbose piece of code, I was surprised to see that many people did not know this fact. Unlike Netbeans or Eclipse where you can specify shortcut for commonly used text, I could not find this option in IntelliJ until I found the solution in SO. Just type **sout **and hit TAB to print out the complete text. ~Ciao … Enjoy the shortcuts and more.\n P.S. – If you liked the post please click on one of the ads in the right hand column to help me maintain this site and do drop a me a line to suggest some topics that would like to see on this site.\n "
},
{
	"uri": "/about-me/",
	"title": "About Me",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "Still to come\n"
},
{
	"uri": "/2013/12/16/apache-camel-how-to-call-an-external-webservice/",
	"title": "Apache Camel : How to call  java webservice",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "I have made up my mind to get rid of WSO2 ESB at my office. It is clumsy, buggy, hard to test, no body wants to work on it and the documentation is horrible. I looked at various alternative and Apache Camel was free and easy to set up and work with me.\nTo cut the story short, I was able to run most of the example but was struggling with CXF to call a third party service hosted at a random url. The documentation on the website is focused on exposing web service built in Camel. I was finally able to figure this out with a couple of slide show on slideshare.\nHere\u0026rsquo;s the scenario: I have a third party webservice hosted on the web which gives you the the conversion rate between two currencies. I am going to call this web service and log the response.\nAs usual I will start from scratch. My webservice is hosted at this url -http://www.webservicex.net/CurrencyConvertor.asmx?WSDL. This webservice exposes a operation called - “ConversionRate\u0026rdquo;.\nI am using Fuse Ide(free - Developer version) but you can use Intellij Or Eclipse.\nPrerequisites - Must have Maven.\nStep 1: Create a new Camel-Spring project.\nStep 2: Add the following dependencies in your pom.xml. “camel-cxf\u0026rdquo;\n1 2 3 4 5 6 7 8 9  \u0026lt;scope\u0026gt;\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.apache.camel\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;camel-cxf\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.10.0.redhat-60024\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\u0026lt;/scope\u0026gt;\r  My pom.xml looks like this -\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266  \u0026lt;!-?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt;\rxmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\u0026#34;\u0026gt;\r\u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt;\r\u0026lt;groupId\u0026gt;com.mycompany\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;camel-spring\u0026lt;/artifactId\u0026gt;\r\u0026lt;packaging\u0026gt;jar\u0026lt;/packaging\u0026gt;\r\u0026lt;version\u0026gt;1.0.0-SNAPSHOT\u0026lt;/version\u0026gt;\r\u0026lt;name\u0026gt;A Camel Spring Route\u0026lt;/name\u0026gt;\r\u0026lt;url\u0026gt;http://www.myorganization.org\u0026lt;/url\u0026gt;\r\u0026lt;properties\u0026gt;\r\u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt;\r\u0026lt;project.reporting.outputEncoding\u0026gt;UTF-8\u0026lt;/project.reporting.outputEncoding\u0026gt;\r\u0026lt;/properties\u0026gt;\r\u0026lt;repositories\u0026gt;\r\u0026lt;repository\u0026gt;\r\u0026lt;id\u0026gt;release.fusesource.org\u0026lt;/id\u0026gt;\rFuseSource Release Repository\r\u0026lt;url\u0026gt;http://repo.fusesource.com/nexus/content/repositories/releases\u0026lt;/url\u0026gt;\r\u0026lt;snapshots\u0026gt;\r\u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt;\r\u0026lt;/snapshots\u0026gt;\r\u0026lt;releases\u0026gt;\r\u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt;\r\u0026lt;/releases\u0026gt;\r\u0026lt;/repository\u0026gt;\r\u0026lt;repository\u0026gt;\r\u0026lt;id\u0026gt;snapshot.fusesource.org\u0026lt;/id\u0026gt;\rFuseSource Snapshot Repository\r\u0026lt;url\u0026gt;http://repo.fusesource.com/nexus/content/repositories/snapshots\u0026lt;/url\u0026gt;\r\u0026lt;snapshots\u0026gt;\r\u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt;\r\u0026lt;/snapshots\u0026gt;\r\u0026lt;releases\u0026gt;\r\u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt;\r\u0026lt;/releases\u0026gt;\r\u0026lt;/repository\u0026gt;\r\u0026lt;/repositories\u0026gt;\r\u0026lt;pluginRepositories\u0026gt;\r\u0026lt;pluginRepository\u0026gt;\r\u0026lt;id\u0026gt;release.fusesource.org\u0026lt;/id\u0026gt;\rFuseSource Release Repository\r\u0026lt;url\u0026gt;http://repo.fusesource.com/nexus/content/repositories/releases\u0026lt;/url\u0026gt;\r\u0026lt;snapshots\u0026gt;\r\u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt;\r\u0026lt;/snapshots\u0026gt;\r\u0026lt;releases\u0026gt;\r\u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt;\r\u0026lt;/releases\u0026gt;\r\u0026lt;/pluginRepository\u0026gt;\r\u0026lt;pluginRepository\u0026gt;\r\u0026lt;id\u0026gt;snapshot.fusesource.org\u0026lt;/id\u0026gt;\rFuseSource Snapshot Repository\r\u0026lt;url\u0026gt;http://repo.fusesource.com/nexus/content/repositories/snapshots\u0026lt;/url\u0026gt;\r\u0026lt;snapshots\u0026gt;\r\u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt;\r\u0026lt;/snapshots\u0026gt;\r\u0026lt;releases\u0026gt;\r\u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt;\r\u0026lt;/releases\u0026gt;\r\u0026lt;/pluginRepository\u0026gt; \u0026lt;/pluginRepositories\u0026gt;\r\u0026lt;dependencies\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.apache.camel\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;camel-core\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.10.0.redhat-60024\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.apache.camel\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;camel-spring\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.10.0.redhat-60024\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;!- logging -\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;slf4j-api\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;1.6.6\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;slf4j-log4j12\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;1.6.6\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;log4j\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;log4j\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;1.2.17\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;!- testing -\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.apache.camel\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;camel-test-spring\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.10.0.redhat-60024\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.apache.camel\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;camel-cxf\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.10.0.redhat-60024\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;/dependencies\u0026gt;\r\u0026lt;build\u0026gt;\r\u0026lt;defaultGoal\u0026gt;install\u0026lt;/defaultGoal\u0026gt;\r\u0026lt;plugins\u0026gt;\r\u0026lt;plugin\u0026gt;\r\u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.5.1\u0026lt;/version\u0026gt;\r\u0026lt;configuration\u0026gt;\r\u0026lt;source\u0026gt;1.6\u0026lt;/source\u0026gt;\r\u0026lt;target\u0026gt;1.6\u0026lt;/target\u0026gt;\r\u0026lt;/configuration\u0026gt;\r\u0026lt;/plugin\u0026gt;\r\u0026lt;plugin\u0026gt;\r\u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;maven-resources-plugin\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.4.3\u0026lt;/version\u0026gt;\r\u0026lt;configuration\u0026gt;\r\u0026lt;encoding\u0026gt;UTF-8\u0026lt;/encoding\u0026gt;\r\u0026lt;/configuration\u0026gt;\r\u0026lt;/plugin\u0026gt;\r\u0026lt;!- allows the route to be ran via mvn camel:run -\u0026gt;\r\u0026lt;plugin\u0026gt;\r\u0026lt;groupId\u0026gt;org.apache.camel\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;camel-maven-plugin\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.10.0.redhat-60024\u0026lt;/version\u0026gt;\r\u0026lt;/plugin\u0026gt;\r\u0026lt;/plugins\u0026gt;\r\u0026lt;/build\u0026gt;\r\u0026lt;/project\u0026gt;\r  Step 2: Under src/main.resources/META-INF folder(if not there then create one) create file called camel-context.xml Your camel file should like this -\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt;\rxmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34;\rxmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34;\rxmlns:cxf=\u0026#34;http://camel.apache.org/schema/cxf\u0026#34;\rxsi:schemaLocation=\u0026#34;\rhttp://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\rhttp://camel.apache.org/schema/cxf http://camel.apache.org/schema/cxf/camel-cxf.xsd\rhttp://camel.apache.org/schema/spring http://camel.apache.org/schema/spring/camel-spring.xsd\u0026#34;\u0026gt;\r\u0026lt;cxf:\u0026lt;span class=\u0026#34;hiddenSpellError\u0026#34;\u0026gt;cxfEndpoint id=\u0026#34;wsdlEndpoint\u0026#34;\raddress=\u0026#34;http://www.webservicex.net/CurrencyConvertor.asmx\u0026#34;\rendpointName=\u0026#34;c:SOAPOverHTTP\u0026#34;\rserviceName=\u0026#34;c:CurrencyConvertor\u0026#34;\rxmlns:s=\u0026#34;http://www.webserviceX.NET\u0026#34;/\u0026gt;\r\u0026lt;camelContext xmlns=\u0026#34;http://camel.apache.org/schema/spring\u0026#34;\u0026gt;\r\u0026lt;route\u0026gt;\rhere is a sample which processes the input files\r(leaving them in place - see the \u0026amp;#8216;noop\u0026#39; flag)\rthen performs content based routing on the message using XPath\u0026lt;/description\u0026gt;\rsrc/data/order?noop=true\u0026#34;/\u0026gt;\r\u0026lt;log message=\u0026#34;${body}\u0026#34;/\u0026gt;\rwsdl\u0026amp;serviceName={http://www.webserviceX.NET/}CurrencyConvertor\u0026amp;portName={http://www.webserviceX.NET/}CurrencyConvertorSoap\u0026amp;dataFormat=MESSAGE\u0026#34;/\u0026gt;\r\u0026lt;log message=\u0026#34;${body}\u0026#34;/\u0026gt;\r\u0026lt;/route\u0026gt;\r\u0026lt;/camelContext\u0026gt;\r\u0026lt;/beans\u0026gt;\r  Step 4: Place the payload or input data xml in src/data/input/order.xml. The order.xml should like this -\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  \u0026lt;soapenv:Envelope xmlns:soapenv=\u0026#34;http://schemas.xmlsoap.org/soap/envelope/\u0026#34; xmlns:web=\u0026#34;http://www.webserviceX.NET/\u0026#34;\u0026gt;\r\u0026lt;soapenv:Header/\u0026gt;\r\u0026lt;soapenv:Body\u0026gt;\r\u0026lt;web:ConversionRate\u0026gt;\r\u0026lt;web:FromCurrency\u0026gt;AUD\u0026lt;/web:FromCurrency\u0026gt;\r\u0026lt;web:ToCurrency\u0026gt;USD\u0026lt;/web:ToCurrency\u0026gt;\r\u0026lt;/web:ConversionRate\u0026gt;\r\u0026lt;!-\u0026lt;span class=\u0026#34;hiddenSpellError\u0026#34;\u0026gt;soapenv:Body\u0026gt;-\u0026gt;\r\u0026lt;/soapenv:Envelope\u0026gt;\r  That\u0026rsquo;s it!!!!\nThe interesting part is all in the camel-context.xml. Here\u0026rsquo;s what is happening in this file\n src/data/order?noop=true\u0026rdquo;/\u0026gt;\n This line reads the file order.xml. The option noop=true makes the file to be read again and again. By default this values is false. If this value is false, then after one read, camel marks it as read and when you run the example for second time, it will not read this file.\n  This line will simply log the contents of order.xml.\n serviceName={http://www.webserviceX.NET/}CurrencyConvertor\u0026amp;portName={http://www.webserviceX.NET/}CurrencyConvertorSoap\u0026amp;dataFormat=MESSAGE\u0026rdquo;/\u0026gt;\n This line tells cxf component that it needs to call the webservice -  http://www.webservicex.net/CurrencyConvertor.asmx?wsdl\n -URL - is the url of the wsdl  http://www.webservicex.net/CurrencyConvertor.asmx?wsdl\n  serviceName - is the name of the service. Remember it is the name of teh service not the oepration!! The value between {} is the namespace. If you do not want to write {http://….} then add another tag_xmlns \u0026gt; {http://www.webserviceX.NET/}CurrencyConvertor. portName - is the name of the port.\n  portName={http://www.webserviceX.NET/}CurrencyConvertorSoap. This is again preceded by {http://…} which is the namespace value. This value is defined in the wsdl as -wsdl:port name=\u0026quot;CurrencyConvertorSoap\u0026quot; binding=\u0026quot;tns:CurrencyConvertorSoap\u0026quot;\n The last piece is dataFormat - dataFormat=MESSAGE This tells that the body is of type message.\nPart 2 - In production you would want to avoid writing cxf in the above format as it is prone to error because the string value is very long and difficult to test independently and cannot be reused if you want to call the service in another route. So the best way is to define this as cxf endpoint. All you need to do is slightly modify the camel-context.xml\n Add this(be sure to remove the earlier version of \u0026lt;to uri=\u0026quot;cxf….\u0026quot;)     Define the cxf endpoint called wsdlEndpoint (You call it whatever you want).  1 2 3 4 5 6 7 8 9  \u0026lt;cxf:\u0026lt;span class=\u0026#34;hiddenSpellError\u0026#34;\u0026gt;cxfEndpoint id=\u0026#34;wsdlEndpoint\u0026#34;\raddress=\u0026#34;http://www.webservicex.net/CurrencyConvertor.asmx\u0026#34;\rendpointName=\u0026#34;c:SOAPOverHTTP\u0026#34;\rserviceName=\u0026#34;c:CurrencyConvertor\u0026#34;\rxmlns:s=\u0026#34;http://www.webserviceX.NET\u0026#34;/\u0026gt;\r  That\u0026rsquo;s it.\nNow just run the app. This will print the following-\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  [ead #0 - file://src/data/order] route1 INFO\r\u0026lt;soapenv:Header/\u0026gt;\r\u0026lt;soapenv:Body\u0026gt;\r\u0026lt;web:ConversionRate\u0026gt;\r\u0026lt;web:FromCurrency\u0026gt;AUD\u0026lt;/web:FromCurrency\u0026gt;\r\u0026lt;web:ToCurrency\u0026gt;USD\u0026lt;/web:ToCurrency\u0026gt;\r\u0026lt;/web:ConversionRate\u0026gt;\r\u0026lt;/soapenv:Body\u0026gt;-\u0026gt;\r\u0026lt;/soapenv:Envelope\u0026gt;-\u0026gt;\r  ~ Enjoy Cameling ….\n"
},
{
	"uri": "/2013/10/24/launch-website-in-amazon-ec2/",
	"title": "Launch Website in Amazon EC2",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "I wrote this blog about a year ago and left it in the draft because this post somehow was not getting auto saved on WordPress and since its long post it took time for me type, take screenshots and paste. I did not have energy and time to do it all over again. I had a copy of it though in my google drive and I cannot tell you how many times this document has helped me.\rNow I have a short-term memory. I remember phone numbers which I heard 10-15 years ago but some how command line arguments, street names etc. have always been elusive. My wife keeps poking fun at me when I drive and says that I am “directionally challenged”. I just cannot remember a route. I am absent-minded, not blank, but my mind just keep thinking all the time. I follow the same route to office every day, however as it often happens that I am always lost in my thoughts, I would take I-85 South ramp instead of I-85 north ramp and I am baffled a minute or two later, at the exit signs and wonder why are the exit numbers decreasing.\nAnyway the point is that this document will help some absent-minded like me who do the set up once but when something goes wrong do the research all over again and wonder what did I do the last time.\nAs usual I am going to start from scratch and would put this in steps.\n  Create a new Amazon web services account.\n  Go to your Console and select EC2 tab.\n  Now Lunch and instance. You will be shown a screen to select a wizard. You can choose between classic and quick wizard. The difference is that with classic wizard, you have fine grain control over what instance and software you want to install while Quick wizard is prebuilt server, for example – Ubuntu+Apache+Mysql+PHP. If you want the same instance set up on Classic wizard then you need install on your own.  I choose Classic Wizard. Click Continue.\nNext I chose UBUNTU 12.04 32 bit.\nNext choose your instance. I choose Micro instance.\n You can also chose Request Spot Instance where you basically requests your own quote and can specify the largest amount that you intend to pay. Something like price negotiator.\nClick \u0026gt;Continue\nClick \u0026gt;Continue.\nNext name your instance and click Continue.\n\rNext create a Key-Value pair. Name your key and click\u0026gt; Create and Download your Key Pair\n Save the key on your local system and click continue.\nNext configure your security settings. It will be named quick-launch by default with port 22 for sftp open. You can add more ports if you like. I added port 80(Http) and 443(Https).\nNow you are ready to launch your server.\nA confirmation page lets you know your instance is launching. Click Close to close the confirmation page.\nIn the Navigation pane, click Instances to view the status of your instance. It takes a short time for an instance to launch. The instance’s status will be pending while it’s launching.\nRecord the Public DNS name for your instance because you’ll need it for the next task. If you select the instance, its details (including the public DNS name) are displayed in the lower pane. You can also click Show/Hide in the top right corner of the page to select which columns to display.\nec2-xx-xx-xx-xx.compute-1.amazonaws.com\n Connecting to your Linux instance   Just Right click and click Connect…. It will give you option to connect via ssh or java client. Choose java client. For Ubuntu, the user name is ubuntu. Specify the location of your key-value pair that you downloaded earlier. Hit Connect. You are now connected.\nUpdate ubuntu packages. Run this command –   apt-get update\n  apt-get upgrade –show-upgraded\n Now we already have default user “\u0026gt;ubuntu”. However I wanted to create my username. So create one –   sudo adduser example_user\n You will be asked several questions like Full Name, Room number etc. Just click Enter and continue\n Enter the new value, or press ENTER for the default\n  Full Name []\nRoom Number []\nWork Phone []\nHome Phone []\nOther []\nIs the information correct? [Y/n] y\n Now we need to allow this new user to administer the system. So to do this we need to give it admin rights. Run this:   sudo usermod -a -G sudo example_user\n Install Git   sudo apt-get install build-essential git-core curl\n Install RVM to support different version of Ruby.   curl -L get.rvm.io | bash -s stable\n Add RVM to bashrc   echo ‘[[ -s “$HOME/.rvm/scripts/rvm” ]] \u0026amp;\u0026amp; source “$HOME/.rvm/scripts /rvm”‘ » ~/.bashrc\n Reload bashrc file   . ~/.bashrc\n Now exit from the session and type   type rvm| head -1\n This will give you a message that \u0026gt;“rvm is a function”\nNext we will install ruby.   rvm install 1.9.3\n Use ruby 1.9.3 as default   rvm –default use 1.9.3\n To check the version of ruby-   ruby -v\n This should tell you that you are using\n “ruby 1.9.3p194”\n Let’s install RAILS now.   gem install rails -v 3.2.1\n Now you may run into issue and get this error\n ubuntu@domU-12-31-39-09-84-B8:~$ gem install rails -v 3.2.1\nERROR: Loading command: install (LoadError)\ncannot load such file — zlib\nERROR: While executing gem … (NameError)\nuninitialized constant Gem::Commands::InstallCommand\n If you get this error that do not worry, it is just telling you that you need to install some more packages.\nRun these commands:\n rvm pkg install zlib\nrvm remove 1.9.3\nrvm install 1.9.3\nrvm –default use 1.9.3\ngem install rails -v 3.2.1\n  Time to install Mysql   sudo apt-get update\nsudo apt-get upgrade –show-upgraded\nsudo apt-get install libmysqlclient-dev\nsudo apt-get install mysql-server\n You will be prompted with Mysql installation screen. \u0026gt;Just follow the instructions to set up root user name and password.\nUpdate the git configuration   git config –global user.name “Firstname Lastname”\ngit config –global user.email “your_email@youremail.com“\n Install passenger and Nginx   gem install passenger\npassenger-install-nginx-module\n If you run into issues then run the following\n apt-get install libopenssl-ruby\napt-get install libcurl4-openssl-dev\napt-get install libssl-dev\n If you still run into issues where the installation instructions says that \u0026gt;openssl-dev is not installed then run this command\n rvm pkg install openssl\nrvm remove 1.9.3\nrvm install 1.9.3\nrvm –default use 1.9.3\nrvmsudo passenger-install-nginx-module \u0026gt;//You have to use rvmsudo if you are not logged in as root.\n Download the code from now. To do that you need to create new ssh key and set it up on github.   ssh-keygen -t rsa -C “Your-emial-address@youremial.com”\n – Copy the key value from /root/.ssh/id_rsa.pub and copy the key in your git hub account.(If you do not know how to add ssh key then see github help document. Basically just goto github settings–\u0026gt; ssh-keys–\u0026gt; Add Key)\n– Now create your app folder. I created mine under /home/apps/. Now go to apps folder and run this command in terminal – \u0026gt;git clone git@……….xxxx.git (Your git url).\nNow we will install bundler.\nSwitch to your application folder, such as – cd /home/apps/albums and run the command    gem install bundler\nbundle install\n Ran into error below for Rmagick gem\n Gem::Installer::ExtensionBuildError: ERROR: Failed to build gem native extension.\n /home/ubuntu/.rvm/rubies/ruby-1.9.3-p194/bin/ruby extconf.rb\nchecking for Ruby version \u0026gt;= 1.8.5… yes\nextconf.rb:128: Use RbConfig instead of obsolete and deprecated Config.\nchecking for gcc… yes\nchecking for Magick-config… no\nCan’t install RMagick 2.13.1. Can’t find Magick-config in /home/ubuntu/.rvm/gems/ruby-1.9.3-p194/bin:/home/ubuntu/.rvm/gems/ruby-1.9.3-p194@global/bin:/home/ubuntu/.rvm/rubies/ruby-1.9.3-p194/bin:/home/ubuntu/.rvm/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games\n*** extconf.rb failed *** \nCould not create Makefile due to some reason, probably lack of\n\u0026gt;necessary libraries and/or headers. Check the mkmf.log file for more\n\u0026gt;details. You may need configuration options.\n\u0026gt;Provided configuration options:\n\u0026gt; –with-opt-dir\n\u0026gt; –with-opt-include\n\u0026gt; –without-opt-include=${opt-dir}/include\n\u0026gt; –with-opt-lib\n\u0026gt; –without-opt-lib=${opt-dir}/lib\n\u0026gt; –with-make-prog\n\u0026gt; –without-make-prog\n\u0026gt; –srcdir=.\n\u0026gt; –curdir\n\u0026gt; –ruby=/home/ubuntu/.rvm/rubies/ruby-1.9.3-p194/bin/ruby\n\u0026gt;Gem files will remain installed in /home/ubuntu/.rvm/gems/ruby-1.9.3-p194/gems/rmagick-2.13.1 for inspection.\n\u0026gt;Results logged to /home/ubuntu/.rvm/gems/ruby-1.9.3-p194/gems/rmagick-2.13.1/ext/RMagick/gem_make.out\n\u0026gt;An error occured while installing rmagick (2.13.1), and Bundler cannot continue.\n\u0026gt;Make sure that gem install rmagick -v \u0026amp;#8216;2.13.1\u0026amp;#8217; succeeds before bundling.\n If you get the same error for Rmagick or Mysql or anything else, then run the below command.\n sudo apt-get install libmagickwand-dev\n Now re run the command\n bundle install\n Starting up the passenger now. However before we start passenger we need make sure that our database exist. So let’s create database and do the database migrations. Run the below commands –   rake db:create\nrake db:migrate //// Now this will not create a production db, but will create dev, test db for you. If you intend to create a production DB as well then run this command –\n\u0026gt;RAILS_ENV=production rake db:create\n\u0026gt;RAILS_ENV=production rake db:migrate\n I ran into issue and got the below error –\n rake aborted!\nCould not find a JavaScript runtime. See https://github.com/sstephenson/execjs for a list of available runtimes.\n The forums said that I need to install nodeJs. So here’s the list of command to install nodeJs.\n\u0026gt;sudo apt-get install python-software-properties\n  sudo add-apt-repository ppa:chris-lea/node.js\nsudo apt-get update\nsudo apt-get install nodejs\n Now the last thing you need to before starting passenger is pre compile your assets(css, images, js etc.). If you do not do this you will not be able to see the images and css. So run this command\n bundle exec rake assets:precompile\n Oh by the way if your images are not being served even after running the above command and starting passenger then you need to read my other post – http://railgaadi.wordpress.com/2012/01/28/engineyard-rails-3-x-nginx-passenger-assets-not-displayed/\nP.S. The above issue is pretty common and first time user who are trying to promote run into the above issue and give up eventually. I stopped looking at it after 2 days… took a 3 day break and attacked the issue again 🙂\nNow start the passenger.(Make sure that you have started Nginx before starting Passenger else… see my earlier post – http://railgaadi.wordpress.com/2012/01/28/engineyard-rails-3-x-nginx-passenger-assets-not-displayed/)\n passenger start -e production\n I got error that “\u0026gt;can’t connect to mysqlserver through socket tmp/mysql.sock”. If you run into this server then run this command\n  mysqladmin variables | grep socket\n If you have a root password then use\n sudo mysqladmin -p variables | grep socket\n The above command will give you socket name. In my case it gave me \u0026gt;/tmp/var/mysq.lock.\nNote this value and update your \u0026gt;database.yml file and update the socket as given below.\n development:\n\u0026gt; adapter: mysql2\n\u0026gt; host: localhost\n\u0026gt; username: root\n\u0026gt; password: xxxx\n\u0026gt; database: xxxx\n\u0026gt; socket: /tmp/mysql.sock\n After you have updated the \u0026gt;database.yml file you should be able to start the passenger.\nSetting up NGINX\nMake sure that you nginx.conf under /opt/nginx/conf file’s server section looks like this   \u0026gt;server {\n\u0026gt; listen 80;\n\u0026gt; server_name www.mysitename.com;\n\u0026gt; access_log /srv/www/mysitename.com/logs/access.log;\n\u0026gt; error_log /srv/www/mysitename.com/logs/error.log;\n\u0026gt; root /home/myapp/album/public;\n\u0026gt; passenger_enabled on;\n\u0026gt; passenger_base_uri /home/myapp/album/public;\n\u0026gt; #This property allows you to upload huge pictures files else you will get error 413- File too large\n\u0026gt; client_max_body_size 5M;\n\u0026gt; #charset koi8-r;\n\u0026gt; #access_log logs/host.access.log main;\n\u0026gt;# location / {\n\u0026gt; # root /home/dinesh19aug/album/public;\n\u0026gt; # index index.html index.htm;\n\u0026gt; # }\n Happy launching 🙂\nIn case you are wondering what did I launch —- P.S. If you have been following my blog it’s my wife’s photography website. Wifeys website\n~~Ciao\nP.S. – Look forward for my first hand experience with Node.js in the next post.\n"
},
{
	"uri": "/2013/09/18/how-to-configure-jndi-with-spring-and-jboss45/",
	"title": "How to configure JNDI with Spring and Jboss4/5",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "This is a simple process but if you try and search on the web you will come across various incomplete solutions which will leave you more confused than you already were. This configuration involves just four simple steps that I will walk through to help you set up JNDI on Jboss. I am using Jboss 4.3, but this should be valid for other version of Jboss as well.\nI have a web application which is built on Spring 3.2 and uses Hibernate 4. To set up a new JNDI configuration we will first create a datasource xml file. This file needs to be deployed in Jboss/Deploy folder along with your war file.\nStep 1:\nCreate a datasource file oracle-ds.xml. The content of the file will look like this\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt;\r\u0026lt;!DOCTYPE datasources PUBLIC -//JBoss//DTD JBOSS JCA Config 1.5//EN\u0026#34; http://www.jboss.org/j2ee/dtd/jboss-ds_1_5.dtd\u0026#34;\u0026gt;\r\u0026lt;datasources\u0026gt;\r\u0026lt;local-tx-datasource\u0026gt;\r\u0026lt;jndi-name\u0026gt;\u0026lt;strong\u0026gt;jdbc/listener-dss \u0026lt;/jndi-name\u0026gt;\r\u0026lt;connection-url\u0026gt;jdbc:oracle:thin:@dbsrvossdevl:1521:US91\u0026lt;/connection-url\u0026gt;\r\u0026lt;driver-class\u0026gt;oracle.jdbc.driver.OracleDriver\u0026lt;/driver-class\u0026gt;\r\u0026lt;user-name\u0026gt;myuser\u0026lt;/user-name\u0026gt;\r\u0026lt;password\u0026gt;mypassword\u0026lt;/password\u0026gt;\r\u0026lt;min-pool-size\u0026gt;5\u0026lt;/min-pool-size\u0026gt;\r\u0026lt;max-pool-size\u0026gt;50\u0026lt;/max-pool-size\u0026gt;\r\u0026lt;idle-timeout-minutes\u0026gt;10\u0026lt;/idle-timeout-minutes\u0026gt;\r\u0026lt;exception-sorter-class-name\u0026gt;org.jboss.resource.adapter.jdbc.vendor.OracleExceptionSorter\u0026lt;/exception-sorter-class-name\u0026gt;\r\u0026lt;metadata\u0026gt;\r\u0026lt;type-mapping\u0026gt;Oracle9i\u0026lt;/type-mapping\u0026gt;\r\u0026lt;/metadata\u0026gt;\r\u0026lt;/local-tx-datasource\u0026gt;\r\u0026lt;/datasources\u0026gt;\r  Explanation:\n1  \u0026lt;jndi-name\u0026gt;jdbc/listener-dss \u0026lt;/jndi-name\u0026gt;\r  This line tells what is the jndi name that we are going to use across configuration files.\nStep 2: Now open your web.xml file and add the resource-ref. This tells that jee container that your web application is using JNDI.\nYour web.xml should be under WEB-INF folder. Add the below lines in your web.xml (see the highlighted section ). This step is common whether you use Jboss or Tomcat or Websphere or any other application server.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt;\r\u0026lt;web-app version=\u0026#34;2.5\u0026#34; xmlns=\u0026#34;http://java.sun.com/xml/ns/javaee\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34;\rxsi:schemaLocation=\u0026#34;http://java.sun.com/xml/ns/javaee\rhttp://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\u0026#34;\u0026gt;\r\u0026lt;display-name\u0026gt;ACN Web Application\u0026lt;/display-name\u0026gt;\r\u0026lt;servlet\u0026gt;\r\u0026lt;servlet-name\u0026gt;listener\u0026lt;/servlet-name\u0026gt;\r\u0026lt;servlet-class\u0026gt;org.springframework.web.servlet.DispatcherServlet\u0026lt;/servlet-class\u0026gt;\r\u0026lt;load-on-startup\u0026gt;1\u0026lt;/load-on-startup\u0026gt;\r\u0026lt;/servlet\u0026gt;\r\u0026lt;servlet-mapping\u0026gt;\r\u0026lt;servlet-name\u0026gt;listener\u0026lt;/servlet-name\u0026gt;\r\u0026lt;url-pattern\u0026gt;/\u0026lt;/url-pattern\u0026gt;\r\u0026lt;/servlet-mapping\u0026gt;\r\u0026lt;context-param\u0026gt;\r\u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt;\r\u0026lt;param-value\u0026gt;/WEB-INF/listener-servlet.xml\u0026lt;/param-value\u0026gt;\r\u0026lt;/context-param\u0026gt;\r\u0026lt;resource-ref\u0026gt;\r\u0026lt;description\u0026gt;Listener Database\u0026lt;/description\u0026gt;\r\u0026lt;res-ref-name\u0026gt;jdbc/listener-dss\u0026lt;/res-ref-name\u0026gt;\r\u0026lt;res-type\u0026gt;javax.sql.DataSource\u0026lt;/res-type\u0026gt;\r\u0026lt;res-auth\u0026gt;Container\u0026lt;/res-auth\u0026gt;\r\u0026lt;/resource-ref\u0026gt;\r\u0026lt;listener\u0026gt;\r\u0026lt;listener-class\u0026gt;org.springframework.web.context.ContextLoaderListener\u0026lt;/listener-class\u0026gt;\r\u0026lt;/listener\u0026gt;\r\u0026lt;welcome-file-list\u0026gt;\r\u0026lt;welcome-file\u0026gt;index.jsp\u0026lt;/welcome-file\u0026gt;\r\u0026lt;/welcome-file-list\u0026gt;\r\u0026lt;/web-app\u0026gt;\r  Step 3: Next we will update the Spring context xml file to tell the Spring container that it needs to do a JNDI look up. My Spring context file name is listener-servlet.xml and this is under WEB-INF folder. Add the following(See highlighted section)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34;\rxmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34;\rxmlns:mvc=\u0026#34;http://www.springframework.org/schema/mvc\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34;\rxmlns:tx=\u0026#34;http://www.springframework.org/schema/tx\u0026#34;\rxmlns:p=\u0026#34;http://www.springframework.org/schema/p\u0026#34;\rxsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans\rhttp://www.springframework.org/schema/beans/spring-beans-3.0.xsd\rhttp://www.springframework.org/schema/context\rhttp://www.springframework.org/schema/context/spring-context-3.0.xsd\rhttp://www.springframework.org/schema/mvc\rhttp://www.springframework.org/schema/mvc/spring-mvc-3.0.xsd\rhttp://www.springframework.org/schema/tx\rhttp://www.springframework.org/schema/tx/spring-tx.xsd \u0026gt;\r\u0026lt;context:component-scan base-package=\u0026#34;com.acn.cslistener\u0026#34; /\u0026gt;\r\u0026lt;mvc:annotation-driven /\u0026gt;\r\u0026lt;tx:annotation-driven/\u0026gt;\r\u0026lt;bean class=\u0026#34;org.springframework.web.servlet.view.InternalResourceViewResolver\u0026#34;\u0026gt;\r\u0026lt;property name=\u0026#34;prefix\u0026#34;\u0026gt;\r\u0026lt;value\u0026gt;/WEB-INF/pages/\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property name=\u0026#34;suffix\u0026#34;\u0026gt;\r\u0026lt;value\u0026gt;.jsp\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;/bean\u0026gt;\r\u0026lt;bean id=\u0026#34;sessionFactory\u0026#34; class=\u0026#34;org.springframework.orm.hibernate4.LocalSessionFactoryBean\u0026#34;\u0026gt;\r\u0026lt;property name=\u0026#34;dataSource\u0026#34; ref=\u0026#34;dataSource\u0026#34;/\u0026gt;\r\u0026lt;property name=\u0026#34;hibernateProperties\u0026#34;\u0026gt;\r\u0026lt;props\u0026gt;\r\u0026lt;prop key=\u0026#34;hibernate.dialect\u0026#34;\u0026gt;org.hibernate.dialect.Oracle10gDialect\u0026lt;/prop\u0026gt;\r\u0026lt;prop key=\u0026#34;hibernate.show_sql\u0026#34;\u0026gt;true\u0026lt;/prop\u0026gt;\r\u0026lt;/props\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property name=\u0026#34;packagesToScan\u0026#34; value=\u0026#34;com.acn.cslistener\u0026#34; /\u0026gt;\r\u0026lt;/bean\u0026gt;\r\u0026lt;bean id=\u0026#34;dataSource\u0026#34; class=\u0026#34;org.springframework.jndi.JndiObjectFactoryBean\u0026#34;\u0026gt;\r\u0026lt;property name=\u0026#34;jndiName\u0026#34; value=\u0026#34;java:comp/env/jdbc/listener-dss\u0026#34;/\u0026gt;\r\u0026lt;/bean\u0026gt;\r\u0026lt;bean id=\u0026#34;transactionManager\u0026#34; class=\u0026#34;org.springframework.orm.hibernate4.HibernateTransactionManager\u0026#34;\rp:sessionFactory-ref=\u0026#34;sessionFactory\u0026#34;\u0026gt;\r\u0026lt;/bean\u0026gt;\r\u0026lt;bean id=\u0026#34;persistenceAnnotation\u0026#34; class=\u0026#34;org.springframework.orm.jpa.support.PersistenceAnnotationBeanPostProcessor\u0026#34; /\u0026gt;\r\u0026lt;/beans\u0026gt;\r  Step 4: This is the crucial step. If you are using Jboss then it requires that you tell the web container that Jboss will provide the datasource .xml file where you have defined your jndi properties. Create a new file jboss-web.xml. Place this file under WEB-INF folder. The contents of the file whould like this.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt;\r\u0026lt;jboss-web\u0026gt;\r\u0026lt;resource-ref\u0026gt;\r\u0026lt;res-ref-name\u0026gt;jdbc/listener-dss\u0026lt;/res-ref-name\u0026gt;\r\u0026lt;res-type\u0026gt;javax.sql.DataSource\u0026lt;/res-type\u0026gt;\r\u0026lt;jndi-name\u0026gt;java:/jdbc/listener-dss\u0026lt;/jndi-name\u0026gt;\r\u0026lt;/resource-ref\u0026gt;\r\u0026lt;/jboss-web\u0026gt;\r  That\u0026rsquo;s all we need to do.\n"
},
{
	"uri": "/2013/08/01/rails-jquery-is-not-loading/",
	"title": "Rails: Jquery is not loading",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "It’s been a while I have posted anything. I have been extremly busy and have been working on an extremely critical project where we were asked to become PCI 2.0 compliant. I worked on some interesting problems however today I will be discussing on something trivial and discuss my frustration about Rails. I have to admit that a number of times I thought I should just give up and start learning Python or stick to my forte i.e. Java. BUT Ruby/Rails has been a love hate relationship for me. Every few months I pick up Rails again and struggle fixing the set up before I can start working on my website.\nSo a couple of months back my wife complained that she is not using her website to update client’s picture because there is no client login and the if she upload their album, the album is visible to everyone. So I fixed that and deployed the application. No issues.\nSo two months later about a week ago, I checked again with her and like all nagging wife she complained that she is still not using it because she cannot upload multiple images. So like a dutiful husband I set out to set up rails on my new mac and begin coding however my production branch was not working fine. I was seeing issue with flexslider and found that non of my images were not showing up and Rails complained that JQuery was not defined. I tried everything but I could not make it work.\nSo if you have been issues with JQuery make sure that you have checked these things:\n Your gem file should have this line.    gem ‘jquery-rails’\n  gem “flexslider” — This if you are using flexslider\n In your application.js, make sure that you have defined jquery and the most important thing …… notice the sequence.  //= require jquery_ujs\n//= require jquery\n//= require flexslider\n//= require_tree .\nMy sequence was incorrect and I had defined juqery before jquery_ujs which was throwing error in my application.\nHope this post helps.\n  ~Ciao\n "
},
{
	"uri": "/2013/05/15/how-to-post-parameters-to-a-url-using-ajaxjavascript-between-two-website/",
	"title": "How to post parameters to a url using Ajax/Javascript between two website",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "I am working a new project and I recently ran into an interesting problem. One of the web site that I keep up at work was supposed to take the user to another website which required me to add post parameters.\nEX - www.mywebsite.makeapayment.com ==\u0026gt; Collects Billing information ex - name, amount, address etc.==\u0026gt; Post this information to www.vendor-website.com.\nI did not realize the problem until I started coding and my colleague pointed out that as soon as www.mywebsite.makeapayment.com goes to my servlet, the servlet will not pass params to external web site if use \u0026ldquo;POST\u0026rdquo;, I had to use \u0026ldquo;GET\u0026rdquo; because servlet will look up relative path only and the HTTPServletRequest/Response object is specific to an application. So if I wanted to send parameters using servlet I could only that using action = GET. Now since I was passing sensitive information so I did not want to use GET.\nA couple of solutions were discussed as follows:\n  Insert the params in database and use servlet get from the mywebsite.com to pass the primary key of the database. Ex - www.mywebsite.makeapayment.com ==\u0026gt; www.vendor-website.com?key=10001. The vendor application look up the required params from the database.\n  Create a new JSP and use JavaScript onLoad() to pass the params as Hidden Input and submit as post to www.vendor-website.com.\n   Ex - www.mywebsite.makeapayment.com==\u0026gt; Servlet==\u0026gt; New Blank JSP with Hidden params loaded on onLoad() and submitted to vendor website ==\u0026gt; www.vendor-website.com.\n Third approach is interesting and I had not tried this ever but looked promising and this is what I eventually implemented. Make an Ajax call to from the JSP page to your servlet and when the Ajax Call returns, post it to vendor web site.  Ex - www.mywebsite.makeapayment.com on hitting submit==\u0026gt; calls the JS, uses DWR to post to call the servlet==\u0026gt; Servlet does back ground processing like saving the records etc ==\u0026gt; Returns the control back to the JavaScript ==\u0026gt; Upon return in Ajax Call ==\u0026gt; Post to www.vendor-website.com.\nI implemented the combination of one and three but here I am going to show you how post params to a different URL - i.e. solution 3\nLet\u0026rsquo;s say I have a submit form with Name and address which needs to be saved in database when I submit the form and then I need to post the same information to different web site.\nPersonalInformation.jsp\n\u0026lt;html\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;script\u0026gt;\r\u0026gt; // I am not showing the code for DWR. You will need to include dwr and engine.js. Add dwr.xml in your web-inf and specify the class name and method you want to use as dwr call. This method is called in the dwr Ajax call back.\rfunction submitAndGoToVendorSite()\rvar form = document.createElement(\u0026quot;FORM\u0026quot;);\rform.method = \u0026quot;POST\u0026quot;;\rform.style.display = \u0026quot;none\u0026quot;;\rdocument.body.appendChild(form);\rvar url=\u0026quot;www.vendor-website.com\u0026quot;;\rform.action = url;\r//My dwr ajax call gets a Json string from the servlet response.\rvar jsonString = \u0026quot;{\u0026quot;transactionId\u0026quot;:\u0026quot;1368505156670\u0026quot;,\u0026quot;requesterType\u0026quot;:\u0026quot;APP\u0026quot;,\u0026quot;billingEmail\u0026quot;:\u0026quot;null@cybersource.com\u0026quot;,\u0026quot;billingState\u0026quot;:\u0026quot;NC\u0026quot;,\u0026quot;amount\u0026quot;:\u0026quot;42.7699999999999999433786257441170164384\u0026quot;,\u0026quot;refund\u0026quot;:\u0026quot;N\u0026quot;,\u0026quot;billingCity\u0026quot;:\u0026quot;CONCORD\u0026quot;,\u0026quot;billingLine1\u0026quot;:\u0026quot;Progress Pl\u0026quot;,\u0026quot;billingFirstname\u0026quot;:\u0026quot;test\u0026quot;,\u0026quot;billingLine2\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;shopperIP\u0026quot;:\u0026quot;127.0.0.1\u0026quot;,\u0026quot;application\u0026quot;:\u0026quot;OEP2\u0026quot;,\u0026quot;currencyCode\u0026quot;:\u0026quot;USD\u0026quot;,\u0026quot;billingCompany\u0026quot;:\u0026quot;ACN\u0026quot;,\u0026quot;revenueSource\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;billingLastname\u0026quot;:\u0026quot;test\u0026quot;,\u0026quot;countryCode\u0026quot;:\u0026quot;US\u0026quot;,\u0026quot;billingAddrNum\u0026quot;:\u0026quot;1000\u0026quot;,\u0026quot;cardType\u0026quot;:\u0026quot;VISA\u0026quot;,\u0026quot;businessPurpose\u0026quot;:\u0026quot;TOOL\u0026quot;,\u0026quot;profileConfig\u0026quot;:\u0026quot;cybersource-MLTEST1\u0026quot;,\u0026quot;language\u0026quot;:\u0026quot;en\u0026quot;,\u0026quot;billingZip\u0026quot;:\u0026quot;28025\u0026quot;,\u0026quot;repOrCustID\u0026quot;:\u0026quot;1233836\u0026quot;,\u0026quot;user\u0026quot;:\u0026quot;DARORATEST\u0026quot;,\u0026quot;paymentMethod\u0026quot;:\u0026quot;CC\u0026quot;,\u0026quot;billingPhone\u0026quot;:\u0026quot;\u0026quot;}'\r// Create a JSON object from the JSON String\rvar jsonObj = jQuery.parseJSON(jsonString);\r//Iterate over Json object and set them as hidden input params to the form\rfor(obj in jsonObj)\r{\rvar input = document.createElement(\u0026quot;INPUT\u0026quot;);\rinput.type = \u0026quot;hidden\u0026quot;;\rinput.name = obj;\rinput.value = jsonObj[obj];\rform.appendChild(input);\r}\r//Submit the form\rform.submit();\r\u0026lt;/script\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;form\u0026gt;\r\u0026lt;label\u0026gt;Name:\u0026lt;/label\u0026gt;\u0026lt;Input type=\u0026quot;text\u0026quot;/\u0026gt;\r\u0026amp;#8230;\u0026amp;#8230;\u0026amp;#8230;.\r\u0026lt;input type=\u0026quot;button\u0026quot; onclick=\u0026quot;submitAndGoToVendorSite();\u0026quot;/\u0026gt;\r\u0026lt;/form\u0026gt;\r\u0026lt;/body\u0026gt;\rThat\u0026rsquo;s It!\n~Keep Coding\n"
},
{
	"uri": "/2013/03/07/using-multiple-profiles-in-maven-eclipse/",
	"title": "Using multiple profiles in Maven + Eclipse",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "It’s possible that many of you already knew this but if not then here’ some basic info on Maven profiles. I have been using maven for over 2 and half years now, and have been copy pasting assembly and install files. I never bothered to know how Maven figures out how to read assembly and install file names. For example-\nPROBLEM:\nFor all my projects I have been using assembly-jboss.xml to put the file/directory information and telling maven about my desired directory structure i.e. Pick files from a/b directory and put it in out directory c/d. The second file install-jboss.xml where I specify my panels, target files etc. It never occurred to me what happens if I change the file names to assembly-zzz.xml and intsall-zzz.xml.\n\nWell to cut the story short I checked out a fellow developer code on my machine and the command\n mvn clean install\n threw build error which said -\n[1] [INFO] Searching for file location: C:\\Dinesh\\workspace\\prov-ld-anin-trunk\\artifacts\\src\\assembly\\assembly-jboss4.xml\r[2] [INFO] File: C:\\Dinesh\\workspace\\prov-ld-anin-trunk\\artifacts\\src\\assembly\\assembly-jboss4.xml does not exist.\r[3] [INFO] File: C:\\Dinesh\\workspace\\prov-ld-anin-trunk\\src\\assembly\\assembly-jboss4.xml does not exist.\rNow I was using IZPack plugin and always thought the assembly and install xmls are part of IZPack configuration, so for half an hour I was searching “IZPack assembly descriptor”. Needless to say I did not get any releveant search result. After scratching my head a little and doing a text search in Eclipse to figure out how am I telling maven to find the specific files (in my case the fellow developer had named them as assembly-wso2carbon40.xml and install-wso2carbon40.xml). No results.\nSOLUTION:\nIn Maven you set up a profile in your .m2/settings.xml. For example my settings.xml looks like this\n1 2 3 4 5 6 7 8 9 10 11 12  \u0026lt;settings\u0026gt; \u0026lt;profiles\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;jboss4\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.home\u0026gt;\u0026lt;/java.home\u0026gt; \u0026lt;compileSource\u0026gt;1.5\u0026lt;/compileSource\u0026gt; \u0026lt;server\u0026gt;jboss4\u0026lt;/server\u0026gt;\r\u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt; \u0026lt;/settings\u0026gt;\r  If you will notice I have specified that jboss4 tag has value jboss4. When maven is building your app, it looks for two files assemby-xxx.xml and install-xxx.xml. Here xxxin assembly-xxx.xml is the profile name. So in my case it looks in the settings.xml and sees that profile is jboss, so it uses to find a file assembly-jboss.xml and install-jboss4.xml.\nSo now the problem was that my developer friend had named the files as assembly-wso2Carbon40.xml and install-wso2Carbon40.xml. The first thing that came to my mind was let’s change the jboss4to ****wso2, that would resolve my issue. However I had other application where the file was named assembly-jboss.xml and install-jboss4.xml, which meant that my other application will error out on maven clean install and throw error message could not locate assembly file assembly-wso2Carbon40.xml .\nHere’s comes the neat part, you can have multiple profiles in your settings file. So I updated my .m2/settings.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  \u0026lt;settings\u0026gt; \u0026lt;profiles\u0026gt; \u0026lt;profile\u0026gt; **\u0026lt;id\u0026gt;jboss\u0026lt;/id\u0026gt;** \u0026lt;properties\u0026gt; \u0026lt;svn.username\u0026gt;\u0026lt;/svn.username\u0026gt; \u0026lt;svn.password\u0026gt;\u0026lt;/svn.password\u0026gt; \u0026lt;java.home\u0026gt;\u0026lt;/java.home\u0026gt; \u0026lt;compileSource\u0026gt;1.5\u0026lt;/compileSource\u0026gt; \u0026lt;server\u0026gt;jboss4\u0026lt;/server\u0026gt; \u0026lt;server.home\u0026gt;C:Program Filesjboss-eap-4.3\u0026lt;/server.home\u0026gt; \u0026lt;server.port\u0026gt;80\u0026lt;/server.port\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;profile\u0026gt;\r\u0026lt;id\u0026gt;wso2\u0026lt;/id\u0026gt;\r\u0026lt;properties\u0026gt;\r\u0026lt;compileSource\u0026gt;1.5\u0026lt;/compileSource\u0026gt;\r\u0026lt;server\u0026gt;wso2carbon40\u0026lt;/server\u0026gt;\r\u0026lt;/properties\u0026gt;\u0026lt;br /\u0026gt;\r\u0026lt;/profile\u0026gt;\r\u0026lt;/profiles\u0026gt; \u0026lt;/settings\u0026gt;\r  Now when you build the project using Eclipse, just got to Run As ==\u0026gt; Maven Build … and enter Goals = clean install and Profile = wso2\n\nThat’s it!\n~~Cheers!\n"
},
{
	"uri": "/2012/09/23/how-to-send-email-in-phonegap-android-using-a-gmail-account/",
	"title": "How to send email in PhoneGap (Android) using a gmail account",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "For the last one month, I have been working on an android app for a grocery store.\nI have been using PhoneGap to develop the solution as the client wanted both Android and Iphone version.\nI have tried building the app in native Android but going through the hassle of designing css was just too much for me and plus I did not had time to learn Iphone development.\nThere was a short learning phase for PhoneGap and the results were awesome. However there was one area where I spent hours and ran into several issues. The customer wanted a Feedback section where the user could fill in feedback in a TextArea and hits Submit, which would send an email to customer in the background.\nNow PhoneGap has plugin called WebIntent which will open a Email composer where you have to hit Send. This is not what I wanted as customer would have to hit a SUBMIT button, which would open a Email composer window on Phone and then hit Send again. Also this solution also meant user’s email address would be displayed to Grocery store.\nI wanted to send the feedback in the background anonymously to Grocery store. I decided to use Java email Api and create a dummy email for grocery store which would be used to send feedback to the Grocery store’s main email address.\nI did not find any good tutorial except this one. This is an incomplete tutorial and did not tell you how to create Java classes for Plugin or that you had to make entries in config.xml. So here is the actual tutorial.\nBefore I begin, let me tell you that I am using latest version of Cordova 2.1.0. This is will not work for Cordova 1.9.0(I will explain the issue below).\nStep 1: Add cordova-2.1.0.jar in the project classpath\nStep 2: Add cordova-2.1.0.js in the assets/www/js folder.\nStep 3: create a new Java class called EmailComoposer.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  package com.dinesh.pb;\rimport org.apache.cordova.api.Plugin;\rimport org.apache.cordova.api.PluginResult;\rimport org.apache.cordova.api.PluginResult.Status;\rimport org.json.JSONArray;\rimport org.json.JSONException;\rimport android.annotation.SuppressLint;\rimport android.content.Intent;\rimport android.text.Html;\rimport com.dinesh.pb.utility.Mail;\r@SuppressLint(\u0026#34;ParserError\u0026#34;)\rpublic class EmailComposer extends Plugin {\rpublic final String ACTION_SEND_EMAIL = \u0026#34;sendEmail\u0026#34;;\r@Override\rpublic PluginResult execute(String action, JSONArray arg1, String callbackId) {\rPluginResult result = new PluginResult(Status.INVALID_ACTION);\rif (action.equals(ACTION_SEND_EMAIL)) {\rtry {\rString message = arg1.getString(0);\rthis.sendEmailViaGmail(message);\rresult = new PluginResult(Status.OK);\r}\rcatch (JSONException ex) {\rresult = new PluginResult(Status.JSON_EXCEPTION, ex.getMessage());\r} catch (Exception e) {\r// TODO Auto-generated catch block\r e.printStackTrace();\r}\r}\rreturn result;\r}\rprivate void sendEmailViaGmail(String body) throws Exception{\rMail m = new Mail(\u0026#34;From_email_address@gmail.com\u0026#34;, \u0026#34;your password\u0026#34;);\rString[] toArr = {\u0026#34;TO_EMAIL_ADDRESS@gmail.com\u0026#34;};\rm.set_to(toArr);\rm.set_from(\u0026#34;FROM_EMAIL_ADDRESS@gmail.com\u0026#34;);\rm.set_body(body);\rm.set_subject(\u0026#34;TEST SUBJECT\u0026#34;);\rboolean sendFlag = m.send();\r}\r}\r  Step 4. copy this Mail.java in package of your choice. My package name is com.dinesh.pb.utility.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168  package com.dinesh.pb.utility;\rimport java.util.Date;\rimport java.util.Properties;\rimport javax.activation.CommandMap;\rimport javax.activation.DataHandler;\rimport javax.activation.DataSource;\rimport javax.activation.FileDataSource;\rimport javax.activation.MailcapCommandMap;\rimport javax.mail.BodyPart;\rimport javax.mail.Multipart;\rimport javax.mail.PasswordAuthentication;\rimport javax.mail.Session;\rimport javax.mail.Transport;\rimport javax.mail.internet.InternetAddress;\rimport javax.mail.internet.MimeBodyPart;\rimport javax.mail.internet.MimeMessage;\rimport javax.mail.internet.MimeMultipart;\rpublic class Mail extends javax.mail.Authenticator {\rprivate String _user;\rprivate String _pass;\rprivate String[] _to;\rprivate String _from;\rprivate String _port;\rprivate String _sport;\rprivate String _host;\rprivate String _subject;\rprivate String _body;\rprivate boolean _auth;\rprivate boolean _debuggable;\rprivate Multipart _multipart;\rpublic Mail() {\r_host = \u0026#34;smtp.gmail.com\u0026#34;; // default smtp server\r _port = \u0026#34;465\u0026#34;; // default smtp port\r _sport = \u0026#34;465\u0026#34;; // default socketfactory port\r\r_user = \u0026#34;\u0026#34;; // username\r _pass = \u0026#34;\u0026#34;; // password\r _from = \u0026#34;\u0026#34;; // email sent from\r _subject = \u0026#34;\u0026#34;; // email subject\r _body = \u0026#34;\u0026#34;; // email body\r\r_debuggable = false; // debug mode on or off - default off\r _auth = true; // smtp authentication - default on\r\r_multipart = new MimeMultipart();\r// There is something wrong with MailCap, javamail can not find a handler for the multipart/mixed part, so this bit needs to be added.\r MailcapCommandMap mc = (MailcapCommandMap) CommandMap.getDefaultCommandMap();\rmc.addMailcap(\u0026#34;text/html;; x-java-content-handler=com.sun.mail.handlers.text_html\u0026#34;);\rmc.addMailcap(\u0026#34;text/xml;; x-java-content-handler=com.sun.mail.handlers.text_xml\u0026#34;);\rmc.addMailcap(\u0026#34;text/plain;; x-java-content-handler=com.sun.mail.handlers.text_plain\u0026#34;);\rmc.addMailcap(\u0026#34;multipart/*;; x-java-content-handler=com.sun.mail.handlers.multipart_mixed\u0026#34;);\rmc.addMailcap(\u0026#34;message/rfc822;; x-java-content-handler=com.sun.mail.handlers.message_rfc822\u0026#34;);\rCommandMap.setDefaultCommandMap(mc);\r}\rpublic Mail(String user, String pass) {\rthis();\r_user = user;\r_pass = pass;\r}\rpublic boolean send() throws Exception {\rProperties props = _setProperties();\rif(!_user.equals(\u0026#34;\u0026#34;) \u0026amp;\u0026amp; !_pass.equals(\u0026#34;\u0026#34;) \u0026amp;\u0026amp; _to.length \u0026gt; 0 \u0026amp;\u0026amp; !_from.equals(\u0026#34;\u0026#34;) \u0026amp;\u0026amp; !_subject.equals(\u0026#34;\u0026#34;) \u0026amp;\u0026amp; !_body.equals(\u0026#34;\u0026#34;)) {\rSession session = Session.getInstance(props, this);\rMimeMessage msg = new MimeMessage(session);\rmsg.setFrom(new InternetAddress(_from));\rInternetAddress[] addressTo = new InternetAddress[_to.length];\rfor (int i = 0; i \u0026lt; _to.length; i++) {\raddressTo[i] = new InternetAddress(_to[i]);\r}\rmsg.setRecipients(MimeMessage.RecipientType.TO, addressTo);\rmsg.setSubject(_subject);\rmsg.setSentDate(new Date());\r// setup message body\r BodyPart messageBodyPart = new MimeBodyPart();\rmessageBodyPart.setText(_body);\r_multipart.addBodyPart(messageBodyPart);\r// Put parts in message\r msg.setContent(_multipart);\r// send email\r Transport.send(msg);\rreturn true;\r} else {\rreturn false;\r}\r}\rpublic void addAttachment(String filename) throws Exception {\rBodyPart messageBodyPart = new MimeBodyPart();\rDataSource source = new FileDataSource(filename);\rmessageBodyPart.setDataHandler(new DataHandler(source));\rmessageBodyPart.setFileName(filename);\r_multipart.addBodyPart(messageBodyPart);\r}\rpublic String[] get_to() {\rreturn _to;\r}\rpublic void set_to(String[] _to) {\rthis._to = _to;\r}\rpublic String get_from() {\rreturn _from;\r}\rpublic void set_from(String _from) {\rthis._from = _from;\r}\rpublic String get_body() {\rreturn _body;\r}\rpublic void set_body(String _body) {\rthis._body = _body;\r}\r@Override\rpublic PasswordAuthentication getPasswordAuthentication() {\rreturn new PasswordAuthentication(_user, _pass);\r}\rprivate Properties _setProperties() {\rProperties props = new Properties();\rprops.put(\u0026#34;mail.smtp.host\u0026#34;, _host);\rif(_debuggable) {\rprops.put(\u0026#34;mail.debug\u0026#34;, \u0026#34;true\u0026#34;);\r}\rif(_auth) {\rprops.put(\u0026#34;mail.smtp.auth\u0026#34;, \u0026#34;true\u0026#34;);\r}\rprops.put(\u0026#34;mail.smtp.port\u0026#34;, _port);\rprops.put(\u0026#34;mail.smtp.socketFactory.port\u0026#34;, _sport);\rprops.put(\u0026#34;mail.smtp.socketFactory.class\u0026#34;, \u0026#34;javax.net.ssl.SSLSocketFactory\u0026#34;);\rprops.put(\u0026#34;mail.smtp.socketFactory.fallback\u0026#34;, \u0026#34;false\u0026#34;);\rreturn props;\r}\rpublic String get_subject() {\rreturn _subject;\r}\rpublic void set_subject(String _subject) {\rthis._subject = _subject;\r}\r// more of the getters and setters …..\r }\r  Step 5: Update the config.xml and add the details about the new plugin class EmailComposer.java.\nMine looks like this -\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  \u0026lt;plugin name=\u0026#34;EmailComposer\u0026#34; value=\u0026#34;com.dinesh.pb.EmailComposer\u0026#34;/\u0026gt;. Please update the package name value=\u0026#34;com.dinesh.pb.EmailComposer\u0026#34; with your package path.\r\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;cordova\u0026gt;\r\u0026lt;access origin=\u0026#34;http://127.0.0.1*\u0026#34;/\u0026gt; \u0026lt;!--allow local pages --\u0026gt; \u0026lt;access origin=\u0026#34;.*\u0026#34;/\u0026gt; \u0026lt;log level=\u0026#34;DEBUG\u0026#34;/\u0026gt;\r\u0026lt;preference name=\u0026#34;useBrowserHistory\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt;\r\u0026lt;preference name=\u0026#34;exit-on-suspend\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt;\r\u0026lt;plugins\u0026gt;\r\u0026lt;plugin name=\u0026#34;App\u0026#34; value=\u0026#34;org.apache.cordova.App\u0026#34;/\u0026gt;\r\u0026lt;plugin name=\u0026#34;Geolocation\u0026#34; value=\u0026#34;org.apache.cordova.GeoBroker\u0026#34;/\u0026gt;\r\u0026lt;plugin name=\u0026#34;Device\u0026#34; value=\u0026#34;org.apache.cordova.Device\u0026#34;/\u0026gt;\r\u0026lt;plugin name=\u0026#34;Accelerometer\u0026#34; value=\u0026#34;org.apache.cordova.AccelListener\u0026#34;/\u0026gt;\r\u0026lt;plugin name=\u0026#34;Compass\u0026#34; value=\u0026#34;org.apache.cordova.CompassListener\u0026#34;/\u0026gt;\r\u0026lt;plugin name=\u0026#34;Media\u0026#34; value=\u0026#34;org.apache.cordova.AudioHandler\u0026#34;/\u0026gt;\r\u0026lt;plugin name=\u0026#34;Camera\u0026#34; value=\u0026#34;org.apache.cordova.CameraLauncher\u0026#34;/\u0026gt;\r\u0026lt;plugin name=\u0026#34;Contacts\u0026#34; value=\u0026#34;org.apache.cordova.ContactManager\u0026#34;/\u0026gt;\r\u0026lt;plugin name=\u0026#34;File\u0026#34; value=\u0026#34;org.apache.cordova.FileUtils\u0026#34;/\u0026gt;\r\u0026lt;plugin name=\u0026#34;NetworkStatus\u0026#34; value=\u0026#34;org.apache.cordova.NetworkManager\u0026#34;/\u0026gt;\r\u0026lt;plugin name=\u0026#34;Notification\u0026#34; value=\u0026#34;org.apache.cordova.Notification\u0026#34;/\u0026gt;\r\u0026lt;plugin name=\u0026#34;Storage\u0026#34; value=\u0026#34;org.apache.cordova.Storage\u0026#34;/\u0026gt;\r\u0026lt;plugin name=\u0026#34;Temperature\u0026#34; value=\u0026#34;org.apache.cordova.TempListener\u0026#34;/\u0026gt;\r\u0026lt;plugin name=\u0026#34;FileTransfer\u0026#34; value=\u0026#34;org.apache.cordova.FileTransfer\u0026#34;/\u0026gt;\r\u0026lt;plugin name=\u0026#34;Capture\u0026#34; value=\u0026#34;org.apache.cordova.Capture\u0026#34;/\u0026gt;\r\u0026lt;plugin name=\u0026#34;Battery\u0026#34; value=\u0026#34;org.apache.cordova.BatteryListener\u0026#34;/\u0026gt;\r\u0026lt;plugin name=\u0026#34;SplashScreen\u0026#34; value=\u0026#34;org.apache.cordova.SplashScreen\u0026#34;/\u0026gt;\r\u0026lt;plugin name=\u0026#34;Echo\u0026#34; value=\u0026#34;org.apache.cordova.Echo\u0026#34; /\u0026gt;\r\u0026lt;plugin name=\u0026#34;EmailComposer\u0026#34; value=\u0026#34;com.dinesh.pb.EmailComposer\u0026#34;/\u0026gt;\r\u0026lt;/plugins\u0026gt;\r\u0026lt;/cordova\u0026gt;\u0026lt;/pre\u0026gt;\r  Step 6: Create a new javascript file called email.js\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  var EmailComposer = function(){};\r/*\rcordova.addConstructor(function() {\rcordova.addPlugin(\u0026#34;emailcomposer\u0026#34;, new EmailComposer());\r});\r*/\rEmailComposer.prototype.send = function (message){\rconsole.log(\u0026#34;Calling the send message\u0026#34;);\rcordova.exec(function(){ alert(\u0026#39;feedback sent\u0026#39;)}, function(){ alert(\u0026#39;feedback was not sent\u0026#39;)}, \u0026#39;EmailComposer\u0026#39;, \u0026#39;sendEmail\u0026#39;, [message]);\r}\rfunction sendFeedback(){\rwindow.EmailComposer.prototype.send(\u0026#34;My message body\u0026#34;);\r}\r  Now as I mentioned earlier that I am using cordova-2.1.0.js/jar file there are subtle differences between the latest version and older version (cordova-1.9.0). If you are using older version you will need to uncomment the section cordova.addConstructorabove and instead of calling\n window.EmailComposer.prototype.send(\u0026ldquo;My message body\u0026rdquo;);\n Use this:\n window.plugins.emailComposer.prototype.send(body);\n If you do not use it then you may get error which would say that window.plugins is not defined. If you run into such issues use firebug and see what variables are defined under “window\u0026rdquo; variable.\nNotice the method called “feedback()\u0026quot;. I am simply passing the user text as message body by capturing the input from user feedback TextBox. For simplicity I have just pasted a default Email body.\nStep 7: Include the js file in your index.html file\n1 2 3 4 5 6 7 8 9 10 11 12 13  // \u0026lt;!-[CDATA[\r\r\u0026#34;javascript\u0026#34; src=\u0026#34;js/email.js\u0026#34;\u0026gt;\r// ]]\u0026gt;\r\rStep 8: Include cordova js file in index.html\r// \u0026lt;!-[CDATA[\r\rjavascript\u0026#34; src=\u0026#34;js/cordova-2.1.0.js\u0026#34;\u0026gt;\r// ]]\u0026gt;\r  Step 9: Add three jar files for Java mail api - namely, Activation.jar, Mail.jar and Additional.jar in the libs folder and add it to the classpath. You can these files here.\nCheers!!\nUPDATE: A lot of people commented that they could not find mail.jar,additional.jar and actication.jar so I have uploaded them on 4shared.com. You can download them from the link below.\nActivation.jar\nAdditional.jar\nMail.jar\n"
},
{
	"uri": "/2012/07/13/share-any-folder-on-mac-via-built-in-web-server/",
	"title": "How To Share Any Folder On Mac Via Built-in Web Server",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "So what\u0026rsquo;s new here? Well I was playing around with Phonegap to build a small android and ios app. I was able to build a small weather app using Yahoo weather api but then I came across Sencha Touch 2.\nI wanted to build the same app in Sencha Touch and compare the two platforms for developing mobile apps and as ap part of its get started tutorial I had to drop the Sencha Touch in a web server. Now as it always happens with me the most simplest of things don\u0026rsquo;t work properly for me. I turned on apache server on my mac and added my directory on /etc/apache2/httpd.conf along with and Alias but that did not work out. I constantly ran in forbidden 403 error and tried everything described in various forums but nothing worked and then I came across a post which showed me an alternative way to run a webserver and access my folder without the hassle of apache2 httpd.conf file changes.\nIt\u0026rsquo;s really simple, all you need to do is figure out which folder you want to get access to on web server. In my case I wanted to share /Users/dinesharora/Desktop/Mydocument/softwares/sencha-touch-2\nso here are the steps:\n  Open the terminal\n  cd /Users/dinesharora/Desktop/Mydocument/softwares/sencha-touch-2\n  type python -m SimpleHTTPServer\n  Hit enter\n  You will see a message - Serving HTTP on 0.0.0.0 port 8000\rNow if for some reason you are a stickler and like the old-fashioned 8080 port then just type 1  python -m SimpleHTTPServer 8080\r  That\u0026rsquo;s it. Now access your folder via http://localhost:8000/. If you want to get access to this over another machine then just type http://localhost:8080, so for example in my case it would be http://dinesharora.local:8080\nNow you know how to fly a plane, but do you know how to do a safe landing?? Just hit control +c to shut down the server. Dumb!!\nCheers!!\n** **\n"
},
{
	"uri": "/2012/06/03/saving-files-in-amazon-s3-using-carrierwave-and-fog-gem/",
	"title": "Saving files in Amazon S3 using Carrierwave and Fog Gem",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "Long long time ago in a far far away land….. I am just kidding. So I needed a gem to do file uploads(in my case images but you can upload anything) and I was looking at various options. Paperclip is a popular option but there is a new kid on the block (so i read in various forums)… Carrierwave.\nNow I have not used Paperclip but what I read was that Carrierwave is more flexible and powerful than Paperclip so if are interested then keep reading. Now let me tell you that you may need to do some additional settings, I will not get into details because the wiki page of Carrierwave is pretty intensive. The purpose of writing this post is to highlight a couple of issue that I ran into and some settings which were not explained.\nStep 1: Install the Carrierwave gem\n gem install carrierwave**\rStep 2: Update the gem file\ngem carrierwave\rStep 3: Now you need a uploader. This is the file which has all the settings like which folder the image will be saved, setting the image quality, caching etc. I wanted to call my uploader class as ImageUploader\nrails generate uploader ImageUploader\rStep 4: Install fog gem\ngem install fog\rStep 5: Update gem file\ngem 'fog', ''~\u0026gt; 1.3.1'\rbundle install\rStep 6: Choose the storage type\n1 2 3 4 5  ImageUploader \u0026lt; CarrierWave::Uploader::Base\rstorage :fog\rend\r  Step 7: Create model. Mine was called Photo so I create photo.rb. Notice the line number 10.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  class Photo \u0026lt; ActiveRecord::Base\r#Attributes or fileds\r attr_accessible :image,:pic_name,:description,:albums_id\r#associations\r belongs_to :albums\r#carrier wave\r mount_uploader :image,**ImageUploader**\r#Validations\r validates :description,:pic_name,:albums_id, :presence=\u0026gt;true\rvalidates_uniqueness_of :pic_name\rend\r  Step 7: How to upload file and show uploaded file in the html page\nUpload page:\n1 2 3 4 5 6 7  \u0026lt;%= form_for @user, :html =\u0026gt; {:multipart =\u0026gt; true} do |f| \u0026gt;\r\u0026lt;p\u0026gt;\r\u0026lt;label\u0026gt;My Avatar\u0026lt;/label\u0026gt;\r\u0026lt;%= f.file_field :avatar \u0026gt;\r\u0026lt;%= f.hidden_field :avatar_cache \u0026gt;\r\u0026lt;/p\u0026gt;\r\u0026lt;% end  \u0026gt;\r  View uploaded image\n\u0026lt;%= form_for @user, :html =\u0026gt; {:multipart =\u0026gt; true} do |f| \u0026gt;\r\u0026lt;p\u0026gt;\r\u0026lt;label\u0026gt;My Avatar\u0026lt;/label\u0026gt;\r\u0026lt;%= image_tag(@user.avatar_url) if @user.avatar? \u0026gt;\r\u0026lt;%= f.file_field :avatar \u0026gt;\r\u0026lt;%= f.hidden_field :avatar_cache \u0026gt;\r\u0026lt;/p\u0026gt;\r\u0026lt;% end \u0026gt;\rStep 8: Now comes the most important part. Setting up fog. Now if you follow the documentation on Carrierwave then you will run into issue(I will explain the issue and fix below). The wiki page said create a file **fog.rb **in the **lib/carrierwave/storage/fog.rb **and that\u0026rsquo;s what I did. I created the file with the contents below.\n1 2 3 4 5 6 7 8 9 10 11 12  CarrierWave.configure do |config|\rconfig.fog_credentials = {\r:provider =\u0026gt; \u0026#39;AWS\u0026#39;, # required\r :aws_access_key_id =\u0026gt; \u0026#39;xxx\u0026#39;, # required\r :aws_secret_access_key =\u0026gt; \u0026#39;yyy\u0026#39;, # required\r :region =\u0026gt; \u0026#39;eu-west-1\u0026#39; # optional, defaults to \u0026#39;us-east-1\u0026#39;\r }\rconfig.fog_directory = \u0026#39;name_of_directory\u0026#39; # required\r config.fog_host = \u0026#39;https://assets.example.com\u0026#39; # optional, defaults to nil\r config.fog_public = false # optional, defaults to true\r config.fog_attributes = {\u0026#39;Cache-Control\u0026#39;=\u0026gt;\u0026#39;max-age=315576000\u0026#39;} # optional, defaults to {}\r end\r  Now before you start you need to have a S3 account on Amazon S3. So get your Amazon access key and secret access key. For example mine was …. hehehe no I am not going to share my access keys with you :-). Anyway if you forgot to note down your access key and incase you are wondering where I can find that and are guessing that it will be on S3 Dashboard then you are mistaken just like me. You can find that on your account settings –\u0026gt; Security credentials.\nSo after you have noted down your key and access key. Go ahead create a bucket on S3. A bucket is nothing but a directory. It\u0026rsquo;s just a fancy shimancy name for directory that Amazon came up with. You can further create sub directories.\nNow coming back to the meaty part and **fog.rb **file. I updated the below fields in the fog.rb\n1 2  :aws_access_key_id =\u0026gt; \u0026#39;xxx\u0026#39;, # required\r :aws_secret_access_key =\u0026gt; \u0026#39;yyy\u0026#39;, # required\r   I commented out the below lines as they are optional\n1 2 3  #:region=\u0026gt; eu-west-1\r # optional, defaults to us-east-1\r   I was not sure what was my region so if you are not sure as well then go ahead and comment it.\n1 2 3 4  #config.fog_host = https://s3.amazonaws.com\u0026#39;\r # optional, defaults to nil\r #config.fog_public = true # optional, defaults to true\r   If you leave\n config.fog_host to https://s3.amazonaws.com\n then I ran into issues which said\nLoadError (Expected /Users/dinesharora/Desktop/Mydocument/ruby-proj/album/app/uploaders/image_uploader.rb to define ImageUploader):\rSo I commented that field. The next part that I was not sure about was how to tell fog which folder or directory I want to upload my files. I had created a bucket(directory) called **myalbums **and had created a sub folder called devlopment.\nSo I updated\nconfig.fog_directory = myalbums/development\rwhich did not work. The right way to do is\nconfig.fog_directory = myalbums\rand also in **ImageUploader **update the line\ndef store_dir\rdevelopment/uploads/#{model.class.to\\_s.underscore}/#{mounted\\_as}/#{model.id}\rend\rThat\u0026rsquo;s it. Now just start the server and start uploading, that\u0026rsquo;s what the forums said but as it always happens with me(nothing works for me the first time) I ran into error(as I mentioned earlier that you will if you create the fog.rb in lib/carrierwave/storage/ folder) which said\n1 2 3 4 5 6 7 8 9 10 11 12 13  **ActionController::RoutingError (uninitialized constant CarrierWave::Storage::Fog):**\r**app/uploaders/image_uploader.rb:11:in \\`\u0026lt;class:ImageUploader\u0026gt;\u0026#39;**\r**app/uploaders/image_uploader.rb:3:in \\`\u0026lt;top (required)\u0026gt;\u0026#39;**\r**app/models/photo.rb:10:in \\`\u0026lt;class:Photo\u0026gt;\u0026#39;**\r**app/models/photo.rb:1:in \\`\u0026lt;top (required)\u0026gt;\u0026#39;**\r**app/controllers/photo_controller.rb:1:in \\`\u0026lt;top (required)\u0026gt;\u0026#39;**\r  To get rid of this error, just copy the file in **config/initializers **and now I could finally say – That\u0026rsquo;s it!!!! 🙂\n[1]: http://javahabit.com/wp-content/uploads/2012/06/screen-shot-2012-06-03-at-12-26-01-am1.png\r"
},
{
	"uri": "/2012/05/30/installing-rails-on-mac-osx/",
	"title": "Installing Rails on Mac OSX",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "I struggled a lot doing this on my mac. I prepared steps and notes while I was upgrading. here are the steps for mac osx. This works for Mac OSX 10.6+\n============ Section 1 =================\nInstall and update Ruby 1.9 on MAC OSX Snow leopard 10.6.5\n Install RVM\nInstallation instruction: http://rvm.beginrescueend.com/rvm/install/  – In Treminal Run the following command:\nbash \u0026lt; \u0026lt;( curl http://rvm.beginrescueend.com/releases/ … all-latest )\n– type in terminal: version=$(curl http://rvm.beginrescueend.com/releases/ … sion.txt);\n– type in terminal:\nmkdir -p ~/.rvm/src/ \u0026amp;\u0026amp; cd ~/.rvm/src/ \u0026amp;\u0026amp; curl -O http://rvm.beginrescueend.com/releases/ … on}.tar.gz | tar zxf – \u0026amp;\u0026amp; cd rvm-${version} \u0026amp;\u0026amp; ./install\n– The first time you install RVM, you must put the following line into your ~/.bash_profile at the very end, after all path loads etc:\n(If you do not have .bash_profile then open terminal.\nStart up Terminal\n• Type “cd ~/” to go to your home folder\n• Type “touch .bash_profile” to create your new file.\n• Edit .bash_profile with your favorite editor (or you can just type “open -e .bash_profile” to open it in TextEdit.\n• Type “. .bashrc” to reload .bashrc and update any functions you add.\n)\n– Update the .bash_profile and add this text.\n[[ -s “$HOME/.rvm/scripts/rvm” ]] \u0026amp;\u0026amp; . “$HOME/.rvm/scripts/rvm” # This loads RVM into a shell session.\n– Close the terminal and open a new terminal.\n– Check if rvm is installed correctly by typing\ntype rvm | head -1\nThis should show result : “rvm is a function ”\n– type : source ~/.rvm/scripts/rvm\n– type: rvm notes\n–\n=========== Section 2: After you have done section 1 above ======\nII Upgrade to ruby 1.9\n– Make sure that you installed rvm\nInstruction URL- http://asciicasts.com/episodes/200-rails-3-beta-and-rvm\n– type: rvm install 1.9.2\n– Check which version of ruby is installed so far by typing “rvm list”.\n– The new version of ruby will be active only until the terminal is open. To make ruby 1.9.2 as default version. Type: rvm 1.9.2 –default\n– If we want to return to previous version of the system. Then type: rvm system –default\nIII INSTALL RAILS 3\n– Type: gem install rails\nIV INSTALL FRESH COPY OF MYSQL\n– INSTRUCTION URL: http://weblog.rubyonrails.org/2009/8/30 … ow-leopard\n– First Stop the mysql server if it is running :\nsudo /opt/local/share/mysql5/mysql/mysql.server stop\n– Now download a fresh copy from this URL:\nhttp://weblog.rubyonrails.org/2009/8/30 … ow-leopard\n– Next Install the mysql.pkg → Next install MySQLStartupItem.pkg -→ Install MySQL.prefPane\n– The Mac OS X PKG of MySQL installs itself into\n`/usr/local/mysql-VERSION’ and also installs a symbolic link,\n`/usr/local/mysql’, that points to the new location. If a directory\nnamed `/usr/local/mysql’ exists, it is renamed to\n`/usr/local/mysql.bak’ first. Additionally, the installer creates the\ngrant tables in the `mysql’ database by executing `mysql_install_db’.\n– Start the MySql server from the System Prefernce pane and make sure that it runs.\n– Go to /usr/local/mysql/bin and type: ./mysql, This should start start the MYSQL prompt and you can execute the SQl statements.\n– Let us now secure the database by giving it a user id and password.\nIn the same package type: ./mysqladmin –u root password ISSUES:\nAccess Denied for local host after you have set root and password then you need to reset the password..\n Stop the Server from preference pane. From /usr/local/mysql/bin folder type the following the terminal:\nsudo ./mysqld_safe — –skip-grant-tables . This will start the server. Type : ./mysql -u root mysql type: UPDATE user SET Password=PASSWORD(‘admin’) where USER=’root’; — This will set the password as admin. Restart the server from prefernce pane.  Hope this helps. I used the exact same steps to upgrade to Rails 3.0.3 and ruby 1.9.2\n—Cheers!!!\n\r\r\rGo to forum Go to topic Go to post\r\r\r14 dinesh19aug "
},
{
	"uri": "/2012/05/29/setting-up-imap-settings-for-hotmail-account-on-iphone-and-android/",
	"title": "Setting up IMAP settings for hotmail account on Iphone and android",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "Yes, there are still a few lost soul who still have a Hotmail account and I am one of them :-).\nI have used Iphone in the past and use an android phone now, however I always complained that I was not able to set up an IMAP account for Hotmail. I always had a POP3 account 🙁\nWhat does IMAP and POP3 mean? – For beginner who do not understand what is IMAP and POP3, here’s a small description.\na) POP3 – is a one way email checking. When you setup account on your iPhone, android or Microsoft outlook or any other email client and you download an email on your phone or on your desktop, it just downloads a copy of that email. So when you hit delete or read an email on your phone or desktop, it does not affect the email in the Hotmail account. Now most of us use Iphone o android phone these days to check emails. Now when you delete the email on phone, you still need to login on your Hotmail account to really delete email. As result when I login to Hotmail account after a month, there are hundreds of emails which I deleted on my phone and I have to go through each email to make sure that I do not delete an important email.\nb) IMAP – is a two-way email checking. When you read or delete and email on phone or any other email client such as OUTLOOK, the email is updated in your account as well. For example if you delete an email on your phone, it will be deleted from your account as well.\nSo here’s a run down of the process.\nIPHONE SETUP:\n Go to Settings – Mail, Contact, Calendars Click on Add Account… Choose Microsoft Exchange Fill in the fields shown (Leave domain blank and your login should be your email address) Click next and it will ask for server. Use m.hotmail.com Choose if you want your email, contacts or calendar synced.  ANDROID PHONE SETUP:\n  Open the Mail app.\n  Hit the menu button \u0026gt; Add account\n  Enter your hotmail e-mail address and password.\n  Press Manual setup (don’t press Next!)\n  For account, select Exchange.\n  On the Server settings page, clear out the DomainUsername field and enter your hotmail address.\n  Change the Server to m.hotmail.com (without the quotes).\n  Keep the checkboxes the way they are (Use secure connection enabled, but don’t accept all SSL certificates)\n  Press Next.\n  Once the server settings are confirmed, you’ll be asked for how far back you’d like to sync your e-mail, contacts and calendars.\n  Cheers!!!\n"
},
{
	"uri": "/2012/01/28/engineyard-rails-3-x-nginx-passenger-assets-not-displayed/",
	"title": "Engineyard, Rails 3.x, NGINX, PASSENGER ASSETS NOT DISPLAYED",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": "CAUTION: Please excuse the diction/grammar/spelling. It’s 3 AM and I am in a hurry to sleep as I need to drop my friends to airport in exactly 4 hrs.\nSo I was trying to set up this new application for my wife. I was using galleria plugin to show a slide like image. Everything was working fine in development so I decided to see how it would look like in production environment if it was deployed in a cloud or virtual server. So I ended up choosing engineyard because it gives you 500 free hours and you do not need to have dns name. Once the application is deployed on the server, you can view the application on temporary url.\nInstalling a rails app on engineyard is pretty easy, however tunneling (ssh) on to the server was a nightmare. I will cover the ssh experience in some other post. The main issue was my galleria plugin css, images and javascript was not showing correctly. After spending 2 days and mailing the engineyard (They pretty responsive and quick!!) I realized that there was an issue with application configuration. So I tried to run the application on my mac in production mode and found that galleria javascripts and css files were not loaded. The engineyard support told me that they were using passenger and Nginx. So I decided to install the same on my local and experiment.\nYou can install passenger with Nginx or apache. I used apache version initially but had some issues so decided to use nginx instead.\nOn an interesting note While I was still struggling to load galleria assets using passenger, I searched a lot site documentation, rails sites, forums etc., but none told me how to start and stop Nginx … call me dumb but that is something I did not find on any of the sites until I decided to go through the whole Nginx documentation and there it was… buried deep half way through the documentation :-). It should have been there on there installation page.\nSo this post is in two parts, the first part will walk you through passenger and Nginx installation and the second part will let you know the configuration changes in your rails app so that assets are loaded properly in production mode.\nPART 1: PASSENGER AND NGINX installation\n Install passenger: Run this in your command line  gem install passenger\rInstall the Nginx: Run this in your command line  passenger-install-nginx-module\rIf you see permission errors which says that you do not have permission to install then try\n sudo passenger-install-nginx-module\rIf you still get error which says\n Could not find RubyGem passenger (\u0026gt;= 0) (Gem::LoadError),\n then you probably use rvm to maintain your ruby rails version. So in this case try\nrvmsudo passenger-install-nginx-module\rNow when the installation starts, it will ask you some basic question like should I install some file plugins or location of installation etc., just keep saying yes or hit enter to continue. The whole process will probably take 3-4 minutes to complete.\nUpdate the nginx configuration file  By default nginx will be installed in /opt/nginx folder on your mac or linux system. I don’t know what is the default location for windows. On a lighter note do people actually use windows for RAILS development??? Seriously?? No offense but I have only met people who use windows to try out rails sample apps .\nOk I am done with bashing Windows users 🙂 So to update the configuration file go to nginx.conf\rfile under\n/opt/nginx/conf\rand update the code under server tag. You can find more details about nginx configuration here.\nserver {\r**listen 80;**\r**server_name localhost;**\r**root /Users/dinesharora/Desktop/Mydocument/ruby-proj/album;**\r**passenger_enabled on;**\r**passenger\\_base\\_uri /Users/xxxxx/Desktop/Mydocument/ruby-proj/album;**\rAfter saving the file. Stop the Nginx server\nStop nginx by going into /opt/nginx/sbin. Then run this command\nsudo ./nginx -s stop\rTo start just run\n./ngnix\rStart your passenger or application.  Go to your rails app folder and run this command in the terminal\npassenger start\r(To stop ctrl+c)\rNow by default passenger should start in production mode, but mine did not. It started in development mode. The documentation said that it will start in production mode by default but id did not. After racking my brains and going through the whole documentation, I did not find anything. Guess what ……. the documentation is outdated on the site. I almost gave up on Rails development and was thinking about going back to Java/Spring/Grails or GWT, but decided to stick a little longer. Anyway too much blabbering about what I did and whined …. here’s how to check if your passenger is running in production or development mode.\nWhen you run you passenger start, you will in 3rd or fourth line something like this\nLog file: /Users/dinesharora/Desktop/Mydocument/ruby-proj/album/log/passenger.3000.log\rEnvironment: development\rAccessible via: http://0.0.0.0:3000/\rIf it is running in development mode, the you need to start your application using this command.\npassenger start -e production\rIt goes without saying that if you run into permission issues, run it using sudo or rvmsudo\nSo that\u0026rsquo;s it. Your app is running and can be accessed via http://0.0.0.0:3000/. I mapped 0.0.0.0 to localhost :-). Anyway I was happy that my installation was successful(I struggled for 4-5 days), without any solutions.\nPART 2: ASSETS CONFIGURATION\nWell my happiness was short lived because my galleria plugin was not working. I initially thought it was an issue with galleria plugin so I switched it with other jquery image slide show plugin, but each had same issue, they all worked fine in development but were not loaded in production mode. I kept seeing this error in the production logs Routing error [get] /assets/javascripts/galleria/xxxx.js not found 404 error.\nEvery site said that Just set 1  config.assets.compile = true\r  and it will start showing up. Well I believed that statement for 4 more days to no avail. I tried playing around with application.js (Sprockets gem built in Rails 3.x) bit it did not work. I included the galleria folder as well in the application.js but still no images.\nSo I had placed my galleria plugin /app/assets/javascripts/galleria and I had to access\n js file\rgalleria/plugins/*.css files etc\rgalleria/plugins/images etc.\rI tried placing them in app/assets, lib/assets, vendor/assets but nothing will work. Here are steps if you have the same issue.\nOpen production.rb and make sure you have added or uncommented the following\n1.\nCode is not reloaded between requests\rconfig.cache_classes = true\rFull error reports are disabled and caching is turned on\rconfig.consider\\_all\\_requests_local = false\rconfig.action\\_controller.perform\\_caching = true\rDisable Rails\u0026amp;#8217;s static asset server (Apache or nginx will already do this)\rconfig.serve\\_static\\_assets = false\rCompress JavaScripts and CSS\rconfig.assets.compress = true\r**\\# Don\u0026amp;#8217;t fallback to assets pipeline if a precompiled asset is missed**\r**config.assets.compile = true**\r**\\# Generate digests for assets URLs**\r**config.assets.digest = true**\r**config.i18n.fallbacks = true**\r**\\# Send deprecation notices to registered listeners**\r**config.active_support.deprecation = :notify**\r\\# config.assets.initialize\\_on\\_precompile = false\rconfig.assets.precompile += [“*.js”, “*.css”] —— This HAS TO BE ADDED and was the key. Unless you add this line galleria images or any other images which are sub folders in assets or controller specific or personal folder under app, vendor lib will not loaded.\nAfter you have made the above changes in production.rb file, Rails needs to compile js and css and put them in\npublic/assets\rfolder. Now in development environment Rails does it for you but when you are in production, you need to generate assets. So while you are in you rails application folder run this command\nrake assets:precompile\rOR bundle exec rake\nassets:precompile\rThis will attach fingerprint to all the images, css and js files and put them in public/assets folder. Read Rails documentation.\nNow start your application in production mode using\npassenger start -e production\rOpen the application url.\nVoila!!! All the images show up.\nCheers\n"
},
{
	"uri": "/series/",
	"title": "Series",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
}]