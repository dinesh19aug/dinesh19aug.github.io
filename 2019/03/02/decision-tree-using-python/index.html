
<!DOCTYPE html>
<html lang="en">
<head>
  
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta http-equiv="Cache-Control" content="public" />
<!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.54.0" />

    
    
    

<title>Part 7 Decision tree regression or classification using python • A Morsel Of Code</title>


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Part 7 Decision tree regression or classification using python"/>
<meta name="twitter:description" content="Machine learning tutorial using decision tree regression. This post in the machine learning series will walk you through the process of implementing decision tee regression using python."/>

<meta property="og:title" content="Part 7 Decision tree regression or classification using python" />
<meta property="og:description" content="Machine learning tutorial using decision tree regression. This post in the machine learning series will walk you through the process of implementing decision tee regression using python." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/2019/03/02/decision-tree-using-python/" />
<meta property="article:published_time" content="2019-03-03T19:17:12-05:00"/>
<meta property="article:modified_time" content="2019-03-03T19:17:12-05:00"/>



<link rel="canonical" href="/2019/03/02/decision-tree-using-python/" />

<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
<link rel="icon" href="/favicon.ico" type="image/x-icon">





<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Allerta+Stencil">

<link rel="stylesheet" href="/css/w3.css" />


<link rel="stylesheet" href="/css/style.css" />









  
  
</head>
<body class="w3-light-grey">


    
    <header id="header">
         
          
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-47631412-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments)};
  gtag('js', new Date());

  gtag('config', 'UA-47631412-1');
</script>

<div class="w3-right ">
<div class="w3-bar w3-light-grey  ">
  
  <span class="w3-bar-item w3-left " id="google_translate_element"></span>
<script>
  function googleTranslateElementInit() {
    new google.translate.TranslateElement(
      {
          pageLanguage: 'en'
        , layout: google.translate.TranslateElement.FloatPosition.TOP_RIGHT
        , multilanguagePage: true
      }
      , 'google_translate_element'
    );
  }
</script>
<script async src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>


  
       <a href="javascript:void(0)" class="w3-bar-item w3-button w3-hover-green" title="Search" onclick="displaysearch()"><i class="fa fa-search"></i></a>
  
      <span class="w3-hide-small">

        <a href="mailto:dinesh19aug@gmail.com" class="w3-bar-item w3-button w3-hover-green"><i class="fa fa-envelope"></i></a>

        <a href="https://stackoverflow.com/users/1172194/dinesh-arora" class="w3-bar-item w3-button w3-hover-green"><i class="fa fa-stack-overflow"></i></a>

        <a href="https://twitter.com/dinesh19aug" class="w3-bar-item w3-button w3-hover-green"><i class="fa fa-twitter"></i></a>

        <a href="https://github.com/dinesh19aug" class="w3-bar-item w3-button w3-hover-green"><i class="fa fa-github"></i></a>

        <a href="https://www.linkedin.com/in/dinesharora" class="w3-bar-item w3-button w3-hover-green"><i class="fa fa-linkedin"></i></a>

        <a href="https://github.com/dinesh19aug" class="w3-bar-item w3-button w3-hover-green"><i class="fa fa-github"></i></a>

      </span>

</div>
</div>
<br>
  <div class="w3-content">

  <div class="w3-container w3-center w3-padding-32 w3-hide-small">
      <h1 class="w3-xxxlarge w3-text-blue w3-wide w3-allerta  " style="text-shadow:1px 1px 0 #444" ><u>
      
         A Morsel Of Code - One Byte At A Time
      
</u></h1>

    </div>
    <div class="w3-content w3-center">
    <div class="w3-bar w3-light-grey w3-border">
    <a href="/" class="w3-bar-item w3-button w3-large w3-green"><i class="fa fa-home"></i></a>
    
      <a href="/categories/" class="w3-bar-item w3-button w3-hide-small">Categories</a>
    
      <a href="/tags/" class="w3-bar-item w3-button w3-hide-small">Tags</a>
    


    <a href="javascript:void(0)" class="w3-bar-item w3-button w3-right w3-hide-large w3-hide-medium" onclick="displaymenu()">&#9776;</a>
  </div>

<div id="mobilemenu" class="w3-bar-block w3-light-grey w3-hide w3-hide-large w3-hide-medium">
  
      <a href="/categories/" class="w3-bar-item w3-button">Categories</a>
      
      <a href="/tags/" class="w3-bar-item w3-button">Tags</a>
      

</div>
</div>
</div>
<script>
function displaymenu() {
    var x = document.getElementById("mobilemenu");
    if (x.className.indexOf("w3-show") == -1) {
        x.className += " w3-show";
    } else {
        x.className = x.className.replace(" w3-show", "");
    }
}
</script>



  <div id="searchOverlay" class="overlay w3-hide">
    <span class="closebtn" onclick="displaysearch()" title="Close Overlay">×</span>
    <div class="overlay-content">
        <form action="/search/">
          <input type="text" placeholder="Search.." name="q">
          <button type="submit"><i class="fa fa-search"></i></button>
        </form>
    </div>
  </div>

  <script>
  function displaysearch() {
    var x = document.getElementById("searchOverlay");
    if (x.className.indexOf("w3-show") == -1) {
        x.className += " w3-show";
    } else {
        x.className = x.className.replace(" w3-show", "");
    }

  }


  </script>





    <hr class="headfoot">

      
    </header>
    
<div class="w3-content">
    
      <div>
        <div id="content" >
          
    

      <div id="toc" class="w3-dropdown-hover w3-hide-small w3-hide-medium">
    <button class="w3-button w3-teal w3-xlarge">&#9776;</button>
    <div class="w3-dropdown-content w3-bar-block w3-border" style="right:0">
         
          <h3 class="w3-center">Contents </h3>
            <nav id="TableOfContents">
<ul>
<li>
<ul>
<li>
<ul>
<li><a href="#how-to-get-dataset">How to get dataset?</a></li>
<li><a href="#what-is-a-decision-tree">What is a &ldquo;Decision Tree&rdquo;&lsquo;&ldquo;?</a></li>
<li><a href="#parts-of-decision-tree">Parts of decision Tree</a></li>
<li><a href="#how-is-the-tree-built">How is the tree built?</a></li>
<li><a href="#can-we-just-start-with-any-random-feature-as-the-root-node">Can we just start with any random feature as the root node?</a></li>
<li><a href="#what-is-data-entropy">What is Data Entropy?</a></li>
<li><a href="#how-to-avoid-overfitting-in-decision-tree">How to avoid overfitting in decision Tree?</a></li>
<li><a href="#would-this-model-work-on-non-categorical-or-continuous-values">Would this model work on non-categorical or continuous values?</a></li>
<li><a href="#python-implementation">Python Implementation</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
         
      </div>

     
      </div>
    

 
     


  <div class="w3-content w3-card-4" >
    
    <header class="w3-container w3-center w3-padding-32">
      <h1>Part 7 Decision tree regression or classification using python</h1>

      <div >
        <p> 2019-03-03 
          
             <code> 1645 words  </code>
             <code> 8 mins read </code>
          
        </p>
        <div >
            
              <a class="w3-btn w3-small w3-round w3-green" href="/categories/tech-notes/"> Tech Notes </a>
            
              <a class="w3-btn w3-small w3-round w3-green" href="/categories/machine-learning/"> Machine learning </a>
            
          </div>
       
        
      </div>
    </header>

   
    
    <div class="w3-container">
      
        

        
        

        
          
          
          

<p>In the <a href="http://www.javahabit.com/2019/02/10/part-6-ml-svr/">previous post</a>, we learnt about Support vector regression. In this post, we will see a new way of deciphering information using a simple format of traversing conditions.</p>

<p><strong>Business Goal</strong>: Can you spot the king? The people of <em>Falkland</em> are scared. Their king disguises as a common man and roams among them to gain knowledge about his kingdom and see if his policies are working in his kingdom. When the king is disguised, the common people don&rsquo;t recognize him. If they accidentally mistreat the king when he is disguised, they get punished. Can you help the people of <em>Falkland</em> spot the king?</p>

<h3 id="how-to-get-dataset">How to get dataset?</h3>

<ul>
<li><a href="https://github.com/dinesh19aug/ml-notes/blob/master/Part-7-decision-tree/iris.csv">Decision Tree dataset</a></li>
<li><a href="https://github.com/dinesh19aug/ml-notes/blob/master/Part-7-decision-tree/decisionTree.ipynb">Decision tree notebook</a></li>
</ul>

<h3 id="what-is-a-decision-tree">What is a &ldquo;Decision Tree&rdquo;&lsquo;&ldquo;?</h3>

<p><img src="/placeholder.svg" data-src="/resources/img/decision/decisionTree.PNG" alt="decsionTree" /></p>

<blockquote>
<p>A Decision tree builds regression or classification models in the form of tree structure. It is a set of &lsquo;yes&rsquo; or &lsquo;no&rsquo; flow, which cascades downward like an upside down tree. For example, given a set of independent variables or features about a person, can we find if the person is healthy.</p>
</blockquote>

<p><img src="/placeholder.svg" data-src="/resources/img/decision/sampleTree.PNG" alt="sampleTree.PNG" /></p>

<h3 id="parts-of-decision-tree">Parts of decision Tree</h3>

<ul>
<li>Each decision point is called a <strong>Node</strong>. Ex - <strong>Age &lt; 30</strong></li>
<li>Each connector is called an <strong>Edge</strong>.</li>
<li>Each node which does not have any subnode is called a <strong>Leaf</strong>. Ex - <strong>Fit</strong> or <strong>Unfit!</strong>.</li>
</ul>

<h3 id="how-is-the-tree-built">How is the tree built?</h3>

<p>To build a tree, we need to start with an <em>Independent Feature</em> as a root node. The possible attributes or unique values of that feature form the edges. Once the first level of the tree is completed, attach another feature node at the end of each node and traverse deeper. Once you have exhausted all the features, you will arrive at the dependent value or result.</p>

<h3 id="can-we-just-start-with-any-random-feature-as-the-root-node">Can we just start with any random feature as the root node?</h3>

<p>This is a million $$$ question here. This is the meat of the whole algorithm. Let&rsquo;s look at our business problem about the problem that people of <em>Falkland</em> are facing. We need to come up with a solution to spot the king when he is disguised to save the common man from mistreating him accidentally and hence punished in return. Here&rsquo;s the data that we have collected about people leaving the castle.
<img src="/placeholder.svg" data-src="/resources/img/decision/falkland.PNG" alt="falkland.PNG" /></p>

<blockquote>
<p>Ok! So we have the data, but how do we find out which feature will be the root node?</p>
</blockquote>

<p>Going back to our previous <a href="http://www.javahabit.com/2019/02/10/part-5-ml-mltr-backward-elimination/">post</a> on <a href="http://www.javahabit.com/2019/02/10/part-5-ml-mltr-backward-elimination/"><strong>Backward Elimination</strong></a>, we can gather that the root node should be a feature which is the most important feature in making the decision. To find the most important feature, we will align each independent feature with dependent feature (<em>Is_King</em>).</p>

<p><img src="/placeholder.svg" data-src="/resources/img/decision/featuremap.PNG" alt="featuremap.PNG" />
<img src="/placeholder.svg" data-src="/resources/img/decision/featureMap2.PNG" alt="featureMap2.PNG" /></p>

<p>If we look at the above mapping, we will see that <strong>Gold_Tooth</strong> feature is right most of the time in predicting the king, followed by the <strong>castle</strong> as it has the least number of false positive.</p>

<blockquote>
<p>Well, that&rsquo;s good to know, but I noticed that you did talk about the last two features - <strong>Greedy</strong> and <strong>Slow</strong>.</p>
</blockquote>

<p>Yes, the distinction between the two is difficult to figure out. Both <strong>Greedy</strong> and <strong>Slow</strong> features have an equal number of false positives. To understand, which feature is more important than the other, we need to understand <strong>Data Entropy</strong>_.</p>

<h3 id="what-is-data-entropy">What is Data Entropy?</h3>

<p>Entropy means how many times information changed that we got a positive result. Imagine if the king never left the castle, which means that all the information that we collected will show <strong>Is_King</strong> as <strong>0</strong>. In our case, the entropy is <strong>1</strong> because anybody could be the king. If we just had <strong>Castle</strong> as the feature, predicting the king would be difficult without another piece of information.
&gt;So in simple terms <strong>Entropy</strong> is how many pieces of the data point(<em>Independent feature</em>) is required, to guess the <em>Dependent variable</em> - <em>Is_King</em>__</p>

<p><img src="/placeholder.svg" data-src="/resources/img/decision/falklandResult.PNG" alt="falklandResult.PNG" /></p>

<p>To further explain. Let&rsquo;s say that instead of starting with <strong>Gold_tooth</strong> as the root node, we start with the <strong>castle</strong>. We will see that we are able to find the king only <strong><sup>3</sup>&frasl;<sub>10</sub></strong> times. On top of that, the left side gives very poor results. Just <strong><sup>1</sup>&frasl;<sub>5</sub></strong> or <strong>20%</strong>.</p>

<p>There is another problem with the above tree. It is too overcomplicated and is <strong>overfitted</strong>. If we get  new data the accuracy of our model could fall drastically.</p>

<p>Going back to our learning in the <a href="http://www.javahabit.com/2019/02/10/part-5-ml-mltr-backward-elimination/">earlier post</a>, the simpler model should be preferred over the complicated model to avoid overfitting.</p>

<h3 id="how-to-avoid-overfitting-in-decision-tree">How to avoid overfitting in decision Tree?</h3>

<p>Just remember the 3 golden rules to avoid overfitting:</p>

<ol>
<li><p>Use a smaller number of data points to build the tree. Ex - 10% of data points is a good place to build a generic model.</p></li>

<li><p>Do not go overboard with the depth of the tree. A tree depth should only be increased if there is a significant improvement in the prediction.</p></li>

<li><p>Stop, if the number of data  points at the split is less than 5%.</p></li>
</ol>

<p>Here&rsquo;s a refined version of the tree.</p>

<p><img src="/placeholder.svg" data-src="/resources/img/decision/refinedTree.PNG" alt="refinedTree.PNG" /></p>

<h3 id="would-this-model-work-on-non-categorical-or-continuous-values">Would this model work on non-categorical or continuous values?</h3>

<p>Absolultely!! The splitting rules would still apply as I mentioned above.</p>

<p><img src="/placeholder.svg" data-src="/resources/img/decision/spli1.PNG" alt="spli1.PNG" /></p>

<p>So each Split is a leaf node above. Imagine if we wanted to find the dependent variable <strong>Y</strong> whose independent partners <strong>X1</strong> and <strong>X2</strong> are <strong>10</strong> and <strong>150</strong>, then it would land in the first node as <strong>300.5</strong>.</p>

<blockquote>
<p>I get why it landed in first leaf node position but where did we get value <strong>300.5</strong>?<br />
The value 300.5 is the average of all the data points in that box.</p>

<p><strong>Pay attention and read the previous 2 lines again.</strong> The last two lines will help you understand why we need to divide it into different leaves and nodes. If you do not have splits, then the only option is to take the average of the <strong>ALL</strong> the data points!! The accuracy would be nowhere close to your expectation and would be same all values of X1 and X2.</p>
</blockquote>

<p><img src="/placeholder.svg" data-src="/resources/img/decision/split2.PNG" alt="split2.PNG" /></p>

<h3 id="python-implementation">Python Implementation</h3>

<p>We are going to take a standard dataset called IRIS Dataset
&gt;“The Iris flower dataset or Fisher’s Iris dataset is a multivariate dataset introduced by the British statistician and biologist Ronald Fisher in his 1936 paper ‘The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis’.” — Wikipedia</p>

<p>In layman terms, it is a set of data points about IRIS flower where we have the information about the length and the width of sepals and petals about 3 varieties.</p>

<p><img src="/placeholder.svg" data-src="/resources/img/decision/iris.PNG" alt="iris.PNG" /></p>

<p><strong>Step 1:</strong> Get the common imports</p>

<pre><code class="language-python"># Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
dataset = pd.read_csv(&quot;iris.csv&quot;)
</code></pre>

<p><strong>Step 2:</strong> Identify the missing data</p>

<pre><code class="language-python">dataset.isnull().any()
</code></pre>

<pre><code>sepal-length    False
sepal-width     False
petal-length    False
petal-width     False
species         False
dtype: bool
</code></pre>

<p><strong>Step 3:</strong> Describe the data and identify the data types</p>

<pre><code class="language-python">dataset.describe()

</code></pre>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal-length</th>
      <th>sepal-width</th>
      <th>petal-length</th>
      <th>petal-width</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>150.000000</td>
      <td>150.000000</td>
      <td>150.000000</td>
      <td>150.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>5.843333</td>
      <td>3.054000</td>
      <td>3.758667</td>
      <td>1.198667</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.828066</td>
      <td>0.433594</td>
      <td>1.764420</td>
      <td>0.763161</td>
    </tr>
    <tr>
      <th>min</th>
      <td>4.300000</td>
      <td>2.000000</td>
      <td>1.000000</td>
      <td>0.100000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>5.100000</td>
      <td>2.800000</td>
      <td>1.600000</td>
      <td>0.300000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>5.800000</td>
      <td>3.000000</td>
      <td>4.350000</td>
      <td>1.300000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>6.400000</td>
      <td>3.300000</td>
      <td>5.100000</td>
      <td>1.800000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>7.900000</td>
      <td>4.400000</td>
      <td>6.900000</td>
      <td>2.500000</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code class="language-python">dataset.dtypes
</code></pre>

<pre><code>sepal-length    float64
sepal-width     float64
petal-length    float64
petal-width     float64
species          object
dtype: object
</code></pre>

<p><img src="/placeholder.svg" data-src="/resources/img/decision/iris_sample.PNG" alt="iris_sample.PNG" /></p>

<p><strong>Step 4:</strong> Load the Iris data and create the X and Y variables</p>

<pre><code class="language-python">
X= dataset.iloc[0:, 0:4].values
Y = dataset.iloc[:,4]
</code></pre>

<p><strong>Step 5:</strong> Plot the data</p>

<pre><code class="language-python">

##Get the dataset for each of the three species
setosa=dataset[dataset['species']=='Iris-setosa']
versicolor =dataset[dataset['species']=='Iris-versicolor']
virginica =dataset[dataset['species']=='Iris-virginica']

#Create an empty figure with two windows pf size 21 by 10
plt.figure()
fig,ax=plt.subplots(1,2,figsize=(21, 10))

#Plot each species using Sepal length and width on x-y axis
setosa.plot(x=&quot;sepal-length&quot;, y=&quot;sepal-width&quot;, kind=&quot;scatter&quot;,ax=ax[0],label='setosa',color='r')
versicolor.plot(x=&quot;sepal-length&quot;,y=&quot;sepal-width&quot;,kind=&quot;scatter&quot;,ax=ax[0],label='versicolor',color='b')
virginica.plot(x=&quot;sepal-length&quot;, y=&quot;sepal-width&quot;, kind=&quot;scatter&quot;, ax=ax[0], label='virginica', color='g')

#Plot each species using Petal length and width on x-y axis
setosa.plot(x=&quot;petal-length&quot;, y=&quot;petal-width&quot;, kind=&quot;scatter&quot;,ax=ax[1],label='setosa',color='r')
versicolor.plot(x=&quot;petal-length&quot;,y=&quot;petal-width&quot;,kind=&quot;scatter&quot;,ax=ax[1],label='versicolor',color='b')
virginica.plot(x=&quot;petal-length&quot;, y=&quot;petal-width&quot;, kind=&quot;scatter&quot;, ax=ax[1], label='virginica', color='g')

#Give Each figure its names
ax[0].set(title='Sepal comparasion ', ylabel='sepal-width')
ax[1].set(title='Petal Comparasion',  ylabel='petal-width')
ax[0].legend()
ax[1].legend()

#Show the plot
plt.show()

</code></pre>

<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>

<p><img src="/placeholder.svg" data-src="/resources/img/decision/iris-plot.PNG" alt="iris-plot.PNG" /></p>

<p><strong>Step 6:</strong> Encode the value of Flower types
The values of dependent the variable needs to be encoded to numbers as they are categorical values</p>

<pre><code class="language-python">from sklearn.preprocessing import LabelEncoder
labelEncoder_y = LabelEncoder()
Y = labelEncoder_y.fit_transform(Y)

</code></pre>

<p><strong>Step 7:</strong> Split the data in training and test set</p>

<pre><code class="language-python">from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=0)
</code></pre>

<p><strong>Step 8:</strong> Train the Decision Tree model</p>

<pre><code class="language-python">from sklearn.tree import DecisionTreeRegressor
regressor = DecisionTreeRegressor(random_state=0)
regressor.fit(x_train, y_train)
</code></pre>

<pre><code>DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,
           max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           presort=False, random_state=0, splitter='best')
</code></pre>

<p><strong>Step 9:</strong> Predict and score the model</p>

<pre><code class="language-python">y_predict=regressor.predict(x_test)

print(regressor.score(x_test,y_test))
</code></pre>

<pre><code>1.0
</code></pre>

<blockquote>
<p>Wow! Did we just predict that our model is correct 100% of the time?<br />
The reason the accuracy is showing 100% is that our model is too complex as we did not define the maximum depth of tree and hence we broke a cardinal rule. Let&rsquo;s take a look at the created tree.</p>
</blockquote>

<pre><code class="language-python">from sklearn.externals.six import StringIO
from IPython.display import Image
from sklearn.tree import export_graphviz
import pydotplus
from sklearn import tree

dot_data = StringIO()  
tree.export_graphviz(regressor, out_file=dot_data)
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
Image(graph.create_png())
</code></pre>

<p><img src="/placeholder.svg" data-src="/resources/img/decision/tree.PNG" alt="tree.PNG" /></p>

<p>As you can see, that since we did not provide a maximum depth of the tree, it created a complex tree of 6 layers and hence for our model we are getting 100% accuracy. This means that the model is an <strong>overfitted model</strong>.</p>

<p>Let&rsquo;s fix this by creating a simpler model.</p>

<pre><code class="language-python">#Creating a model that is only 2 layers deep by setting max_depth=3
regressor = DecisionTreeRegressor(random_state=0,criterion='mse', splitter='best', max_depth=3, min_samples_split=3, min_samples_leaf=2 )
regressor.fit(x_train, y_train)

y_predict=regressor.predict(x_test)

print(regressor.score(x_test,y_test))
</code></pre>

<pre><code>0.9739827477382705
</code></pre>

<blockquote>
<p>As you can see that the model is not an overfit anymore and still gives us pretty good accuracy of <strong>97.4%</strong>.<br />
Looking at the decision tree now.</p>
</blockquote>

<pre><code class="language-python">from sklearn.externals.six import StringIO
from IPython.display import Image
from sklearn.tree import export_graphviz
import pydotplus
from sklearn import tree

dot_data = StringIO()  
tree.export_graphviz(regressor, out_file=dot_data)
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
Image(graph.create_png())

![tree_fix.PNG](/resources/img/decision/tree_fix.PNG)
</code></pre>

<p>So keep climbing the tree of success with this DecisionTree regression model. In the next series, we will see how to use a kind of decision tree called Random forest regression.</p>

                 
                
         
      
    </div>

    
   

    <div class="w3-container">
    	
      
     
	</div>



  


    
    
    
    <div class="w3-container">
        
        <h2>Related Articles:</h2>
        <ul class="w3-ul w3-hoverable">
            
            

              <li class="w3-padding-large"><span class="date">2019/02/16</span> &nbsp; <a href="/2019/02/10/part-6-ml-svr/">Part 6 Support Vector Regression</a></li>
            

              <li class="w3-padding-large"><span class="date">2019/02/11</span> &nbsp; <a href="/2019/02/10/part-5-ml-mltr-backward-elimination/">Part 5 Machine Learning Backward Elimination</a></li>
            

              <li class="w3-padding-large"><span class="date">2019/02/03</span> &nbsp; <a href="/2019/02/02/part-4-ml-multiple-linear-regression/">Part 4 Machine Learning Multiple Regression</a></li>
            

              <li class="w3-padding-large"><span class="date">2019/01/27</span> &nbsp; <a href="/2019/01/27/part-3-ml-understanding-p-value/">Part 3 Machine Learning Understanding P Value</a></li>
            

              <li class="w3-padding-large"><span class="date">2019/01/22</span> &nbsp; <a href="/2019/01/22/part-2-ml-simplelinear-regression/">Part 2 Machine Learning Simplelinear Regression</a></li>
            
        </ul>
    </div>
    
    
    <br>  
</div>



<div class="w3-container w3-card-2 w3-black">
<div class="w3-row">
  <div class="w3-col l2 m2 s12 w3-center">
  
    <img src="https://avatars3.githubusercontent.com/u/1176242?s=460&amp;v=4" width ="100px" class="w3-circle w3-center w3-margin-top w3-margin-bottom" alt="author" >
   
  </div>
  <div class="w3-col l10 m10 s12 ">
  <div class = "w3-container w3-margin-top">
    
    
  </div>
  </div>
  </div>
</div>

      
    <div class="w3-content" > 
      <div class="w3-bar w3-section">
	     
	    
	      <a class="w3-btn w3-right w3-text-indigo w3-hover-green" href="/2019/02/10/part-6-ml-svr/">
	       Part 6 Support Vector Regression &#10095;
	      </a>
  	  </div>
    </div>
	
 

  
  
  

      <div id="wrapads">
        <div class="adBanner">
         
        </div>
       </div>
      
      <div id="allowads" class="allowads-overlay">
  
        <div class="allowads-overlay-content">
        <div class="w3-panel w3-pink w3-large">
        

         <p> We notice you're using an adblocker.  If you like our webite please keep us running by whitelisting this site in your ad blocker. We’re serving quality, related ads only. Thank you!</p>
         
          <div class="w3-btn w3-green"  onclick="closeOverlay()">I've whitelisted your website.</div><br>
          <div class="w3-button w3-small"  onclick="closeOverlay()">Not now</div>
        </div>
        </div>
      </div>

      <script>
      function closeOverlay() {
        document.getElementById("allowads").style.width = "0%";
        document.getElementById("wrapads").style.height="1px";
      }

      function detectads() {
      var h = document.getElementById("wrapads").clientHeight;

      if (h==0){ document.getElementById("allowads").style.width = "100%";
      }
      }
      

     
      
      </script>
        </div>
        
          <script>
  shareurl=encodeURIComponent(location.protocol + '//' + location.host + location.pathname);
  sharetitle=encodeURIComponent(document.title);
    
  </script>
<div class="icon-bar">
<script>
document.write( '<a href="javascript:bookmark();" class="bookmark w3-tooltip"><i class="fa fa-bookmark"></i><span style="position:absolute;left:40px;bottom:18px" class="w3-text w3-small w3-tag w3-round w3-green ">Bookmark this page</span></a> ');

document.write( '<a href="http://www.facebook.com/sharer.php?u='+shareurl+'" onclick="window.open(this.href, \'mywin\',\'left=20,top=20,width=500,height=500,toolbar=1,resizable=0\'); return false;" class="facebook w3-tooltip"><i class="fa fa-facebook "></i><span style="position:absolute;left:40px;bottom:18px" class="w3-text w3-small w3-tag w3-round w3-green">Share to Facebook</span></a> ');

document.write( '<a href="https://twitter.com/share?url='+shareurl+'&amp;text='+sharetitle+'" onclick="window.open(this.href, \'mywin\',\'left=20,top=20,width=500,height=500,toolbar=1,resizable=0\'); return false;" class="twitter w3-tooltip"><i class="fa fa-twitter"></i><span style="position:absolute;left:40px;bottom:18px" class="w3-text w3-small w3-tag w3-round w3-green">Share to Twitter</span></a> ');
document.write( '<a href="https://plus.google.com/share?url='+shareurl+'" onclick="window.open(this.href, \'mywin\',\'left=20,top=20,width=500,height=500,toolbar=1,resizable=0\'); return false;" class="google w3-tooltip"><i class="fa fa-google"></i><span style="position:absolute;left:40px;bottom:18px" class="w3-text w3-small w3-tag w3-round w3-green">Share to Google Plus</span></a>');

document.write( '<a href="http://www.linkedin.com/shareArticle?mini=true&amp;url='+shareurl+'" onclick="window.open(this.href, \'mywin\',\'left=20,top=20,width=500,height=500,toolbar=1,resizable=0\'); return false;" class="linkedin w3-tooltip"><i class="fa fa-linkedin"></i><span style="position:absolute;left:40px;bottom:18px" class="w3-text w3-small w3-tag w3-round w3-green">Share to Linkedin</span></a>');

</script>

<script>
function bookmark(){

if ('sidebar' in window && 'addPanel' in window.sidebar) { 
                window.sidebar.addPanel(location.href,document.title,"");
            } else if(  false) { 
                window.external.AddFavorite(location.href,document.title); 
            } else { 
                alert('Press ' + (navigator.userAgent.toLowerCase().indexOf('mac') != - 1 ? 'Command/Cmd' : 'CTRL') + ' + D to bookmark this page.');
            }
        }

</script>
</div>
        
           
          
  

        
        
      </div>
    

   
    <footer id="footer" >
      <div class="w3-container w3-center w3-padding-32"> 
  
  <hr class="headfoot">
  <p>Powered by <a href="https://gohugo.io">Hugo</a> | Theme - <a href="https://github.com/jesselau76/hugo-w3-simple">Hugo W3 Simple</a>
  </p>
  &copy; <a href="http://javahabit.com">Dinesh Arora</a> 2019 | <a href="https://github.com/dinesh19aug">Github</a> | <a href="https://twitter.com/dinesh19aug">Twitter</a>  | <a href="/index.xml">RSS</a>
  
</div>

    </footer>
    

    
  </div>

  

  
    
      <div id="backtotop" class="w3-hide-small w3-hide-medium">
  
        <button onclick="topFunction()" class="w3-btn w3-red w3-large" style="width:160px">Back To Top
        &rarr;</button>
        
      </div>

      <script>
        function topFunction() {
          document.body.scrollTop = 0;
          document.documentElement.scrollTop = 0;
      }
      </script>


    
 
    
    <script>
    
    function isVisible(elem) {

      let coords = elem.getBoundingClientRect();

      let windowHeight = document.documentElement.clientHeight;

      
      let topVisible = coords.top > 0 && coords.top < windowHeight;
      let bottomVisible = coords.bottom < windowHeight && coords.bottom > 0;

      return topVisible || bottomVisible;
    }

    

    function showVisible() {
      for (let img of document.querySelectorAll('img')) {
        let realSrc = img.dataset.src;
        if (!realSrc) continue;

        if (isVisible(img)) {
          

          img.src = realSrc;

          img.dataset.src = '';
        }
      }
      if ( Array.from(document.querySelectorAll('[data-src]')).every(
        img => img.getAttribute('data-src') === '') ) {
        window.removeEventListener('scroll', showVisible)
      }

    }

    window.addEventListener('scroll', showVisible);
    showVisible();
  </script>


    
    
      <div class="progress-container" id="scrollbar">
        <div class="progress-bar" id="progress-bar"></div>
      </div>  


    
<script>

window.onscroll = function() {scrollFunction()};

function scrollFunction() {
  <!-- TOC -->
    
    
    if (document.body.scrollTop > 50 || document.documentElement.scrollTop > 50) {
        document.getElementById("toc").style.display = "block";
    } else {
        document.getElementById("toc").style.display = "none";
    }
    
    <!-- cookie bar -->
    
<!-- Back to top -->
    
    if (document.body.scrollTop > 50 || document.documentElement.scrollTop > 50) {
        document.getElementById("backtotop").style.display = "block";
    } else {
        document.getElementById("backtotop").style.display = "none";
    }
    
    <!-- scroll indicator -->
    
      var winScroll = document.body.scrollTop || document.documentElement.scrollTop;
      var height = document.documentElement.scrollHeight - document.documentElement.clientHeight;
      var scrolled = (winScroll / height) * 100;
      document.getElementById("progress-bar").style.width = scrolled + "%";
      if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
            document.getElementById("scrollbar").style.display = "block";
        } else {
            document.getElementById("scrollbar").style.display = "none";
        }
    

    

    <!-- allowads -->
    
       if (document.body.scrollTop > 2000 || document.documentElement.scrollTop > 2000) {
          detectads();
       } 

    
}


</script>



  

</body>
</html>
